##  JVM是如何处理异常的

- 在 Java 语言规范中，所有异常都是 Throwable 类或者其子类的实例。Throwable 有两大直接子类
  - 第一个是 Error，涵盖程序不应捕获的异常。
  - 第二子类则是 Exception，涵盖程序可能需要捕获并且处理的异常。
    - RuntimeException 和 Error 属于 Java 里的非检查异常（unchecked exception）。其他异常则属于检查异常（checked exception）。
    -  所有的检查异常都需要程序显式地捕获，或者在方法声明中用 throws 关键字标注。

- 异常实例的构造十分昂贵。这是由于在构造异常实例时，Java 虚拟机便需要生成该异常的栈轨迹。该操作会逐一访问当前线程的 Java 栈帧，并且记录下各种调试信息
  - 然而，该异常对应的栈轨迹并非 throw 语句的位置，而是新建异常的位置。
  - 这也是为什么在实践中，我们往往选择抛出新建异常实例的原因
- 在编译生成的字节码中，每个方法都附带一个异常表。
  - Java 代码中的 catch 代码块和 fnally 代码块都会生成异常表
  - 异常表不是声明这段代码所有有可能抛出的异常，而是声明会被捕获的异常
- fnally 代码块的编译比较复杂。当前版本 Java 编译器的做法，是复制 fnally 代码块的内容，分别放在 try-catch 代码块所有正常执行路径以及异常执行路径的出口中。
  - 编译结果包含三份 fnally 代码块。其中，前两份分别位于 try 代码块和 catch 代码块的正常执行路径出口。最后一份则作为异常处理器，监控 try 代码块以及 catch 代码块。它将捕获 try代码块触发的、未被 catch 代码块捕获的异常，以及 catch 代码块触发的异常。
  - 如果 catch 代码块捕获了异常，并且触发了另一个异常，那么 fnally 捕获并且重抛的异常是哪个呢？答案是后者。也就是说原本的异常便会被忽略掉，这对于代码调试来说十分不利。
  - Java 7 专门构造了一个名为 try-with-resources 的语法糖，在字节码层面自动使用Supressed 异常。
    - try 关键字后声明并实例化实现了 AutoCloseable 接口的类，编译器将自动添加对应的 close() 操作
    - try-with-resources 还会使用 Supressed 异常的功能，来避免原异常“被消失”。





## JVM是如何实现反射的

- 允许正在运行的 Java 程序观测，甚至是修改程序的动态行为。

- 反射调用的实现

  - 方法的反射调用，也就是 Method.invoke

    - 实际上委派给 MethodAccessor 来处理。MethodAccessor 是一个接口，它有两个已有的具体实现：一个通过本地方法来实现反射调用，另一个则使用了委派模式。
    - 每个 Method 实例的第一次反射调用都会生成一个委派实现，它所委派的具体实现便是一个本地实现。

  - Java 的反射调用机制还设立了另一种动态生成字节码的实现（下称动态实现），直接使用invoke 指令来调用目标方法。之所以采用委派实现，便是为了能够在本地实现以及动态实现中切换。

  - 考虑到许多反射调用仅会执行一次，Java 虚拟机设置了一个阈值15	

    - 动态实现无需经过 Java 到 C++再到 Java 的切换，但由于生成字节码十分耗时，仅调用一次的话，反而是本地实现要快上 3 到 4倍

    - 当某个反射调用的调用次数在 15 之下时，采用本地实现；当达到 15 时，便开始动态生成字节码，并将委派实现的委派对象切换至动态实现，这个过程我们称之为 Infation。

    - 可以关闭反射调用的 Infation 机制，从而取消委派实现，并且直接使用动态实现

    - 此外，每次反射调用都会检查目标方法的权限，而这个检查同样可以在 Java 代码里关闭

    - >  -Dsun.refect.noInfation=true
      >
      > method.setAccessible(true);

- 反射调用的开销

  - 以 getMethod 为代表的查找方法操作，会返回查找得到结果的一份拷贝。因此，我们应当避免在热点代码中使用返回 Method 数组的 getMethods 或者 getDeclaredMethods 方法，以减少不必要的堆空间消耗。
  - 在实践中，我们往往会在应用程序中缓存 Class.forName 和 Class.getMethod 的结果。

- 反射调用之前字节码都做了什么

  - 由于 Method.invoke 是一个变长参数方法，在字节码层面它的最后一个参数会是 Object 数组。Java 编译器会在方法调用处生成一个长度为传入参数 数量的 Object 数组，并将传入参数一一存储进该数组中。
    - 由于 Object 数组不能存储基本类型，Java 编译器会对传入的基本类型参数进行自动装箱
    - 这两个操作除了带来性能开销外，还可能占用堆内存，使得 GC 更加频繁。
    - 如果一个对象不逃逸，那么即时编译器可以选择栈分配甚至是虚拟分配，也就是不占用堆空间。
  - 之所以反射调用能够变得这么快，主要是因为即时编译器中的方法内联。在关闭了 Infation 的情况下，内联的瓶颈在于 Method.invoke 方法中对 MethodAccessor.invoke 方法的调用。
  - 在生产环境中，我们往往拥有多个不同的反射调用，对应多个 GeneratedMethodAccessor，也就是动态实现。
    -  Java 虚拟机的关于上述调用点的调用者的具体类型（ invokevirtual 或者invokeinterface），Java 虚拟机会记录下调用者的具体类型，我们称之为类型 profle）无法同时记录这么多个类，因此可能造成所测试的反射调用没有被内联的情况。
    - 之所以这么慢，除了没有内联之外，另外一个原因是逃逸分析不再起效
    - 只要没有完全内联，就会将看似不逃逸的对象通过参数传递出去。即时编译器不知道所调用的方法对该对象有没有副作用，所以会将其判定为逃逸。

- 方法的反射调用会带来不少性能开销，原因主要有三个：变长参数方法导致的 Object 数组，基本类型的自动装箱、拆箱，还有最重要的方法内联。







##  Java对象的内存布局

- 以 new 语句为例，它编译而成的字节码将包含用来请求内存的 new 指令，以及用来调用构造器的invokespecial 指令。
- 构造器
  - 如果一个类没有定义任何构造器的话， Java 编译器会自动添加一个无参数的构造器。
  - 子类的构造器需要调用父类的构造器。如果父类存在无参数构造器的话，该调用可以是隐式的，也就是说 Java 编译器会自动添加对父类构造器的调用
  - 如果父类没有无参数构造器，那么子类的构造器则需要显式地调用父类带参数的构造器。
  - 通过 new 指令新建出来的对象，它的内存其实涵盖了所有父类中的实例字段。
  - 子类的实例还是会为这些父类实例字段分配内存的。
- 压缩指针
  - 在 Java 虚拟机中，每个 Java 对象都有一个对象头（object header）
    - 由标记字段和类型指针所构成
    - 标记字段用以存储 Java 虚拟机有关该对象的运行数据，如哈希码、GC 信息以及锁信息，而类型指针则指向该对象的类。
    - 为了尽量较少对象的内存使用量，64 位 Java 虚拟机引入了压缩指针的概念，将堆中原本 64 位的 Java 对象指针压缩成 32 位的，32 位压缩指针最多可以标记 2 的 32 次。这样一来，对象头中的类型指针也会被压缩成 32 位，使得对象头的大小从 16 字节降至 12 字节。
  - 默认情况下，Java 虚拟机堆中对象的起始地址需要对齐至 8 的倍数。如果一个对象用不到 8N 个字节，那么空白的那部分空间就浪费掉了。这些浪费掉的空间我们称之为对象间的填充
    - 内存对齐不仅存在于对象与对象之间，也存在于对象中的字段之间。
    - 字段内存对齐的其中一个原因，是让字段只出现在同一 CPU 的缓存行中。如果字段不是对齐的， 那么就有可能出现跨缓存行的字段。也就是说，该字段的读取可能需要替换两个缓存行，而该字段 的存储也会同时污染两个缓存行。
- 字段重排列
  - java 虚拟机重新分配字段的先后顺序，以达到内存对齐的目的
  - Java 8 还引入了一个新的注释 @Contended，用来解决对象字段之间的伪共享问题 。这个注释也会影响到字段的排列。Java 虚拟机会让不同的 @Contended 字段处于独立的缓存行中，因此你会看到大量的空间被浪费掉。
  - 伪共享
    - 假设两个线程分别访问同一对象中不同的 volatile 字段，逻辑上它们并没有共享内容，因此不需要同步。
    - 如果这两个字段恰好在同一个缓存行中，那么对这些字段的写操作会导致缓存行的写回，也就造成了实质上的共享。





# 监控和诊断JVM堆内和堆外内存使用

- 以 JConsole 为例，其内存页面可以显示常见的**堆内存**和**各种堆外部分**使用状态。
  - 也可以使用命令行工具进行运行时查询，如 jstat 和 jmap 等工具都提供了一些选项，可以查看堆、方法区等使用数据。
  - 或者，也可以使用 jmap 等提供的命令，生成堆转储（Heap Dump）文件，然后利用 jhat 或 Eclipse MAT 等堆转储分析工具进行详细分析。
  - 如果你使用的是 Tomcat、Weblogic 等 Java EE 服务器，这些服务器同样提供了内存管理相关的功能。
  - 另外，从某种程度上来说，GC 日志等输出，同样包含着丰富的信息
  - 特别推荐[Java Mission Control](http://www.oracle.com/technetwork/java/javaseproducts/mission-control/java-mission-control-1998576.html)（JMC），这是一个非常强大的工具，不仅仅能够使用[JMX](https://en.wikipedia.org/wiki/Java_Management_Extensions)进行普通的管理、监控任务，还可以配合[Java Flight Recorder](https://docs.oracle.com/javacomponents/jmc-5-4/jfr-runtime-guide/about.htm#JFRUH171)（JFR）技术，以非常低的开销，收集和分析 JVM 底层的 Profiling 和事件等信息。
- 年代视角的堆结构
  - 按照通常的 GC 年代方式划分，Java 堆内分为
    - 新生代
      - 是大部分对象创建和销毁的区域，在通常的 Java 应用中，绝大部分对象生命周期都是很短暂的。其内部又分为 Eden 区域，作为对象初始分配的区域；两个 Survivor，有时候也叫 from、to 区域，被用来放置从 Minor GC 中保留下来的对象。
      - JVM 会随意选取一个 Survivor 区域作为“to”，然后会在 GC 过程中进行区域间拷贝，也就是将 Eden 中存活下来的对象和 from 区域的对象，拷贝到这个“to”区域。这种设计主要是为了防止内存的碎片化，并进一步清理无用对象。
      - 从内存模型而不是垃圾收集的角度，对 Eden 区域继续进行划分，Hotspot JVM 还有一个概念叫做 Thread Local Allocation Buffer（TLAB），据我所知所有 OpenJDK 衍生出来的 JVM 都提供了 TLAB 的设计。这是 JVM 为每个线程分配的一个私有缓存区域，否则，多线程同时分配内存时，为避免操作同一地址，可能需要使用加锁等机制，进而影响分配速度；TLAB 仍然在堆上，它是分配在 Eden 区域内的。其内部结构比较直观易懂，start、end 就是起始地址，top（指针）则表示已经分配到哪里了。所以我们分配新对象，JVM 就会移动 top，当 top 和 end 相遇时，即表示该缓存已满，JVM 会试图再从 Eden 里分配一块儿。
    - 老年代
      - 放置长生命周期的对象，通常都是从 Survivor 区域拷贝过来的对象。当然，也有特殊情况，我们知道普通的对象会被分配在 TLAB 上；
      - 如果对象较大，JVM 会试图直接分配在 Eden 其他位置上；
      - 如果对象太大，完全无法在新生代找到足够长的连续空闲空间，JVM 就会直接分配到老年代。

- 如何利用 JVM 参数，直接影响堆和内部区域的大小

  - > 最大堆体积
    >
    > -Xmx value
    >
    > 
    >
    > 初始的最小堆体积
    >
    > -Xms value
    >
    > 
    >
    > 在 JVM 内部，如果 Xms 小于 Xmx，堆的大小并不会直接扩展到其上限，也就是说保留的空间（reserved）大于实际能够使用的空间（committed）。当内存需求不断增长的时候，JVM 会逐渐扩展新生代等区域的大小，所以 Virtual 区域代表的就是暂时不可用（uncommitted）的空间。
    >
    > 
    >
    > 老年代和新生代的比例
    >
    > -XX:NewRatio=value
    >
    > 默认情况下，这个数值是 2，意味着老年代是新生代的 2 倍大
    >
    > 
    >
    > 也可以不用比例的方式调整新生代的大小，直接指定下面的参数，设定具体的内存大小数值
    >
    > -XX:NewSize=value
    >
    > 
    >
    > Eden 和 Survivor 的大小是按照比例设置的，YoungGen=Eden + 2*Survivor，JVM 参数格式是
    >
    > -XX:SurvivorRatio=value

- JVM 堆外内存

  - > 首先来做些准备工作，开启 NMT 并选择 summary 模式，
    >
    > -XX:NativeMemoryTracking=summary
    >
    > 
    >
    > 为了方便获取和对比 NMT 输出，选择在应用退出时打印 NMT 统计信息
    >
    > -XX:+UnlockDiagnosticVMOptions
    >
    > -XX:+PrintNMTStatistics

  - NMT 所表征的 JVM 本地内存使用

    - Java 堆

    -  Class 内存占用，它所统计的就是 Java 类元数据所占用的空间，JVM 可以通过类似下面的参数调整其大小

      - -XX:MaxMetaspaceSize=value

    - hread，这里既包括 Java 线程，如程序主线程、Cleaner 线程等，也包括 GC 等本地线程。

      - 你有没有注意到，即使是一个 HelloWorld 程序，这个线程数量竟然还有 25。似乎有很多浪费，设想我们要用 Java 作为 Serverless 运行时，每个 function 是非常短暂的，如何降低线程数量呢
        - JDK 9 的默认 GC 是 G1，虽然它在较大堆场景表现良好，但本身就会比传统的 Parallel GC 或者 Serial GC 之类复杂太多，所以要么降低其并行线程数目，要么直接切换 GC 类型；
        - JIT 编译默认是开启了 TieredCompilation 的，将其关闭，那么 JIT 也会变得简单，相应本地线程也会减少。
        - 替换了默认 GC，并关闭 TieredCompilation 的命令行
          - 线程数目降低，消耗的内存也下降了。

    - Code 统计信息

      - 显然这是 CodeCache 相关内存，也就是 JIT compiler 存储编译热点方法等信息的地方

      - > JVM 提供了一系列参数可以限制其初始值和最大值等
        >
        > -XX:InitialCodeCacheSize=value
        > -XX:ReservedCodeCacheSize=value

    - GC 部分

      - G1 等垃圾收集器其本身的设施和数据结构就非常复杂和庞大，例如 Remembered Set 通常都会占用 20%~30% 的堆空间
      - GC 明确修改为相对简单的 Serial GC，不仅总线程数大大降低，而且 GC 设施本身的内存开销就少了非常多

    - Compiler 部分

      - 就是 JIT 的开销，显然关闭 TieredCompilation 会降低内存使用。



