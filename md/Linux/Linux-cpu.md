## 平均负载

- 每次发现系统变慢时，我们通常做的第一件事，就是执行 top 或者 uptime 命令

  - 过去 1 分钟、5 分钟、15 分钟的平均负载（LoadAverage）
  - 简单来说，平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和 CPU 使用率并没有直接关系。
    - 所谓可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用ps 命令看到的，处于 R 状态（Running 或Runnable）的进程。
    - 不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。
      - 不可中断状态实际上是系统对进程和硬件设备的一种保护机制

- 平均负载为多少时合理

  - 当平均负载比 CPU 个数还大的时候，系统已经出现了过载。
  - 假设我们在一个单 CPU 系统上看到平均负载为 1.73，0.60，7.98，那么说明在过去 1 分钟内，系统有 73% 的超载，而在 15 分钟内，有 698% 的超载，从整体趋势来看，系统的负载在降低。
  - 在实际生产环境中，当平均负载高于 CPU 数量 70% 的时候需要我们重点关注

- 平均负载与 CPU 使用率

  - CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应
  - 平均负载它不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待I/O 的进程。
    - CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的；
    - I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高；

- 工具

  - stress 是一个 Linux 系统压力测试工具，这里我们用作异常进程模拟平均负载升高的场景。

    - > 模拟一个 CPU 使用率 100% 的场景    stress --cpu 1 --timeout 600
      >
      > 模拟 I/O 压力，即不停地执行 sync     stress -i 1 --timeout 600
      >
      > 模拟8 个进程                                    stress -c 8 --timeout 600

  - mpstat 是一个常用的多核 CPU 性能分析工具，用来实时查看每个 CPU 的性能指标，以及所有 CPU 的平均指标

  - pidstat 是一个常用的进程性能分析工具，用来实时查看进程的 CPU、内存、I/O 以及上下文切换等性能指标。

    - >  -w 参数表示输出进程切换指标，
      >
      >  -u 参数则表示输出 CPU 使用指标
      >
      >  -d 所有进程的 I/O 使用情况
      >
      >  -t 参数表示输出线程的指标。
      >
      >  -p 指定进程号



## 用户态和内核态

- 内核态：cpu可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序。

- 用户态：只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取。

- 为什么要有用户态和内核态？

  - 由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络, CPU划分出两个权限等级 -- 用户态和内核态。

- 用户态与内核态的切换

  所有用户程序都是运行在用户态的, 但是有时候程序确实需要做一些内核态的事情, 例如从硬盘读取数据, 或者从键盘获取输入等. 而唯一可以做这些事情的就是操作系统, 所以此时程序就需要先操作系统请求以程序的名义来执行这些操作.

  这时需要一个这样的机制: 用户态程序切换到内核态, 但是不能控制在内核态中执行的指令

  这种机制叫系统调用, 在CPU中的实现称之为**陷阱指令**(Trap Instruction)

  他们的**工作流程**如下:

  1. 用户态程序将一些数据值放在寄存器中, 或者使用参数创建一个堆栈(stack frame), 以此表明需要操作系统提供的服务.
  2. 用户态程序执行陷阱指令
  3. CPU切换到内核态, 并跳到位于内存指定位置的指令, 这些指令是操作系统的一部分, 他们具有内存保护, 不可被用户态程序访问
  4. 这些指令称之为陷阱(trap)或者系统调用处理器(system call handler). 他们会读取程序放入内存的数据参数, 并执行程序请求的服务
  5. 系统调用完成后, 操作系统会重置CPU为用户态并返回系统调用的结果

  当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。这与处于内核态的进程的状态有些类似。 

  内核态与用户态是操作系统的两种运行级别,跟intel cpu没有必然的联系, intel cpu提供**Ring0-Ring3三种级别的运行模式**，Ring0级别最高，Ring3最低。Linux使用了Ring3级别运行用户态，Ring0作为 内核态，没有使用Ring1和Ring2。Ring3状态不能访问Ring0的地址空间，包括代码和数据。Linux进程的4GB地址空间，3G-4G部 分大家是共享的，是内核态的地址空间，这里存放在整个内核的代码和所有的内核模块，以及内核所维护的数据。用户运行一个程序，该程序所创建的进程开始是运 行在用户态的，如果要执行文件操作，网络数据发送等操作，必须通过write，send等系统调用，这些系统调用会调用内核中的代码来完成操作，这时，必 须切换到Ring0，然后进入3GB-4GB中的内核地址空间去执行这些代码完成操作，完成后，切换回Ring3，回到用户态。这样，用户态的程序就不能 随意操作内核地址空间，具有一定的安全保护作用。
  至于说保护模式，是说通过内存页表操作等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程的地址空间中的数据。

   

   

  1. **用户态和内核态的概念区别**

  究竟什么是用户态，什么是内核态，这两个基本概念以前一直理解得不是很清楚，根本原因个人觉得是在于因为大部分时候我们在写程序时关注的重点和着眼的角度放在了实现的功能和**代码**的逻辑性上，先看一个例子：

  ```c++
  void testfork(){
  	if(0 = = fork()){
  		printf(“create new process success!\n”);
  	}
  	printf(“testfork ok\n”);
  }
  
  ```

  这段代码很简单，从功能的角度来看，就是实际执行了一个fork()，生成一个新的进程，从逻辑的角度看，就是判断了如果fork()返回的是0则打印相关语句，然后函数最后再打印一句表示执行完整个testfork()函数。代码的执行逻辑和功能上看就是如此简单，一共四行代码，从上到下一句一句执行而已，完全看不出来哪里有体现出用户态和进程态的概念。

  如果说前面两种是静态观察的角度看的话，我们还可以从动态的角度来看这段代码，即它被转换成CPU执行的指令后加载执行的过程，这时这段程序就是一个动态执行的指令序列。而究竟加载了哪些代码，如何加载就是和操作系统密切相关了。

   

  2）**特权级**

  熟悉Unix/Linux系统的人都知道，**fork的工作实际上是以系统调用的方式完成相应功能的**，具体的工作是由sys_fork负责实施。其实无论是不是Unix或者Linux，对于任何操作系统来说，创建一个新的进程都是属于核心功能，因为它要做很多底层细致地工作，消耗系统的物理资源，比如分配物理内存，从父进程拷贝相关信息，拷贝设置页目录页表等等，这些显然不能随便让哪个程序就能去做，于是就自然引出特权级别的概念，显然，最关键性的权力必须由高特权级的程序来执行，这样才可以做到集中管理，减少有限资源的访问和使用冲突。

  **特权级显然是非常有效的管理和控制程序执行的手段**，因此在硬件上对特权级做了很多支持，就Intel x86架构的CPU来说一共有0~3四个特权级，0级最高，3级最低，硬件上在执行每条指令时都会对指令所具有的特权级做相应的检查，相关的概念有CPL、DPL和RPL，这里不再过多阐述。硬件已经提供了一套特权级使用的相关机制，软件自然就是好好利用的问题，这属于操作系统要做的事情，对于Unix/Linux来说，只使用了0级特权级和3级特权级。也就是说在Unix/Linux系统中，一条工作在0级特权级的指令具有了CPU能提供的最高权力，而一条工作在3级特权级的指令具有CPU提供的最低或者说最基本权力。

   

  3）用户态和内核态

  **现在我们从特权级的调度来理解用户态和内核态就比较好理解了**，当程序运行在3级特权级上时，就可以称之为运行在用户态，因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；反之，当程序运行在0级特权级上时，就可以称之为运行在内核态。

  **虽然用户态下和内核态下工作的程序有很多差别，但最重要的差别就在于特权级的不同，即权力的不同。**运行在用户态下的程序不能直接访问操作系统内核数据结构和程序，比如上面例子中的testfork()就不能直接调用sys_fork()，因为前者是工作在用户态，属于用户态程序，而sys_fork()是工作在内核态，属于内核态程序。

  当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态，比如testfork()最初运行在用户态进程下，当它调用fork()最终触发sys_fork()的执行时，就切换到了内核态。

   

  2. 用户态和内核态的转换

  1）用户态切换到内核态的3种方式

  a. 系统调用

  这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。

  b. 异常

  当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

  c. 外围设备的中断

  当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

   

  这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。

   

  2）具体的切换操作

  **从触发方式上看，可以认为存在前述3种不同的类型，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一致的，没有任何区别，都相当于执行了一个中断响应的过程**，因为系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本上也是一致的，关于它们的具体区别这里不再赘述。关于中断处理机制的细节和步骤这里也不做过多分析，涉及到由用户态切换到内核态的步骤主要包括：

  [1] 从当前进程的描述符中提取其内核栈的ss0及esp0信息。

  [2] 使用ss0和esp0指向的内核栈将当前进程的cs,eip,eflags,ss,esp信息保存起来，这个

  过程也完成了由用户栈到内核栈的切换过程，同时保存了被暂停执行的程序的下一

  条指令。

  [3] 将先前由中断向量检索得到的中断处理程序的cs,eip信息装入相应的寄存器，开始

  执行中断处理程序，这时就转到了内核态的程序执行了。





## CPU 上下文切换

- 概述

  - Linux 是一个多任务操作系统，它支持远大于 CPU 数量的任务同时运行。当然，这些任务实际上并不是真的在同时运行，而是因为系统在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。
  - 根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景，也就是进程上下文切换、线程上下文切换以及中断上下文切换。

- CPU 上下文切换

  - 而在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要系统事先帮它设置好 CPU 寄存器和程序计数器（Program Counter，PC）
    - CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存
    - 程序计数器，则是用来存储CPU 正在执行的指令位置、或者即将执行的下一条指令位置。
    - 它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 CPU 上下文。
  - CPU 上下文切换，就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务

- 进程上下文切换

  - 从用户态到内核态的转变，需要通过系统调用来完成
  - 系统调用的过程有没有发生 CPU 上下文的切换呢
    - CPU 寄存器里原来用户态的指令位置，需要先保存起来。
    - 接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。
    - 而系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。所以，一次系统调用的过程，其实是发生了两次 CPU 上下文切换。
  - 进程上下文切换跟系统调用又有什么区别
    - 进程上下文切换，是指从一个进程切换到另一个进程运行
    - 而系统调用过程中一直是同一个进程在运行。
    - 进程是由内核来管理和调度的，进程的切换只能发生在内核态
    - 进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。
  - 进程在什么时候才会被调度到 CPU 上运行呢
    - 其一，为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。
    - 其二，进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。
    - 其三，当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。
    - 其四，当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行。
    - 最后一个，发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。

- 线程上下文切换

  - 线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位
    - 说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源
    - 线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的
  - 线程的上下文切换其实就可以分为两种情况
    - 第一种， 前后两个线程属于不同进程。
    - 第二种，前后两个线程属于同一个进程。

- 中断上下文切换

  - 为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。
  - 跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。
    - 即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。
    - 中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等

- 怎么查看系统的上下文切换情况

  - vmstat 是一个常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数。

    - r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。
    - b（Blocked）则是处于不可中断睡眠状态的进程数。
    - in（interrupt）则是每秒中断的次数。
    - cs（context switch）是每秒上下文切换的次数。

  - vmstat 只给出了系统总体的上下文切换情况，要想查看每个进程的详细情况，就需要使用我们前面提到过的 pidstat 了。给它加上 -w 选项，你就可以查看每个进程上下文切换的情况了。

    -  cswch ，表示每秒自愿上下文切换（voluntary context switches）的次数
      - 自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。
    - nvcswch ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。
      - 非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。

  - sysbench 是一个多线程的基准测试工具，一般用来评估不同系统参数下的数据库负载情况。当然，在这次案例中，我们只把它当成一个异常进程来看，作用是模拟上下文切换过多的问题

  - > 以 10 个线程运行 5 分钟的基准测试，模拟多线程切换的问题
    >
    > $ sysbench --threads=10 --max-time=300 threads run

  - 中断只发生在内核态，而 pidstat 只是一个进程的性能分析工具，并不提供任何关于中断的详细信息，怎样才能知道中断发生的类型呢

    - /proc 实际上是 Linux 的一个虚拟文件系统，用于内核空间与用户空间之间的通信。

    - >  -d 参数表示高亮显示变化的区域
      > $ watch -d cat /proc/interrupts

    - 变化速度最快的是重调度中断（RES）

      - 这个中断类型表示，唤醒空闲状态的 CPU 来调度新的任务运行。
      - 这是多处理器系统（SMP）中，调度器用来分散任务到不同 CPU 的机制，通常也被称为处理器间中断



## 某个应用的CPU使用率达到100%

- CPU 使用率

  - 单位时间内 CPU 使用情况的统计，以百分比的方式展示

  - Linux 通过 /proc 虚拟文件系统，向用户空间提供了系统内部状态的信息，而 /proc/stat提供的就是系统的 CPU 和任务统计信息

  - 跟系统的指标类似，Linux也给每个进程提供了运行情况的统计信息，也就是 /proc/[pid]/stat。

  - 事实上，为了计算 CPU 使用率，性能工具一般都会取间隔一段时间（比如 3 秒）的两次值，作差后，再计算出这段时间内的平均 CPU 使用率

  - $$
    平均CPU使用率=1-\frac{空闲时间_{new}-空闲时间_{old}}{总CPU时间_{new}-总CPU时间_{old}}
    $$

  - 对比一下 top 和 ps 这两个工具报告的 CPU 使用率，默认的结果很可能不一样，因为 top 默认使用 3 秒时间间隔，而 ps 使用的却是进程的整个生命周期。

  - top命令，每个进程都有一个 %CPU 列，表示进程的CPU 使用率。它是用户态和内核态 CPU 使用率的总和

- pidstat

  - 用户态 CPU 使用率 （%usr）；
  - 内核态 CPU 使用率（%system）；
  - 运行虚拟机 CPU 使用率（%guest）；
  - 等待 CPU 使用率（%wait）；
  - 以及总的 CPU 使用率（%CPU）。

- CPU 使用率过高怎么办

  - 哪种工具适合在第一时间分析进程的 CPU 问题呢？我的推荐是 perf
    - 它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。
  - 第一种常见用法是 perf top，类似于 top，它能够实时显示占用 CPU 时钟最多的函数或者指令，因此可以用来查找热点函数
    - 表格式样的数据
    - 第一列 Overhead ，是该符号的性能事件在所有采样中的比例，用百分比来表示
    - 第二列 Shared ，是该函数或指令所在的动态共享对象（Dynamic Shared Object），如内核、进程名、动态链接库名、内核模块名等。
    - 第三列 Object ，是动态共享对象的类型。比如 [.] 表示用户空间的可执行程序、或者动态链接库，而 [k] 则表示内核空间
    - 最后一列 Symbol 是符号名，也就是函数名。当函数名未知时，用十六进制的地址来表示。
  - 第二种常见用法，也就是 perf record 和 perf report
    - 在实际使用中，我们还经常为 perf top 和 perf record 加上 -g 参数，开启调用关系的采样，方便我们根据调用链来分析性能问题。

  



## 系统的 CPU 使用率很高

- 测试

  - > 并发 100 个请求测试 Nginx 性能，总共测试 1000 个请求
    >
    > 请求时长为 10 分钟（-t 600）                       
    >
    > 2 $ ab -c 100 -n 1000  -t 600 http://192.168.0.10:10000/

- 明明用户 CPU 使用率已经高达 80%，但我却怎么都找不到是哪个进程的问题。
  - 这次从头开始看 top 的每行输出，Tasks 这一行看起来有点奇怪，就绪队列中居然有6 个 Running 状态的进程（6 running），是不是有点多呢？
  - 再仔细看进程列表，这次主要看 Running（R） 状态的进程。你有没有发现， Nginx 和所有的 php-fpm 都处于 Sleep（S）状态，而真正处于 Running（R）状态的，却是几个stress 进程。
  -  ps aux | grep 24344  还是没有输出。现在终于发现问题，原来这个进程已经不存在了
  -  pstree 就可以用树状形式显示所有进程之间的关系
    - pstree | grep stress
    - 从这里可以看到，stress 是被应用调用的子进程，并且进程数量不止一个（这里是 3个）。找到父进程后，我们能进入 app 的内部分析了。
    - 找到了，果然是 源码中直接调用了 stress 命令。
    - stress 会通过 write() 和 unlink() 对 I/O 进程进行压测，看来，这应该就是系统 CPU 使用率升高的根源了。
  - 是不是真的有大量的 stress 进程。该用什么工具或指标呢？
    -  perf ，它可以用来分析 CPU 性能事件
- execsnoop
  - 在这个案例中，我们使用了 top、pidstat、pstree 等工具分析了系统 CPU 使用率高的问题，并发现 CPU 升高是短时进程 stress 导致的，但是整个分析过程还是比较复杂的。
  - execsnoop 就是一个专为短时进程设计的工具。它通过 ftrace 实时监控进程的 exec() 行为，并输出短时进程的基本信息，包括进程 PID、父进程 PID、命令行参数以及执行的结果
  - 用 execsnoop 监控上述案例，就可以直接得到 stress 进程的父进程 PID 以及它的命令行参数，并可以发现大量的 stress 进程在不停启动
- 碰到常规问题无法解释的 CPU 使用率情况时，首先要想到有可能是短时应用导致的问题，比如有可能是下面这两种情况
  - 第一，应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过 top 等工具也不容易发现。
  - 第二，应用本身在不停地崩溃重启，而启动过程的资源初始化，很可能会占用相当多的CPU
  - 对于这类进程，我们可以用 pstree 或者execsnoop 找到它们的父进程，再从父进程所在的应用入手，排查问题的根源。



