## 杂

### 集群、分布式

- 集群
  - 集群，是指同一种组件的多个实例，形成的逻辑上的整体。
  - 单机处理到达瓶颈的时候，你就把单机复制几份，这样就构成了一个“集群”。集群中每台服务器就叫做这个集群的一个“节点”，所有节点构成了一个集群。每个节点都提供相同的服务，那么这样系统的处理能力就相当于提升了好几倍
  - 但问题是用户的请求究竟由哪个节点来处理呢
    - 负载均衡服务器
  - 当你的业务发展到一定程度的时候，你会发现一个问题——无论怎么增加节点，貌似整个集群性能的提升效果并不明显了。这时候，你就需要使用微服务结构了。
  - 分布式结构就是将一个完整的系统，按照业务功能，拆分成一个个独立的子系统，在分布式结构中，每个子系统就被称为“服务”。这些子系统能够独立运行在web容器中，它们之间通过RPC方式通信。
- 分布式
  - 分布式不一定就是不同的组件，同一个组件也可以，关键在于是否通过交换信息的方式进行协作。比如说Zookeeper的节点都是对等的，但它自己就构成一个分布式系统。
  - 也就是说，分布式是指通过网络连接的多个组件，通过交换信息协作而形成的系统。
  - 好处
    - 系统之间的耦合度大大降低，可以独立开发、独立部署、独立测试
    - 系统之间的耦合度降低，从而系统更易于扩展
    - 服务的复用性更高。比如，当我们将用户系统作为单独的服务后，该公司所有的产品都可以使用该系统作为用户系统，无需重复开发。
- 可以看出这两个概念并不完全冲突，分布式系统也可以是一个集群，例子就是前面说的zookeeper等，它的特征是服务之间会互相通信协作。
- 情况
  - 是分布式系统不是集群的情况，就是多个不同组件构成的系统
  - 是集群不是分布式系统的情况，比如多个经过负载均衡的HTTP服务器，它们之间不会互相通信，如果不带上负载均衡的部分的话，一般不叫做分布式系统。

### 数据库高并发解决方法

- 概述
  - 关键是如何解决慢和等，核心一个是短，一个是少，一个是分流,最后一个是集群/横向扩张/读写分离/建立主从。
    - 短是指路径（请求）要短
      - 页面静态化
      - 缓存
      - 储存过程
      - 批量读取
      - 延迟修改
      - 索引
    - 少是指查询的数据要少
      - 分表
      - 分离活跃数据
      - 分块
    - 分流
      - 集群
        - 并发请求分配到不同的服务器上
      - 分布式
        - 把单次请求的多项业务逻辑分配到多个服务器上
      - CDN
        - 例如将华南地区的用户请求分配到华南的服务器，华中地区的用户请求分配到华中的服务器
- 解决数据库高并发访问瓶颈问题
  - 缓存式的Web应用程序架构
    - 在Web层和db层之间加一层cache层
  - 业务拆分
    - 每一个模块都使用单独的数据库来进行存储，不同的业务访问不同的数据库
  - MySQL主从复制，读写分离
    - 主从复制技术（master-slave模式）来达到读写分离，以提高读写性能和读库的可扩展性
    - 主从复制
      - 数据复制的实际就是Slave从Master获取Binary log文件，然后在本地镜像的执行日志中记录的操作
    - 读写分离
      - 只在主服务器上写，只在从服务器上读
      - 让主数据库处理事务性查询，而从数据库处理select查询
      - 数据库复制被用于把事务性查询（增删改）导致的改变更新同步到集群中的从数据库
    - 实现主从分离可以使用MySQL中间件如：Atlas
  - 分表分库
    - 采用Master-Slave复制模式的MySQL架构，只能对数据库的读进行扩展，而对数据的写操作还是集中在Master上
    - 分表
      - 对于访问极为频繁且数据量巨大的单表来说，首先要做的是减少单表的记录条数
    - 分表能够解决单表数据量过大带来的查询效率下降的问题，但是却无法给数据库的并发处理能力带来质的提升
      - 分表的实质还是在一个数据库上进行的操作，很容易受数据库IO性能的限制
    - 分库
      - 当数据库master服务器无法承载写操作压力时，不管如何扩展Slave服务器都是没有意义的
    - 数据库分表可以解决单表海量数据的查询性能问题，分库可以解决单台数据库的并发访问压力问题
    - 经过业务拆分及分库分表，虽然查询性能和并发处理能力提高了。但是原本跨表的事务上升为分布式事务
    - 分库分表后需要进一步对系统进行扩容（路由策略变更）将变得非常不方便，需要重新进行数据迁移
    - 分库分表的策略
      - １、中间变量　＝ user_id%（库数量*每个库的表数量）; 　　

　　２、库序号　＝　取整（中间变量／每个库的表数量）; 　　

　　３、表序号　＝　中间变量％每个库的表数量;

### 分布式架构系统生成全局唯一序列号

- 概述
  - 分布式架构下，唯一序列号生成是我们在设计一个系统，尤其是数据库使用分库分表的时候常常会遇见的问题
  - 当分成若干个sharding表后，如何能够快速拿到一个唯一序列号，是经常遇到的问题
- 需求
  - 全局唯一
    支持高并发
    能够体现一定属性
    高可靠，容错单点故障
    高性能
    - 通常分布式系统采用主从模式，一个主机连接多个处理节点，主节点负责分发任务，而子节点负责处理业务，当主节点发生故障时，会导致整个系统发故障，我们把这种故障叫做单点故障
- 业内方案
  - Snowflake 算法
    - 全局唯一ID生成服务
    - 41位的时间序列
    - 10位的机器标识
    - 12位的计数顺序号
    - snowflake的结构如下(每部分用-分开)： 
      0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000
    - 一共加起来刚好64位，为一个Long型
    - 生成的ID整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞
    - 缺点：需要独立的开发和部署
  - Redis生成ID
    - Redis是单线程的，所以也可以用生成全局唯一的ID。可以用Redis的原子操作INCR和INCRBY来实现
    - 可以使用Redis集群来获取更高的吞吐量
    - 可以初始化每台Redis的值分别是1,2,3,4,5，然后步长都是5
    - 比较适合使用Redis来生成每天从0开始的流水号。比如订单号=日期+当日自增长号
    - 需要编码和配置的工作量比较大，多环境运维很麻烦
  - Flicker的解决方案
    - MySQL本身支持auto_increment操作
    - Flicker在解决全局ID生成方案里就采用了MySQL自增长ID的机制（auto_increment + replace into + MyISAM）
  - 其他一些方案
    - 订单号尽可能要多些冗余的业务信息
      - 滴滴：时间+起点编号+车牌号
      - 淘宝订单：时间戳+用户ID
    - 携程方案
      - 以flicker方案为基础进行优化改进。具体实现是，单表递增，内存缓存号段的方式
        - replace to来更新记录来获得唯一id
        - replace into 首先尝试插入数据到表中， 如果发现表中已经有此行数据（根据主键或者唯一索引判断）则先删除此行数据，然后插入新的数据
        - 插入数据的表必须有主键或者是唯一索引！否则的话，replace into 会直接插入数据，这将导致表中出现重复的数据
        - 再用 SELECT id FROM sequenceid WHERE ip = “192.168.1.1”  把它拿回来
      - 但是追根溯源，在原理上，方案还是依靠数据库的特性，每次生成id都要请求db，开销很大
      - 把这个id作为一个号段，而并不是要发出去的序列号
      - 现在的问题就是要解决同一台服务器在高并发场景，让大家顺序拿号，别拿重复，也别漏拿
        - 保持这个号段对象隔离性的问题
          - 当第一次拿回号段id后，扩大1000倍，然后赋值给这个变量atomic，这就是这个号段的第一个号码。

atomic.set(n * 1000);

并且内存里保存一下最大id，也就是这个号段的最后一个号码

currentMaxId = (n + 1) * 1000;

一个号段就形成了。
					- 此时每次有请求来取号时候，判断一下有没有到最后一个号码，没有到，就拿个号，走人

```
					- Long uid = atomic.incrementAndGet();

				- 如果到达了最后一个号码，那么阻塞住其他请求线程，最早的那个线程去db取个号段，再更新一下号段的两个值，就可以了。

	- 美团

		- 用户通过Round-robin的方式调用Leaf Server的各个服务，所以某一个Client获取到的ID序列可能是：1，1001，2001，2，1002，2002……也可能是：1，2，1001，2001，2002，2003，3，4……当某个Leaf Server号段用完之后，下一次请求就会从DB中加载新的号段，这样保证了每次加载的号段是递增的。
		- DB压力
		- 采用了异步更新的策略，同时通过双Buffer的方式，保证无论何时DB出现问题，都能有一个Buffer的号段可以正常对外提供服务
		- 动态调整Step

			- 服务QPS为Q，号段长度为L，号段更新周期为T，那么Q * T = L
			- Leaf本质的需求是希望T是固定的。那么如果L可以和Q正相关的话，T就可以趋近一个定值了
			- Leaf每次更新号段的时候，根据上一次更新号段的周期T和号段长度step，来决定下一次的号段长度nextStep

				- - T < 15min，nextStep = step * 2
```

- 15min < T < 30min，nextStep = step
- T > 30min，nextStep = step / 2

### 高并发系统的设计

- 设置http连接池
  - 如果不采用连接池，每次连接发起Http请求的时候 都会重新建立TCP连接(经历3次握手)，用完就会关闭连接(4次挥手)，如果采用连接池则减少了这部分时间损耗
  - 采用连接池，连接的复用，可以提高并发访问量
  - 降低延迟，支持更大的并发
- 把一些静态资源先加载到浏览器缓存里面
- 可以对服务器端的数据进行压缩
- 反向代理服务器可以保护服务器的安全（服务器的负载均衡）
- NIO模型
  - 解决线程资源受限的方案，实际开发过程中，我们会开多个线程，每个线程都管理着一批连接
  - 处理器访问任何寄存器和 Cache 等封装以外的数据资源都可以当成 I/O 操作，包括内存，磁盘，显卡等外部设备。
- 线程池
  - 设置一个最大线程数量和最小线程数量
  - 阻塞队列的大小要有界
    - 阻塞队列
      - 线程把请求放到阻塞队列里面
  - 线程池的失败策略
- 数据库连接池
- 数据存储部分
  - 数据库的优化，包括合理的事务隔离级别、SQL语句优化、索引的优化
- 缓存
  - 使用缓存，尽量减少数据库 IO
  - 分布式数据库、分布式缓存
- 数据库考虑集群、分库分表。
- 一致性哈希算法实现分布式缓存数据库
- 若有重复数据，布隆过滤器去重

### 消息队列

- 为什么使用消息队列
  - 其实就是问问你消息队列都有哪些使用场景
  - 优点
    - 解耦
      - 如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费
    - 异步
      - 使用 MQ， A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，本地写库要 3ms,A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms
      - BCD 三个系统分别写库要 300ms、450ms、200ms
    - 削峰
      - 如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。
      - 哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。
      - 只要高峰期一过，A 系统就会快速将积压的消息给解决掉
  - 缺点
    - 系统可用性降低
      - MQ 一挂，整套系统崩溃
    - 系统复杂度提高
      - 保证消息没有重复消费
      - 处理消息丢失的情况
      - 等等
    - 一致性问题
      - A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了
  - 特性
    - 单机吞吐量
      - 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景
    - topic 数量对吞吐量的影响
      - topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源
    - 时效性
      - 延迟在 ms 级以内
    - 可用性
      - 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用
    - 消息可靠性
      - 经过参数优化配置，可以做到 0 丢失
    - 功能支持
      - 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用
- 设计消息队列
  - 技术的基本原理、核心组成部分、基本架构构成
  - 支持可伸缩性
    - kafka
      - broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，给 topic 增加 partition，然后做数据迁移，增加机器
  - 落地磁盘
    - 顺序写
  - 可用性
    - kafka 的高可用保障机制
      - 多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。
  - 数据 0 丢失
    - kafka 数据零丢失方案
- 如何保证消息不被重复消费？或者说，如何保证消息消费的幂等性？
  - 先大概说一说可能会有哪些重复消费的问题
    - 这问题通常不是 MQ 自己保证的，是由我们开发来保证的
    - consumer 有些消息处理了，但是没来得及提交 offset
    - Kafka 实际上有个offset的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。
  - 怎么保证幂等性
    - 一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性
    - 几个思路
      - 根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
      - 写 Redis，那没问题了，反正每次都是 set，天然幂等性
      - 生产者发送每条数据的时候，里面加一个全局唯一的 id，消费到了之后，先根据这个 id 去比如 Redis 里查一下
      - 基于数据库的唯一键来保证重复数据不会重复插入多条
- 如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？
  - 数据不能多一条，也不能少一条
    - 不能多
      - 重复消费和幂等性问题
    - 不能少
      - 这数据别搞丢了
  - 消费端弄丢了数据
    - 你消费到了这个消息，然后消费者那边自动提交了 offset，让 Kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢了
    - Kafka 会自动提交 offset，那么只要关闭自动提交 offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢
      - 但是此时确实还是可能会有重复消费，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了
    - 生产环境碰到的一个问题，就是说我们的 Kafka 消费者消费到了数据之后是写到一个内存的 queue 里先缓冲一下，结果有的时候，你刚把消息写入内存 queue，然后消费者会自动提交 offset。然后此时我们重启了系统，就会导致内存 queue 里还没来得及处理的数据就丢失了
  - Kafka 弄丢了数据
    - Kafka 某个 broker 宕机，此时其他的 follower 刚好还有些数据没有同步
    - 此时一般是要求起码设置如下 4 个参数
      - replication.factor
        - 这个值必须大于 1，要求每个 partition 必须有至少 2 个副本
      - min.insync.replicas
        - 这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系
      - producer 端设置 acks=all
        - 要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了
      - producer 端设置 retries=MAX
        - 要求一旦写入失败，就无限重试
    - 这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失
  - 生产者会不会弄丢数据
    - 如果按照上述的思路设置了 acks=all，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了
    - 如果没满足这个条件，生产者会自动不断的重试，重试无限次
- 如何保证消息的顺序性
  - 你在 mysql 里增删改一条数据，对应出来了增删改 3 条 binlog日志，接着这三条 binlog发送到 MQ 里面，再消费出来依次执行
  - 顺序会错乱的场景
    - 生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的
    - 多个线程来并发处理消息
      - 多个线程并发跑的话，顺序可能就乱掉了
  - 解决方案
    - 写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可
- 消息队列的高可用
  - 架构
    - Kafka由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据
    - 天然的分布式消息队列,一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据
  - HA 机制
    - replica（复制品） 副本机制
      - 每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本
      - 所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower
      - 写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可
        - 写数据的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据
    - Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性
- 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？
  - 大量消息在 mq 里积压了几个小时了还没解决
    - 一般这个时候，只能临时紧急扩容了
      - 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉
      - 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量
      - 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue
      - 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据
      - 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。
  - mq 中的消息过期失效了
    - 批量重导
      - 将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来
  - mq 都快写满了
    - 临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧



# 双十一抢购性能瓶颈调优

首先，由于没有限流，超过预期的请求量导致了系统卡顿；其次，基于 Redis 实现的分布式锁分发抢购名额的功能抛出了大量异常；再次，就是我们误判了横向扩容服务可以起到的作用，其实第一波抢购的性能瓶颈是在数据库，横向扩容服务反而又增加了数据库的压力，起到了反作用；最后，就是在服务挂掉的情况下，丢失了异步处理的业务请求。

## 抢购业务流程

在进行具体的性能问题讨论之前，我们不妨先来了解下一个常规的抢购业务流程，这样方便我们更好地理解一个抢购系统的性能瓶颈以及调优过程。

- 用户登录后会进入到商品详情页面，此时商品购买处于倒计时状态，购买按钮处于置灰状态。
- 当购买倒计时间结束后，用户点击购买商品，此时用户需要排队等待获取购买资格，如果没有获取到购买资格，抢购活动结束，反之，则进入提交页面。
- 用户完善订单信息，点击提交订单，此时校验库存，并创建订单，进入锁定库存状态，之后，用户支付订单款。
- 当用户支付成功后，第三方支付平台将产生支付回调，系统通过回调更新订单状态，并扣除数据库的实际库存，通知用户购买成功。

## 抢购系统中的性能瓶颈

熟悉了一个常规的抢购业务流程之后，我们再来看看抢购中都有哪些业务会出现性能瓶颈。

### 1. 商品详情页面

如果你有过抢购商品的经验，相信你遇到过这样一种情况，在抢购马上到来的时候，商品详情页面几乎是无法打开的。

这是因为大部分用户在抢购开始之前，会一直疯狂刷新抢购商品页面，尤其是倒计时一分钟内，查看商品详情页面的请求量会猛增。此时如果商品详情页面没有做好，就很容易成为整个抢购系统中的第一个性能瓶颈。

类似这种问题，我们通常的做法是提前将整个抢购商品页面生成为一个静态页面，并 push 到 CDN 节点，并且在浏览器端缓存该页面的静态资源文件，通过 CDN 和浏览器本地缓存这两种缓存静态页面的方式来实现商品详情页面的优化。

### 2. 抢购倒计时

在商品详情页面中，存在一个抢购倒计时，这个倒计时是服务端时间的，初始化时间需要从服务端获取，并且在用户点击购买时，还需要服务端判断抢购时间是否已经到了。

如果商品详情每次刷新都去后端请求最新的时间，这无疑将会把整个后端服务拖垮。我们可以改成初始化时间从客户端获取，每隔一段时间主动去服务端刷新同步一次倒计时，这个时间段是随机时间，避免集中请求服务端。这种方式可以避免用户主动刷新服务端的同步时间接口。

### 3. 获取购买资格

可能你会好奇，在抢购中我们已经通过库存数量限制用户了，那为什么会出现一个获取购买资格的环节呢？

我们知道，进入订单详情页面后，需要填写相关的订单信息，例如收货地址、联系方式等，在这样一个过程中，很多用户可能还会犹豫，甚至放弃购买。如果把这个环节设定为一定能购买成功，那我们就只能让同等库存的用户进来，一旦用户放弃购买，这些商品可能无法再次被其他用户抢购，会大大降低商品的抢购销量。

增加购买资格的环节，选择让超过库存的用户量进来提交订单页面，这样就可以保证有足够提交订单的用户量，确保抢购活动中商品的销量最大化。

获取购买资格这步的并发量会非常大，还是基于分布式的，通常我们可以通过 Redis 分布式锁来控制购买资格的发放。

### 4. 提交订单

由于抢购入口的请求量会非常大，可能会占用大量带宽，为了不影响提交订单的请求，我建议将提交订单的子域名与抢购子域名区分开，分别绑定不同网络的服务器。

用户点击提交订单，需要先校验库存，库存足够时，用户先扣除缓存中的库存，再生成订单。如果校验库存和扣除库存都是基于数据库实现的，那么每次都去操作数据库，瞬时的并发量就会非常大，对数据库来说会存在一定的压力，从而会产生性能瓶颈。与获取购买资格一样，我们同样可以通过分布式锁来优化扣除消耗库存的设计。

由于我们已经缓存了库存，所以在提交订单时，库存的查询和冻结并不会给数据库带来性能瓶颈。但在这之后，还有一个订单的幂等校验，为了提高系统性能，我们同样可以使用分布式锁来优化。

而保存订单信息一般都是基于数据库表来实现的，在单表单库的情况下，碰到大量请求，特别是在瞬时高并发的情况下，磁盘 I/O、数据库请求连接数以及带宽等资源都可能会出现性能瓶颈。此时我们可以考虑对订单表进行分库分表，通常我们可以基于 userid 字段来进行 hash 取模，实现分库分表，从而提高系统的并发能力。

### 5. 支付回调业务操作

在用户支付订单完成之后，一般会有第三方支付平台回调我们的接口，更新订单状态。

除此之外，还可能存在扣减数据库库存的需求。如果我们的库存是基于缓存来实现查询和扣减，那提交订单时的扣除库存就只是扣除缓存中的库存，为了减少数据库的并发量，我们会在用户付款之后，在支付回调的时候去选择扣除数据库中的库存。

此外，还有订单购买成功的短信通知服务，一些商城还提供了累计积分的服务。

在支付回调之后，我们可以通过异步提交的方式，实现订单更新之外的其它业务处理，例如库存扣减、积分累计以及短信通知等。通常我们可以基于 MQ 实现业务的异步提交。

## 性能瓶颈调优

了解了各个业务流程中可能存在的性能瓶颈，我们再来讨论下商城基于常规优化设计之后，还可能出现的一些性能问题，我们又该如何做进一步调优。

### 1. 限流实现优化

限流是我们常用的兜底策略，无论是倒计时请求接口，还是抢购入口，系统都应该对它们设置最大并发访问数量，防止超出预期的请求集中进入系统，导致系统异常。

通常我们是在网关层实现高并发请求接口的限流，如果我们使用了 Nginx 做反向代理的话，就可以在 Nginx 配置限流算法。Nginx 是基于漏桶算法实现的限流，这样做的好处是能够保证请求的实时处理速度。

Nginx 中包含了两个限流模块：[ngx_http_limit_conn_module](http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html) 和 [ngx_http_limit_req_module](http://nginx.org/en/docs/http/ngx_http_limit_req_module.html)，前者是用于限制单个 IP 单位时间内的请求数量，后者是用来限制单位时间内所有 IP 的请求数量。以下分别是两个限流的配置：

```
limit_conn_zone $binary_remote_addr zone=addr:10m;
 
server {
    location / {
        limit_conn addr 1;
    }
http {
    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;
    server {
        location / {
            limit_req zone=one burst=5 nodelay;
        }
} 
```

在网关层，我们还可以通过 lua 编写 OpenResty 来实现一套限流功能，也可以通过现成的 Kong 安装插件来实现。除了网关层的限流之外，我们还可以基于服务层实现接口的限流，通过 Zuul RateLimit 或 Guava RateLimiter 实现。

### 2. 流量削峰

瞬间有大量请求进入到系统后台服务之后，首先是要通过 Redis 分布式锁获取购买资格，这个时候我们看到了大量的“JedisConnectionException Could not get connection from pool”异常。

这个异常是一个 Redis 连接异常，由于我们当时的 Redis 集群是基于哨兵模式部署的，哨兵模式部署的 Redis 也是一种主从模式，我们在写 Redis 的时候都是基于主库来实现的，在高并发操作一个 Redis 实例就很容易出现性能瓶颈。

你可能会想到使用集群分片的方式来实现，但对于分布式锁来说，集群分片的实现只会增加性能消耗，这是因为我们需要基于 Redission 的红锁算法实现，需要对集群的每个实例进行加锁。

后来我们使用 Redission 插件替换 Jedis 插件，由于 Jedis 的读写 I/O 操作还是阻塞式的，方法调用都是基于同步实现，而 Redission 底层是基于 Netty 框架实现的，读写 I/O 是非阻塞 I/O 操作，且方法调用是基于异步实现。

但在瞬时并发非常大的情况下，依然会出现类似问题，此时，我们可以考虑在分布式锁前面新增一个等待队列，减缓抢购出现的集中式请求，相当于一个流量削峰。当请求的 key 值放入到队列中，请求线程进入阻塞状态，当线程从队列中获取到请求线程的 key 值时，就会唤醒请求线程获取购买资格。

### 3. 数据丢失问题

无论是服务宕机，还是异步发送给 MQ，都存在请求数据丢失的可能。例如，当第三方支付回调系统时，写入订单成功了，此时通过异步来扣减库存和累计积分，如果应用服务刚好挂掉了，MQ 还没有存储到该消息，那即使我们重启服务，这条请求数据也将无法还原。

重试机制是还原丢失消息的一种解决方案。在以上的回调案例中，我们可以在写入订单时，同时在数据库写入一条异步消息状态，之后再返回第三方支付操作成功结果。在异步业务处理请求成功之后，更新该数据库表中的异步消息状态。

假设我们重启服务，那么系统就会在重启时去数据库中查询是否有未更新的异步消息，如果有，则重新生成 MQ 业务处理消息，供各个业务方消费处理丢失的请求数据。

### 总结

减少抢购中操作数据库的次数，缩短抢购流程，是抢购系统设计和优化的核心点。

抢购系统的性能瓶颈主要是在数据库，即使我们对服务进行了横向扩容，当流量瞬间进来，数据库依然无法同时响应处理这么多的请求操作。我们可以对抢购业务表进行分库分表，通过提高数据库的处理能力，来提升系统的并发处理能力。

除此之外，我们还可以分散瞬时的高并发请求，流量削峰是最常用的方式，用一个队列，让请求排队等待，然后有序且有限地进入到后端服务，最终进行数据库操作。当我们的队列满了之后，可以将溢出的请求放弃，这就是限流了。通过限流和削峰，可以有效地保证系统不宕机，确保系统的稳定性。



# 设计一个高并发、高可用秒杀系统

作者：腾讯技术工程
链接：https://zhuanlan.zhihu.com/p/109742840
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



## **秒杀系统的难点**

- 友好的用户体验

- - 用户不能接受破窗的体验，例如：系统超时、系统错误的提示，或者直接 404 页面

- 瞬时高并发流量的挑战

- - 木桶短板理论，整个系统的瓶颈往往都在 DB，如何设计出高并发、高可用系统？

## **如何设计**

![img](https://pic1.zhimg.com/v2-e3a128f561bb4739c156ed6e392cb426_b.jpg)

上图是一个典型的互联网业务，用户完成一个写操作，一般会通过接入层和逻辑层，这里的服务都是无状态，可以通过平行拓展去解决高并发的问题；到了 db 层，必须要落到介质中，可以是磁盘/ssd/内存，如果出现 key 的冲突，会有一些并发控制技术，例如 cas/加锁/串行排队等。

### **直筒型**

直筒型业务，指的是用户请求 1:1 的洞穿到 db 层，如下图所示。在比较简单的业务中，才会采用这个模型。随着业务规模复杂度上来，一定会有 db 和逻辑层分离、逻辑层和接入层分离。

![img](https://pic2.zhimg.com/v2-15f4981679385991797c2c435160d2dd_b.jpg)

### **漏斗型**

漏斗型业务，指的是，用户的请求，从客户端到 db 层，层层递减，递减的程度视业务而定。例如当 10w 人去抢 1 个物品时，db 层的请求在个位数量级，这就是比较理想的模型。如下图所示

![img](https://picb.zhimg.com/v2-243232ef478e347dd4d594af21a03d8a_b.jpg)

这个模型，是高并发的基础，翻译一下就是下面这些：

- 及早发现，及早拒绝
- Fast Fail
- 前端保护后端
   

### **如何实现漏斗型系统**

漏斗型系统需要从产品策略/客户端/接入层/逻辑层/DB 层全方位立体的设计。

![img](https://pic4.zhimg.com/v2-e0a777b9cacabc2e32df83f4e7d6d829_b.jpg)

### **产品策略**

- 轻重逻辑分离，以秒杀为例，将抢到和到账分开；

- - 抢到，是比较轻的操作，库存扣成功后，就可以成功了
  - 到账，是比较重的操作，需要涉及到到事务操作
     

- 用户分流，以整点秒杀活动为例，在 1 分钟内，陆续对用户放开入口，将所有用户请求打散在 60s 内，请求就可以降一个数量级
   

- 页面简化，在秒杀开始的时候，需要简化页面展示，该时刻只保留和秒杀相关的功能。例如，秒杀开始的时候，页面可以不展示推荐的商品。
   

### **客户端**

- 重试策略非常关键，如果用户秒杀失败了，频繁重试，会加剧后端的雪崩。如何重试呢？根据后端返回码的约定，有两种方法：
   

- - 不允许重试错误，此时 ui 和文案都需要有一个提示。同时不允许重试
  - 可重试错误，需要策略重试，例如二进制退避法。同时文案和 ui 需要提示。
     

- ui 和文案，秒杀开始前后，用户的所有异常都需要有精心设计的 ui 和文案提示。例如：【当前活动太火爆，请稍后再重试】【你的货物堵在路上，请稍后查看】等
   

- 前端随机丢弃请求可以作为降级方案，当用户流量远远大于系统容量时，人工下发随机丢弃标记，用户本地客户端开始随机丢弃请求。
   

### **接入层**

- 所有请求需要鉴权，校验合法身份
   

- - 如果是长链接的服务，鉴权粒度可以在 session 级别；如果是短链接业务，需要应对这种高并发流量，例如 cache 等

- 根据后端系统容量，需要一个全局的限流功能，通常有两种做法：
   

- - 设置好 N 后，动态获取机器部署情况 M，然后下发单机限流值 N/M。要求请求均匀访问，部署机器统一。
  - 维护全局 key，以时间戳建 key。有热 key 问题，可以通过增加更细粒度的 key 或者定时更新 key 的方法。
     

- 对于单用户/单 ip 需要频控，主要是防黑产和恶意用户。如果秒杀是有条件的，例如需要完成 xxx 任务，解锁资格，对于获得资格的步骤，可以进行安全扫描，识别出黑产和恶意用户。
   

### **逻辑层**

- 逻辑层首先应该进入校验逻辑，例如参数的合法性，是否有资格，如果失败的用户，快速返回，避免请求洞穿到 db。
   

- 异步补单，对于已经扣除秒杀资格的用户，如果发货失败后，通常的两种做法是：
   

- - 事务回滚，回滚本次行为，提示用户重试。这个代价特别大，而且用户重试和前面的重试策略结合的话，用户体验也不大流畅。
  - 异步重做，记录本次用户的 log，提示用户【稍后查看，正在发货中】，后台在峰值过后，启动异步补单。需要服务支持幂等
     

- 对于发货的库存，需要处理热 key。通常的做法是，维护多个 key，每个用户固定去某个查询库存。对于大量人抢红包的场景，可以提前分配。
   

### **存储层**

对于业务模型而言，对于 db 的要求需要保证几个原则：

- 可靠性
   

- - 主备：主备能互相切换，一般要求在同城跨机房
     
  - 异地容灾：当一地异常，数据能恢复，异地能选主
     
  - 数据需要持久化到磁盘，或者更冷的设备
     

- 一致性
   

- - 对于秒杀而言，需要严格的一致性，一般要求主备严格的一致。

## **实践——微视集卡瓜分系统**

微视集卡瓜分项目属于微视春节项目之一。用户的体验流程如下：

![img](https://pic2.zhimg.com/v2-9bde162bee150dc33d61df71ffb71724_b.jpg)

### **架构图**

![img](https://pic2.zhimg.com/v2-60b7f118b41855263cd1e4d434285b4d_b.jpg)

- 客户端主要是微视主 app 和 h5 页面，主 app 是入口，h5 页面是集卡活动页面和瓜分页面。
   
- 逻辑部分为分：发卡来源、集卡模块、奖品模块，发卡来源主要是任务模块；集卡模块主要由活动模块和集卡模块组成。瓜分部分主要在活动控制层。
   
- 奖品模块主要是发钱和其他奖品。
   

### **瓜分降级预案**

为了做好瓜分时刻的高并发，对整个系统需要保证两个重要的事情：

- 全链路梳理，包括调用链的合理性和时延设置
   
- 降级服务预案分析，提升系统的鲁棒性
   

如下图所示，是针对瓜分全链路调用分析如下图，需要特别说明的几点：

![img](https://picb.zhimg.com/v2-2357aac83e60101d1b143f634725b5b2_b.jpg)

- 时延很重要，需要全链路分析。不但可以提高吞吐量，而且可以快速暴露系统的瓶颈。
   
- 峰值时刻，补单逻辑需要关闭，避免加剧雪崩。
   

我们的降级预案大概如下：

- 一级预案，瓜分时刻前后 5 分钟自动进入：
   

- - 入口处 1 分钟内陆续放开入口倒计时，未登录用户不弹入口
     
  - 主会场排队，以进入主会场 100wqps 为例，超过了进入排队，由接入层频控控制
     
  - 拉取资格接口排队，拉取资格接口 100wqps，超过了进入排队，由接入层频控控制
     
  - 抢红包排队，抢红包 100wqps，超过了进入排队，由接入层频控控制
     
  - 红包到账排队，如果资格扣除成功，现金发放失败，进入排队，24 小时内到账。异步补单
     
  - 入口处调用后端非关键 rpc:ParticipateStatus，手动关闭
     
  - 异步补单逻辑关闭。
     

- 二级预案，后端随机丢请求，接入层频控失效或者下游服务过载，手动开启进入
   

- 三级预案，前端随机丢请求，后端服务过载或者宕机进入。手动开启
   

综上，整个瓜分时刻体验如下所示：

![img](https://pic4.zhimg.com/v2-4551c7d39e776fe0d494c4cc6005fa17_b.jpg)

回顾下漏斗模型，总结下整个实践：

![img](https://picb.zhimg.com/v2-db80d36c4a81173ec75db7fe88b25a75_b.jpg)





降级开关设计，过载感知，分流策略设计



## 游戏服务器

游戏服务器特征：

长期运行，要求有一定的稳定性和性能。如果需要动态扩容来提高承载能力还要考虑到维护部署的方便性。如果是手游服务器还要考虑到弱联网，保证通信交互的顺畅。

对于服务端需求主要有以下几点：

1：玩家交互数据的广播，同步

2：玩家数据存储

3：做好验证，防止外挂

4：交互的流畅性

为了满足以上需求，我们得考虑服务器的内存，cpu，带宽等因素，来制定最优的服务器开发和部署方案。



**第三代网游服务器**

![img](https://pic1.zhimg.com/80/v2-5c80ce49a944b07ec87c22c9dfbde44a_1440w.jpg)



网关部分分离成单端的gate服务器，DB部分分离为DB服务器，把网络功能单独提取出来，让用户统一去连接一个网关服务器，再有网关服务器转发数据到后端游戏服务器。而游戏服务器之间数据交换也统一连接到网管进行交换。所有有DB交互的，都连接到DB服务器来代理处理。



上面版本的进化版

![img](https://picb.zhimg.com/80/v2-cf4bcbf82399e1d4abaea41d79c1d02d_1440w.jpg)

每个相同的模块分布到一台服务器处理，多组服务器集群共同组成一个游戏服务端。一般地，我们可以将一个组内的服务器简单地分成两类：场景相关的(如：行走、战斗等)以及场景不相关的(如：公会聊天、不受区域限制的贸易等)。经常可以见到的一种方案是：gate服务器、场景服务器、非场景服务器、聊天管理器、AI服务器以及数据库代理服务器。



#### 成熟形态的服务器框架

逻辑服务器的负载均摊方法一：按照功能划分多个服务器进程



![img](https://pic2.zhimg.com/80/v2-83d176b88c6ffcf64211a8d34ba9d842_1440w.png)





逻辑服务器的负载均摊方法二：按照场景划分多个服务器进程



![img](https://pic3.zhimg.com/80/v2-3c87d414d04a2ab57c24f6bb78af5d45_1440w.png)



对游戏服务器历史有了基本了解后，成熟形态的游戏服务器很容易理解。简单来说，就是把逻辑服务器单个进程的压力分摊到多个服务器。

难点在逻辑的设计上，要像做手术一样把本来是一体的功能切开，并抽象出若干个API来保持联系（服务器之间是TCP连接）。

在分解时，**要找联系相对最薄弱的环节入手**，比如场景和场景之间分开、单独抽出聊天服务、组队服务、好友服务。

无论如何分解，最终结果只能是有限个服务。而且分解的越细，开发难度就越大。因为跨服务器逻辑是把简单的同步逻辑变成了异步Callback逻辑，而且容易出现时序问题等不易测试的问题。

单个场景服务几乎是无法分解的。分解单个场景难度巨大以至于出现了BigWorld引擎来专门的解决场景分割问题，后面会谈到。



这种成熟形态的游戏服务器已经能满足现实中99%的频繁交互类网游需求，是大型MMO端游、页游的主流形式。

当然有实力的公司在这个基础上会做很多改动，实现动态开辟副本、相位技术等等，但是万变不离其宗，其本质和上图没有什么区别。



#### 附：开房间式的网络游戏

开房间式的网络游戏也是游戏的一个重要分支，英雄联盟、DOTA、很多手游例如皇室战争、王者荣耀等等。

这种游戏房间之间几乎没有交互，只有大厅内有交互，可以理解为原始形态的游戏服务器的平行扩展。

房间式游戏扩展难度较小，只是需要根据玩家数量动态扩展游戏房间的数量、服务器数量。很像网站的架构。



![img](https://pic2.zhimg.com/80/v2-e465c12055355c1170130c7c9602a9d2_1440w.png)





这种游戏架构最最适合放在云平台上，设计合理的话，它可能遇到的问题和大型网站几乎一模一样。不需要特别的讨论它们。

只是，**毕竟游戏不都是开房间的玩法**。



#### 小结：游戏服务器框架特点

1、真正的数据都在内存中，数据库性能不那么重要

· 注：很多大型游戏采用了共享内存，避免宕机时损失过大。

2、单CPU性能比CPU数量重要的多。

3、目前有很多游戏，特别是手游，使用Redis读写代替内存读写，甚至也有用Mongo的。

4、开新服、旧区合服的情况，非常适合云平台。