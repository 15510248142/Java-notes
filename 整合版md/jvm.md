## 为什么要学习 Java虚拟机？

- 学习 Java虚拟机，可以针对自己的应用，最优化匹配运行参数。
- Java 虚拟机拥有当前最前沿、最成熟的垃圾回收算法实现，以及即时编译器实现。





## Java代码是怎么运行的

- JRE，也就是 Java 运行时环境。

  - JRE 仅包含运行 Java 程序的必需组件，包括 Java 虚拟机以及 Java 核心类库等
  - JDK（Java 开发工具包）同样包含了 JRE，并且还附带了一系列开发、诊断工具。

- 汇编代码

  - ;最左列是偏移；中间列是给机器读的机器码；最右列是给人读的汇编代码
  - 0x00: 55 push rbp

- 一旦一个程序被转换成Java 字节码，那么它便可以在不同平台（Windows_x64、Linux_aarch64）上的虚拟机实现里运行。这也就是我们经常说的“一次编写，到处运行”。

- 另外一个好处是它带来了一个托管环境（Managed Runtime）

  - 能够代替我们处理一些代码中冗长而且容易出错的部分
  - 最广为人知的当属自动内存管理与垃圾回收

- Java 虚拟机具体是怎样运行 Java 字节码的

  - 虚拟机
    - 执行 Java 代码首先需要将它编译而成的 class 文件加载到 Java 虚拟机中。加载后的 Java 类会被存放于方法区（Method Area）中。实际运行时，虚拟机会执行方法区内的代码。
    - 每当调用进入一个 Java 方法，Java 方法栈中生成一个栈帧，用以存放局部变量以及字节码的操作数
  - 底层硬件
    - Java 字节码无法直接执行。因此，Java 虚拟机需要将字节码翻译成机器码。
      - 第一种是解释执行，即逐条将字节码翻译成机器码并执行；
      - 第二种是即时编译（JIT），即将一个方法中包含的所有字节码编译成机器码后再执行。
    - 前者的优势在于无需等待编译，而后者的优势在于实际运行速度更快。
    - HotSpot 默认采用混合模式，它会先解释执行字节码，而后将其中反复执行的热点代码，以方法为单位进行即时编译

- 为了满足不同用户场景的需要，HotSpot 内置了多个即时编译器：C1、C2 和 Graal。

  - C1 又叫做Client 编译器，面向的是对启动性能有要求的客户端 GUI 程序，采用的优化手段相对简单，因此编译时间较短。
  - C2 又叫做 Server 编译器，面向的是对峰值性能有要求的服务器端程序，采用的优化手段相对复杂，因此编译时间较长，但同时生成代码的执行效率较高。
  - 从 Java 7 开始，HotSpot 默认采用分层编译的方式：热点方法首先会被 C1 编译，而后热点方法中的热点会进一步被 C2 编译。
  - HotSpot 的即时编译是放在额外的编译线程中进行的。按 1:2 的比例配置给 C1 及 C2 编译器。

  



## Java的基本类型

- Java 虚拟机的 boolean 类型
  - 在 Java 虚拟机规范中，boolean 类型则被映射成 int 类型。具体来说，“true”被映射为整数 1，而“false”被映射为整数 0。
    - if（fag）比较时ifeq指令做是否为零判断
    - if（true == fag）比较时if_cmpne做整数比较
  - boolean 和 char 是唯二的无符号类型。
    - char 类型的取值范围则是 [0, 65535]。通常我们可以认定 char 类型的值为非负数。这种特性十分有用，比如说作为数组索引等。
- Java 虚拟机每调用一个 Java 方法，便会创建一个栈帧。我只讨论供解释器使用的解释栈帧
  - 这种栈帧有两个主要的组成部分，分别是局部变量区，以及字节码的操作数栈。
  - 这里的局部变量是广义的，除了普遍意义下的局部变量之外，它还包含实例方法的“this 指针”以及方法所接收的参数。
  - 在 Java 虚拟机规范中，局部变量区等价于一个数组
    - 除了long、double 值需要用两个数组单元来存储之外，其他基本类型以及引用类型的值均占用一个数组单元。
    - boolean、byte、char、short 这四种类型，在栈上占用的空间和 int 是一样的
    - 在 64 位的HotSpot 中，他们将占 8 个字节。
    - 这种情况仅存在于局部变量，而并不会出现在存储于堆中的字段或者数组元素上。对于byte、char 以及 short 这三种类型的字段或者数组单元，它们在堆上占用的空间分别为一字节、两字节，以及两字节，
    - 因此，当我们将一个 int 类型的值，存储到这些类型的字段或数组时，相当于做了一次隐式的掩码操作
      - 举例来说，当我们把 0xFFFFFFFF（-1）存储到一个声明为 char 类型的字段里时，由于该字段仅占两字节，所以高两位的字节便会被截取掉，最终存入“\uFFFF”。
    - boolean 字段和 boolean 数组则比较特殊
      - 为了保证堆中的 boolean 值是合法的，HotSpot 在存储时显式地进行掩码操作，也就是说，只取最后一位的值存入 boolean 字段或数组中。
  - Java 虚拟机的算数运算几乎全部依赖于操作数栈
    - 也就是说，我们需要将堆中的 boolean、byte、char 以及 short 加载到操作数栈上，而后将栈上的值当成 int 类型来运算。
    - 对于 boolean、char 这两个无符号类型来说，加载伴随着零扩展。举个例子，char 的大小为两个字节。在加载时 char 的值会被复制到 int 类型的低二字节，而高二字节则会用 0 来填充
    - 对于 byte、short 这两个类型来说，加载伴随着符号扩展。举个例子，short 的大小为两个字节。在加载时 short 的值同样会被复制到 int 类型的低二字节。如果该 short 值为非负数，即最高位为 0，那么该 int 类型的值的高二字节会用 0 来填充，否则用 1 来填充。
- Unsafe就是一些不被虚拟机控制的内存操作的合集。
  - CAS可以理解为原子性的写操作，这个概念来自于底层CPU指令。Unsafe提供了一些cas的Java接口，在即时编译器中我们会将对这些接口的调用替换成具体的CPU指令。





## Java虚拟机是如何加载 Java类的

- 通常类加载机制有三个基本特征

  - 双亲委派模型。但不是所有类加载都遵守这个模型，有的时候，启动类加载器所加载的类型，是可能要加载用户代码的，比如 JDK 内部的 ServiceProvider/ServiceLoader机制，用户可以在标准 API 框架上，提供自己的实现，JDK 也需要提供些默认的参考实现。 例如，Java 中 JNDI、JDBC、文件系统、Cipher 等很多方面，都是利用的这种机制，这种情况就不会用双亲委派模型去加载，而是利用所谓的上下文加载器
  - 可见性，子类加载器可以访问父加载器加载的类型，但是反过来是不允许的，不然，因为缺少必要的隔离，我们就没有办法利用类加载器去实现容器的逻辑
  - 单一性，由于父加载器的类型对于子加载器是可见的，所以父加载器中加载过的类型，就不会在子加载器中重复加载。但是注意，类加载器“邻居”间，同一类型仍然可以被加载多次，因为互相并不可见

- Java 的基本类型，它们是由 Java 虚拟机预先定义好的。

- 引用类型，Java 将其细分为四种：类、接口、数组类和泛型参数

  - 泛型参数会在编译过程中被擦除
  - 数组类是由 Java 虚拟机直接生成的，其他两种则有对应的字节流。
  - 字节流，最常见的形式要属由 Java 编译器生成的 class 文件
  - 这些不同形式的字节流，都会被加载到 Java 虚拟机中，成为类或接口。
  - 无论是直接生成的数组类，还是加载的类，Java 虚拟机都需要对其进行链接和初始化。
  - 下面我就用“类”来统称它们

- 加载

  - 查找字节流，并且据此创建类的过程
  - 对于数组类来说，它并没有对应的字节流，而是由 Java 虚拟机直接生成的。对于其他的类来说，Java 虚拟机则需要借助类加载器来完成查找字节流的过程。
  - 除了启动类加载器之外，其他的类加载器都是 java.lang.ClassLoader 的子类
  - 类加载器
    - 启动类加载器、扩展类加载器、应用类加载器
      - 扩展类加载器的父类加载器是启动类加载器。它负责加载相对次要、但又通用的类	
        - 比如存放在JRE 的 lib/ext 目录下 jar 包中的类
      - 应用类加载器的父类加载器则是扩展类加载器。它负责加载应用程序路径下的类	
        - 指虚拟机参数 -cp/-classpath、系统变量 java.class.path 或环境变量 CLASSPATH 所指定的路径
    - 除了加载功能之外，类加载器还提供了命名空间的作用	
      - 在 Java 虚拟机中，类的唯一性是由类加载器实例以及类的全名一同确定的。借助这一特性，来运行同一个类的不同版本。

- 链接

  - 将创建成的类合并至 Java 虚拟机中，使之能够执行的过程。它可分为验证、准备以及解析三个阶段。
  - 链接时取得的不是被加载类的地址，而且被加载类所调用的其它方法的地址
  - 准备
    - 为被加载类的静态字段分配内存
    - 构造其他跟类层次相关的数据结构，比如说用来实现虚方法的动态绑定的方法表。
      - Java中所有的非私有实例方法，都算是虚方法。
  - 解析
    - 将这些符号引用解析成为实际引用
    - 举例来说，对于一个方法调用，编译器会生成一个包含目标方法所在类的名字、目标方法的名字、接收参数类型以及返回值类型的符号引用，来指代所要调用的方法
    - 如果符号引用指向一个未被加载的类，或者未被加载类的字段或方法，那么解析将触发这个类的加载（但未必触发这个类的链接以及初始化。）

- 初始化

  - 为标记为常量值的字段赋值，以及执行 < clinit > 方法的过程。Java 虚拟机会通过加锁来确保类的 < clinit > 方法仅被执行一次。

    - 如果直接赋值的静态字段被 fnal 所修饰，并且它的类型是基本类型或字符串时，该字段便会被 Java 编译器标记成常量值，初始化直接由 Java 虚拟机完成
    - 除此之外的直接赋值操作，以及所有静态代码块中的代码，则会被 Java 编译器置于同一方法中，并把它命名为<clinit>。

  - 类的初始化何时会被触发呢？

    - 当虚拟机启动时，初始化用户指定的主类；

    - new 指令，初始化 new 指令的目标类

    - 遇到调用静态方法的指令，初始化该静态方法所在的类

    - 遇到访问静态字段的指令，初始化该静态字段所在的类

      - ```java
        // 只有当调用Singleton.getInstance 时，程序才会访问 LazyHolder.INSTANCE ，才会触发对 LazyHolder 的初始化，继而新建一个 Singleton 的实例。
        // 由于类初始化是线程安全的，并且仅被执行一次，因此程序可以确保多线程环境下有且仅有一个Singleton 实例。
        public class Singleton {
         private Singleton() {}
         private satic class LazyHolder {
         satic fnal Singleton INSTANCE = new Singleton();
         }
         public satic Singleton getInsance() {
         return LazyHolder.INSTANCE;
         }
        }
        ```

    - 子类的初始化会触发父类的初始化

    - 接口定义了 default 方法

    - 反射调用

    - 初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。

- 谈到类加载器，绕不过的一个话题是自定义类加载器，常见的场景有

  - 实现类似进程内隔离，类加载器实际上用作不同的命名空间，以提供类似容器、模块化的效果。例如，两个模块依赖于某个类库的不同版本，如果分别被不同的容器加载，就可以互不干扰。这个方面的集大成者是Java EE和OSGI、JPMS等框架。
  - 应用需要从不同的数据源获取类定义信息，例如网络数据源，而不是本地文件系统。
  - 或者是需要自己操纵字节码，动态修改或者生成类型





## JVM是如何执行方法调用的

- 通常来说，之所以不提倡可变长参数方法的重载，是因为 Java 编译器可能无法决定应该调用哪个目标方法。

- **重载**

  - 在 Java 程序里，如果同一个类中出现多个名字相同，并且参数类型相同的方法，那么它无法通过编译。也就是说，在正常情况下，如果我们想要在同一个类中定义名字相同的方法，那么它们的参数类型必须不同。

  - 这个限制可以通过字节码工具绕开。也就是说，在编译完成之后，我们可以再向 class 文件中添加方法名和参数类型相同，而返回类型不同的方法。

  - 重载的方法在编译过程中即可完成识别

  - Java 编译器会根据所传入参数的声明类型（注意与实际类型区分）来选取重载方法。

  - ```java
    // 选取的过程共分为三个阶段：
    // 		不考虑对基本类型自动装拆箱，以及可变长参数的情况下选取重载方法；
    // 		在允许自动装拆箱，但不允许可变长参数的情况下选取重载方法；
    // 		在允许自动装拆箱以及可变长参数的情况下选取重载方法。
    
    // 当传入 null 时，它既可以匹配第一个方法中声明为 Object 的形式参数，也可以匹配第二个方法中声明为 String 的形式参数。由于 String 是 Object 的子类，因此 Java 编译器会认为第二个方法更为贴切。
    
    void invoke(Object obj, Object... args) { ... }
    void invoke(String s, Object obj, Object... args) { ... }
    invoke(null, 1); // 调用第二个 invoke 方法
    invoke(null, 1, 2); // 调用第二个 invoke 方法
    invoke(null, new Object[]{1}); // 只有手动绕开可变长参数的语法糖，
     // 才能调用第一个 invoke 方法
    ```



- **重写**

  - 如果子类定义了与父类中非私有方法同名的方法，而且这两个方法的参数类型相同，那么这两个方法之间又是什么关系呢？
  - 如果这两个方法都是静态的，那么子类中的方法隐藏了父类中的方法。如果这两个方法都不是静态的，且都不是私有的，那么子类的方法重写了父类中的方法。
  - 方法重写，正是多态最重要的一种体现方式：它允许子类在继承父类部分功能的同时，拥有自己独特的行为。
  - 重写调用会根据调用者的动态类型，来选取实际的目标方法。

- **JVM 的静态绑定和动态绑定**

  - Java 虚拟机识别方法的关键在于类名、方法名以及方法描述符（方法描述符，它是由方法的参数类型以及返回类型所构成）
    - 同一个类中，如果同时出现多个名字相同且描述符也相同的方法，那么 Java 虚拟机会在类的验证阶段报错。
  - 由于对重载方法的区分在编译阶段已经完成，我们可以认为 Java 虚拟机不存在重载这一概念
  - Java 虚拟机中关于方法重写的判定同样基于方法描述符。
    - 如果子类定义了与父类中非私有、非静态方法同名的方法，那么只有当这两个方法的参数类型以及返回类型一致，Java 虚拟机才会判定为重写
  - 重载也被称为静态绑定，重写则被称为动态绑定
    - 并非完全正确。重载方法可能被它的子类所重写，因此 Java 编译器会将所有对非私有实例方法的调用编译为需要动态绑定的类型
    - 确切地说。静态绑定指的是在解析时便能够直接识别目标方法的情况，而动态绑定则指的是需要在运行过程中根据调用者的动态类型来识别目标方法的情况。

- **调用指令的符号引用**

  - > 1. invokestatic：用于调用静态方法。
    > 2. invokespecial：用于调用私有实例方法、构造器，以及使用 super 关键字调用父类的实例方法或构造器，和所实现接口的默认方法。
    > 3. invokevirtual：用于调用非私有实例方法。
    > 4. invokeinterface：用于调用接口方法。
    > 5. invokedynamic：用于调用动态方法。

  - 在执行使用了符号引用的字节码前，Java 虚拟机需要解析这些符号引用，并替换为实际引用。

    - 对于可以静态绑定的方法调用而言，实际引用是一个指向方法的指针。
    - 对于需要动态绑定的方法调用而言，实际引用则是一个方法表的索引。

  - Java识别方法是在java代码——>字节流class编译阶段的。

  - Jvm识别方法是在字节码class——>机器码阶段的。也就是加载，链接，初始化

- **虚方法调用**

  - Java 里所有非私有实例方法调用都会被编译成 invokevirtual 指令，而接口方法调用都会被编译成 invokeinterface 指令。这两种指令，均属于 Java 虚拟机中的虚方法调用
  - 在绝大多数情况下，Java 虚拟机需要根据调用者的动态类型，来确定虚方法调用的目标方法
  - 这个过程我们称之为动态绑定。Java 虚拟机中采取了一种用空间换取时间的策略来实现动态绑定，它为每个类生成一张方法表，用以快速定位目标方法

- **方法表**

  - 类的准备阶段，它除了为静态字段分配内存之外，还会构造与该类相关联的方法表。
  - 方法表本质上是一个数组，每个数组元素指向一个当前类及其祖先类中非私有的实例方法
  - 方法表满足两个特质：其一，子类方法表中包含父类方法表中的所有方法；其二，子类方法在方法表中的索引值，与它所重写的父类方法的索引值相同。
  - 在执行过程中，Java 虚拟机将获取调用者的实际类型，并在该实际类型的虚方法表中，根据索引值获得目标方法。这个过程便是动态绑定。

- **我们是否可以认为虚方法调用对性能没有太大影响呢？**

  - 但实际上仅存在于解释执行中，或者即时编译代码的最坏情况中。这是因为即时编译还拥有另外两种性能更好的优化手段：内联缓存（inlining cache）和方法内联（method inlining）
  - 内联缓存
    - 加快动态绑定的优化技术。能够缓存虚方法调用中调用者的动态类型，以及该类型所对应的目标方法。如果没有碰到已缓存的类型，内联缓存则会退化至使用基于方法表的动态绑定
    - 在实践中，大部分的虚方法调用均是单态的，也就是只有一种动态类型。为了节省内存空间，Java 虚拟机只采用单态内联缓存。
  - 在即时编译中，方法内联不仅仅能够消除方法调用的固定开销，而且还增加了进一步优化的可能性

## JVM是如何处理异常的

- 在 Java 语言规范中，所有异常都是 Throwable 类或者其子类的实例。Throwable 有两大直接子类
  - 第一个是 Error，涵盖程序不应捕获的异常。
  - 第二子类则是 Exception，涵盖程序可能需要捕获并且处理的异常。
    - RuntimeException 和 Error 属于 Java 里的非检查异常（unchecked exception）。其他异常则属于检查异常（checked exception）。
    - 所有的检查异常都需要程序显式地捕获，或者在方法声明中用 throws 关键字标注。
- 异常实例的构造十分昂贵。这是由于在构造异常实例时，Java 虚拟机便需要生成该异常的栈轨迹。该操作会逐一访问当前线程的 Java 栈帧，并且记录下各种调试信息
  - 然而，该异常对应的栈轨迹并非 throw 语句的位置，而是新建异常的位置。
  - 这也是为什么在实践中，我们往往选择抛出新建异常实例的原因
- 在编译生成的字节码中，每个方法都附带一个异常表。
  - Java 代码中的 catch 代码块和 fnally 代码块都会生成异常表
  - 异常表不是声明这段代码所有有可能抛出的异常，而是声明会被捕获的异常
- fnally 代码块的编译比较复杂。当前版本 Java 编译器的做法，是复制 fnally 代码块的内容，分别放在 try-catch 代码块所有正常执行路径以及异常执行路径的出口中。
  - 编译结果包含三份 fnally 代码块。其中，前两份分别位于 try 代码块和 catch 代码块的正常执行路径出口。最后一份则作为异常处理器，监控 try 代码块以及 catch 代码块。它将捕获 try代码块触发的、未被 catch 代码块捕获的异常，以及 catch 代码块触发的异常。
  - 如果 catch 代码块捕获了异常，并且触发了另一个异常，那么 fnally 捕获并且重抛的异常是哪个呢？答案是后者。也就是说原本的异常便会被忽略掉，这对于代码调试来说十分不利。
  - Java 7 专门构造了一个名为 try-with-resources 的语法糖，在字节码层面自动使用Supressed 异常。
    - try 关键字后声明并实例化实现了 AutoCloseable 接口的类，编译器将自动添加对应的 close() 操作
    - try-with-resources 还会使用 Supressed 异常的功能，来避免原异常“被消失”。





## JVM是如何实现反射的

- 允许正在运行的 Java 程序观测，甚至是修改程序的动态行为。

- 反射调用的实现

  - 方法的反射调用，也就是 Method.invoke

    - 实际上委派给 MethodAccessor 来处理。MethodAccessor 是一个接口，它有两个已有的具体实现：一个通过本地方法来实现反射调用，另一个则使用了委派模式。
    - 每个 Method 实例的第一次反射调用都会生成一个委派实现，它所委派的具体实现便是一个本地实现。

  - Java 的反射调用机制还设立了另一种动态生成字节码的实现（下称动态实现），直接使用invoke 指令来调用目标方法。之所以采用委派实现，便是为了能够在本地实现以及动态实现中切换。

  - 考虑到许多反射调用仅会执行一次，Java 虚拟机设置了一个阈值15	

    - 动态实现无需经过 Java 到 C++再到 Java 的切换，但由于生成字节码十分耗时，仅调用一次的话，反而是本地实现要快上 3 到 4倍

    - 当某个反射调用的调用次数在 15 之下时，采用本地实现；当达到 15 时，便开始动态生成字节码，并将委派实现的委派对象切换至动态实现，这个过程我们称之为 Infation。

    - 可以关闭反射调用的 Infation 机制，从而取消委派实现，并且直接使用动态实现

    - 此外，每次反射调用都会检查目标方法的权限，而这个检查同样可以在 Java 代码里关闭

    - > -Dsun.refect.noInfation=true
      >
      > method.setAccessible(true);

- 反射调用的开销

  - 以 getMethod 为代表的查找方法操作，会返回查找得到结果的一份拷贝。因此，我们应当避免在热点代码中使用返回 Method 数组的 getMethods 或者 getDeclaredMethods 方法，以减少不必要的堆空间消耗。
  - 在实践中，我们往往会在应用程序中缓存 Class.forName 和 Class.getMethod 的结果。

- 反射调用之前字节码都做了什么

  - 由于 Method.invoke 是一个变长参数方法，在字节码层面它的最后一个参数会是 Object 数组。Java 编译器会在方法调用处生成一个长度为传入参数 数量的 Object 数组，并将传入参数一一存储进该数组中。
    - 由于 Object 数组不能存储基本类型，Java 编译器会对传入的基本类型参数进行自动装箱
    - 这两个操作除了带来性能开销外，还可能占用堆内存，使得 GC 更加频繁。
    - 如果一个对象不逃逸，那么即时编译器可以选择栈分配甚至是虚拟分配，也就是不占用堆空间。
  - 之所以反射调用能够变得这么快，主要是因为即时编译器中的方法内联。在关闭了 Infation 的情况下，内联的瓶颈在于 Method.invoke 方法中对 MethodAccessor.invoke 方法的调用。
  - 在生产环境中，我们往往拥有多个不同的反射调用，对应多个 GeneratedMethodAccessor，也就是动态实现。
    - Java 虚拟机的关于上述调用点的调用者的具体类型（ invokevirtual 或者invokeinterface），Java 虚拟机会记录下调用者的具体类型，我们称之为类型 profle）无法同时记录这么多个类，因此可能造成所测试的反射调用没有被内联的情况。
    - 之所以这么慢，除了没有内联之外，另外一个原因是逃逸分析不再起效
    - 只要没有完全内联，就会将看似不逃逸的对象通过参数传递出去。即时编译器不知道所调用的方法对该对象有没有副作用，所以会将其判定为逃逸。

- 方法的反射调用会带来不少性能开销，原因主要有三个：变长参数方法导致的 Object 数组，基本类型的自动装箱、拆箱，还有最重要的方法内联。







## Java对象的内存布局

- 以 new 语句为例，它编译而成的字节码将包含用来请求内存的 new 指令，以及用来调用构造器的invokespecial 指令。
- 构造器
  - 如果一个类没有定义任何构造器的话， Java 编译器会自动添加一个无参数的构造器。
  - 子类的构造器需要调用父类的构造器。如果父类存在无参数构造器的话，该调用可以是隐式的，也就是说 Java 编译器会自动添加对父类构造器的调用
  - 如果父类没有无参数构造器，那么子类的构造器则需要显式地调用父类带参数的构造器。
  - 通过 new 指令新建出来的对象，它的内存其实涵盖了所有父类中的实例字段。
  - 子类的实例还是会为这些父类实例字段分配内存的。
- 压缩指针
  - 在 Java 虚拟机中，每个 Java 对象都有一个对象头（object header）
    - 由标记字段和类型指针所构成
    - 标记字段用以存储 Java 虚拟机有关该对象的运行数据，如哈希码、GC 信息以及锁信息，而类型指针则指向该对象的类。
    - 为了尽量较少对象的内存使用量，64 位 Java 虚拟机引入了压缩指针的概念，将堆中原本 64 位的 Java 对象指针压缩成 32 位的，32 位压缩指针最多可以标记 2 的 32 次。这样一来，对象头中的类型指针也会被压缩成 32 位，使得对象头的大小从 16 字节降至 12 字节。
  - 默认情况下，Java 虚拟机堆中对象的起始地址需要对齐至 8 的倍数。如果一个对象用不到 8N 个字节，那么空白的那部分空间就浪费掉了。这些浪费掉的空间我们称之为对象间的填充
    - 内存对齐不仅存在于对象与对象之间，也存在于对象中的字段之间。
    - 字段内存对齐的其中一个原因，是让字段只出现在同一 CPU 的缓存行中。如果字段不是对齐的， 那么就有可能出现跨缓存行的字段。也就是说，该字段的读取可能需要替换两个缓存行，而该字段 的存储也会同时污染两个缓存行。
- 字段重排列
  - java 虚拟机重新分配字段的先后顺序，以达到内存对齐的目的
  - Java 8 还引入了一个新的注释 @Contended，用来解决对象字段之间的伪共享问题 。这个注释也会影响到字段的排列。Java 虚拟机会让不同的 @Contended 字段处于独立的缓存行中，因此你会看到大量的空间被浪费掉。
  - 伪共享
    - 假设两个线程分别访问同一对象中不同的 volatile 字段，逻辑上它们并没有共享内容，因此不需要同步。
    - 如果这两个字段恰好在同一个缓存行中，那么对这些字段的写操作会导致缓存行的写回，也就造成了实质上的共享。





## 监控和诊断JVM堆内和堆外内存使用

- 以 JConsole 为例，其内存页面可以显示常见的**堆内存**和**各种堆外部分**使用状态。

  - 也可以使用命令行工具进行运行时查询，如 jstat 和 jmap 等工具都提供了一些选项，可以查看堆、方法区等使用数据。
  - 或者，也可以使用 jmap 等提供的命令，生成堆转储（Heap Dump）文件，然后利用 jhat 或 Eclipse MAT 等堆转储分析工具进行详细分析。
  - 如果你使用的是 Tomcat、Weblogic 等 Java EE 服务器，这些服务器同样提供了内存管理相关的功能。
  - 另外，从某种程度上来说，GC 日志等输出，同样包含着丰富的信息
  - 特别推荐[Java Mission Control](http://www.oracle.com/technetwork/java/javaseproducts/mission-control/java-mission-control-1998576.html)（JMC），这是一个非常强大的工具，不仅仅能够使用[JMX](https://en.wikipedia.org/wiki/Java_Management_Extensions)进行普通的管理、监控任务，还可以配合[Java Flight Recorder](https://docs.oracle.com/javacomponents/jmc-5-4/jfr-runtime-guide/about.htm#JFRUH171)（JFR）技术，以非常低的开销，收集和分析 JVM 底层的 Profiling 和事件等信息。

- 年代视角的堆结构

  - 按照通常的 GC 年代方式划分，Java 堆内分为
    - 新生代
      - 是大部分对象创建和销毁的区域，在通常的 Java 应用中，绝大部分对象生命周期都是很短暂的。其内部又分为 Eden 区域，作为对象初始分配的区域；两个 Survivor，有时候也叫 from、to 区域，被用来放置从 Minor GC 中保留下来的对象。
      - JVM 会随意选取一个 Survivor 区域作为“to”，然后会在 GC 过程中进行区域间拷贝，也就是将 Eden 中存活下来的对象和 from 区域的对象，拷贝到这个“to”区域。这种设计主要是为了防止内存的碎片化，并进一步清理无用对象。
      - 从内存模型而不是垃圾收集的角度，对 Eden 区域继续进行划分，Hotspot JVM 还有一个概念叫做 Thread Local Allocation Buffer（TLAB），据我所知所有 OpenJDK 衍生出来的 JVM 都提供了 TLAB 的设计。这是 JVM 为每个线程分配的一个私有缓存区域，否则，多线程同时分配内存时，为避免操作同一地址，可能需要使用加锁等机制，进而影响分配速度；TLAB 仍然在堆上，它是分配在 Eden 区域内的。其内部结构比较直观易懂，start、end 就是起始地址，top（指针）则表示已经分配到哪里了。所以我们分配新对象，JVM 就会移动 top，当 top 和 end 相遇时，即表示该缓存已满，JVM 会试图再从 Eden 里分配一块儿。
    - 老年代
      - 放置长生命周期的对象，通常都是从 Survivor 区域拷贝过来的对象。当然，也有特殊情况，我们知道普通的对象会被分配在 TLAB 上；
      - 如果对象较大，JVM 会试图直接分配在 Eden 其他位置上；
      - 如果对象太大，完全无法在新生代找到足够长的连续空闲空间，JVM 就会直接分配到老年代。

- 如何利用 JVM 参数，直接影响堆和内部区域的大小

  - > 最大堆体积
    >
    > -Xmx value
    >
    > 
    >
    > 初始的最小堆体积
    >
    > -Xms value
    >
    > 
    >
    > 在 JVM 内部，如果 Xms 小于 Xmx，堆的大小并不会直接扩展到其上限，也就是说保留的空间（reserved）大于实际能够使用的空间（committed）。当内存需求不断增长的时候，JVM 会逐渐扩展新生代等区域的大小，所以 Virtual 区域代表的就是暂时不可用（uncommitted）的空间。
    >
    > 
    >
    > 老年代和新生代的比例
    >
    > -XX:NewRatio=value
    >
    > 默认情况下，这个数值是 2，意味着老年代是新生代的 2 倍大
    >
    > 
    >
    > 也可以不用比例的方式调整新生代的大小，直接指定下面的参数，设定具体的内存大小数值
    >
    > -XX:NewSize=value
    >
    > 
    >
    > Eden 和 Survivor 的大小是按照比例设置的，YoungGen=Eden + 2*Survivor，JVM 参数格式是
    >
    > -XX:SurvivorRatio=value

- JVM 堆外内存

  - > 首先来做些准备工作，开启 NMT 并选择 summary 模式，
    >
    > -XX:NativeMemoryTracking=summary
    >
    > 
    >
    > 为了方便获取和对比 NMT 输出，选择在应用退出时打印 NMT 统计信息
    >
    > -XX:+UnlockDiagnosticVMOptions
    >
    > -XX:+PrintNMTStatistics

  - NMT 所表征的 JVM 本地内存使用

    - Java 堆

    - Class 内存占用，它所统计的就是 Java 类元数据所占用的空间，JVM 可以通过类似下面的参数调整其大小

      - -XX:MaxMetaspaceSize=value

    - hread，这里既包括 Java 线程，如程序主线程、Cleaner 线程等，也包括 GC 等本地线程。

      - 你有没有注意到，即使是一个 HelloWorld 程序，这个线程数量竟然还有 25。似乎有很多浪费，设想我们要用 Java 作为 Serverless 运行时，每个 function 是非常短暂的，如何降低线程数量呢
        - JDK 9 的默认 GC 是 G1，虽然它在较大堆场景表现良好，但本身就会比传统的 Parallel GC 或者 Serial GC 之类复杂太多，所以要么降低其并行线程数目，要么直接切换 GC 类型；
        - JIT 编译默认是开启了 TieredCompilation 的，将其关闭，那么 JIT 也会变得简单，相应本地线程也会减少。
        - 替换了默认 GC，并关闭 TieredCompilation 的命令行
          - 线程数目降低，消耗的内存也下降了。

    - Code 统计信息

      - 显然这是 CodeCache 相关内存，也就是 JIT compiler 存储编译热点方法等信息的地方

      - > JVM 提供了一系列参数可以限制其初始值和最大值等
        >
        > -XX:InitialCodeCacheSize=value
        > -XX:ReservedCodeCacheSize=value

    - GC 部分

      - G1 等垃圾收集器其本身的设施和数据结构就非常复杂和庞大，例如 Remembered Set 通常都会占用 20%~30% 的堆空间
      - GC 明确修改为相对简单的 Serial GC，不仅总线程数大大降低，而且 GC 设施本身的内存开销就少了非常多

    - Compiler 部分

      - 就是 JIT 的开销，显然关闭 TieredCompilation 会降低内存使用。



## Java内存模型

- happens-before 

  - happens-before 关系是用来描述两个操作的内存可见性的。如果操作 X happens-before 操作 Y，那么 X 的结果对于 Y 可见。

  - 实际上，如果后者没有观测前者的运行结果，即后者没有数据依赖于前者，那么它们可能会被重排序。

  - 在同一个线程中，字节码的先后顺序（program order）也暗含了 happens-before 关系

  - 线程间的 happens-before关系

    - 解锁操作 happens-before 之后（这里指时钟顺序先后）对同一把锁的加锁操作
    - volatile 字段的写操作 happens-before 之后（这里指时钟顺序先后）对同一字段的读操作
    - 线程的启动操作（即 Thread.starts()） happens-before 该线程的第一个操作
    - 线程的最后一个操作 happens-before 它的终止事件
      - （即其他线程通过 Thread.isAlive() 或Thread.join() 判断该线程是否中止）。
    - 线程对其他线程的中断操作 happens-before 被中断线程所收到的中断事件
      - 即被中断线程的InterruptedException 异常，或者第三个线程针对被中断线程的 Thread.interrupted 或者Thread.isInterrupted 调用

  - happens-before 关系还具备传递性

    - ```java
      // 如何解决这个问题呢？答案是，将 a 或者 b 设置为 volatile 字段
      
      int a=0, b=0;
      
      public void method1() {
       	int r2 = a;
       	b = 1;
      }
      
      public void method2() {
       	int r1 = b;
       	a = 2;
      }
      ```

    - 解决这种数据竞争问题的关键在于构造一个跨线程的 happens-before 关系 ：操作X happens-before 操作 Y，使得操作 X 之前的字节码的结果对操作 Y 之后的字节码可见。

- Java 内存模型的底层实现

  - Java 内存模型是通过内存屏障来禁止重排序的。对于即时编译器来说，内存屏障将限制它所能做的重排序优化。对于处理器来说，内存屏障会导致缓存的刷新操作。
    - 对于即时编译器来说，它会针对前面提到的每一个 happens-before 关系，向正在编译的目标方法中插入相应的读读、读写、写读以及写写内存屏障。
    - X86_64 架构上读读、读写以及写写内存屏障是空操作（no-op）
    - 这些内存屏障会限制即时编译器的重排序操作
      - 以 volatile 字段访问为例，所插入的内存屏障将不允许 volatile 字段写操作之前的内存访问被重排序至其之后；也将不允许 volatile 字段读操作之后的内存访问被重排序至其之前（写前读后）
    - 即时编译器将根据具体的底层体系架构，将这些内存屏障替换成具体的 CPU 指令
  - X86_64 架构的处理器不能将读操作重排序至写操作之后
  - 只有 volatile 字段写操作之后的写读内存屏障需要用具体指令来替代
    - 该具体指令的效果，可以简单理解为强制刷新处理器的写缓存
    - 强制刷新写缓存，将使得当前线程写入 volatile 字段的值（以及写缓存中已有的其他内存修改），同步至主内存之中。

- 锁，volatile 字段，fnal 字段与安全发布

  - 在解锁时，Java 虚拟机同样需要强制刷新缓存，使得当前线程所修改的内存对其他线程可见。
    - 锁操作的 happens-before 规则的关键字是同一把锁。也就意味着，如果编译器能够（通过逃逸分析）证明某把锁仅被同一线程持有，那么它可以移除相应的加锁解锁操作。
    - 因此也就不再强制刷新缓存。举个例子，即时编译后的 synchronized (new Object()) {}，可能等同于空操作，而不会强制刷新缓存。
  - volatile 字段可以看成一种轻量级的、不保证原子性的同步，其性能往往优于锁操作。
    - 频繁地访问 volatile 字段也会因为不断地强制刷新缓存而严重影响程序的性能。
      - volatile 字段的另一个特性是即时编译器无法将其分配到寄存器里。换句话说，volatile 字段的每次访问均需要直接从内存中读写。
      - 所谓的分配到寄存器中，可以理解为编译器将内存中的值缓存在寄存器中，之后一直用访问寄存器来代表对这个内存的访问的。
        - 遍历一个数组，数组的长度是内存中的值。由于我们每次循环都要比较一次，因此编译器决定把它放在寄存器中，免得每次比较都要读一次内存
        - 对于会更改的内存值，编译器也可以先缓存至寄存器，最后更新回内存即可。
      - 非volatile的
        - jvm不保证何时变量的值会写回内存。假如另一个线程加锁访问这个变量，jvm也不保证它能拿到最新数据。
        - 如果即时编译器把那个变量放在寄存器里维护，那么另一个线程也没办法
      - Volatile会禁止上述优化。
  - fnal 实例字段则涉及新建对象的发布问题。当一个对象包含 fnal 实例字段时，我们希望其他线程只能看到已初始化的 fnal 实例字段。
    - 即时编译器会在 fnal 字段的写操作后插入一个写写屏障，以防某些优化将新建对象的发布重排序至 fnal 字段的写操作之前。





## Java虚拟机是怎么实现 synchronized的

- 当声明 synchronized 代码块时

  - 编译而成的字节码将包含 monitorenter 和 monitorexit 指令。这两种指令均会消耗操作数栈上的一个 synchronized 关键字括号里的引用( synchronized (lock))，作为所要加锁解锁的锁对象。
  - 字节码中包含一个 monitorenter 指令以及多个 monitorexit 指令。这是因为 Java虚拟机需要确保所获得的锁在正常执行路径，以及异常执行路径上都能够被解锁。

- 当用 synchronized 标记方法时

  - 字节码中方法的访问标记包括 ACC_SYNCHRONIZED
  - 表示在进入该方法时，Java 虚拟机需要进行 monitorenter 操作。而在退出该方法时，不管是正常返回，还是向调用者抛异常，Java 虚拟机均需要进行 monitorexit 操作。
  - 这里 monitorenter 和 monitorexit 操作所对应的锁对象是隐式的。对于实例方法来说，这两个操作对应的锁对象是 this；对于静态方法来说，这两个操作对应的锁对象是则是所在类的 Class 实例。

- 关于 monitorenter 和 monitorexit 的作用，我们可以抽象地理解为每个锁对象拥有一个锁计数器和一个指向持有该锁的线程的指针。

  - 当执行 monitorenter 时，如果目标锁对象的计数器为 0，Java 虚拟机会将该锁对象的持有线程设置为当前线程，并且将其计数器加 1。
  - 不为 0 ，如果锁对象的持有线程是当前线程，那么 Java 虚拟机可以将其计数器加 1，否则需要等待，直至持有线程释放该锁
  - 之所以采用这种计数器的方式，是为了允许同一个线程重复获取同一把锁
  - 举个例子，如果一个Java 类中拥有多个 synchronized 方法，那么这些方法之间的相互调用，不管是直接的还是间接的，都会涉及对同一把锁的重复加锁操作。因此，我们需要设计这么一个可重入的特性，来避免编程里的隐式约束。

- 重量级锁

  - Java 线程的阻塞以及唤醒，都是依靠操作系统来完成的
    - 这些操作将涉及系统调用，需要从操作系统的用户态切换至内核态，其开销非常之大
  - 为了尽量避免昂贵的线程阻塞、唤醒操作，Java 虚拟机会在线程进入阻塞状态之前，以及被唤醒后竞争不到锁的情况下，进入自旋状态，在处理器上空跑并且轮询锁是否被释放
    - Java 虚拟机给出的方案是自适应自旋，根据以往自旋等待时是否能够获得锁，来动态调整自旋的时间（循环数目）
    - 自旋状态还带来另外一个副作用，那便是不公平的锁机制。处于阻塞状态的线程，并没有办法立刻竞争被释放的锁。然而，处于自旋状态的线程，则很有可能优先获得这把锁。

- 轻量级锁

  - 多个线程在不同的时间段请求同一把锁，也就是说没有锁竞争。针对这种情形，Java 虚拟机采用了轻量级锁，来避免重量级锁的阻塞以及唤醒。

- Java 虚拟机是怎么区分轻量级锁和重量级锁的。

  - 对象头中的标记字段（mark word）。它的最后两位便被用来表示该对象的锁状态。
    - 00 代表轻量级锁，01 代表无锁（或偏向锁），10 代表重量级锁，11 则跟垃圾回收算法的标记有关。
  - 加锁操作时
    - Java 虚拟机会判断是否已经是重量级锁。如果不是，它会在当前线程的当前栈桢中划出一块空间，作为该锁的锁记录，并且将锁对象的标记字段复制到该锁记录中（假设当前锁对象的标记字段为 X…XYZ）
    - 然后，Java 虚拟机会尝试用 CAS操作替换锁对象的标记字段
      - 如果是X…X01，则替换为刚才分配的锁记录的地址。由于内存对齐的缘故，它的最后两位为 00。此时，该线程已成功获得这把锁，可以继续执行了。
      - 如果不是 X…X01，那么有两种可能。
        - 第一，该线程重复获取同一把锁。此时，Java 虚拟机会将锁记录清零，以代表该锁被重复获取
        - 第二，其他线程持有该锁。此时，Java 虚拟机会将这把锁膨胀为重量级锁，并且阻塞当前线程。
  - 解锁操作时
    - 如果当前锁记录，值为 0，则代表重复进入同一把锁，直接返回即可。
    - 否则，Java 虚拟机会尝试用 CAS 操作，比较锁对象的标记字段的值是否为当前锁记录的地址
      - 如果是，则替换为锁记录中的值，也就是锁对象原本的标记字段。此时，该线程已经成功释放这把锁。
      - 如果不是，则意味着这把锁已经被膨胀为重量级锁。此时，Java 虚拟机会进入重量级锁的释放过程，唤醒因竞争该锁而被阻塞了的线程。

- 偏向锁

  - 偏向锁针对的情况则更加乐观：从始至终只有一个线程请求某一把锁。
    - 具体来说，在线程进行加锁时，如果该锁对象支持偏向锁，那么 Java 虚拟机会通过 CAS 操作，将当前线程的地址记录在锁对象的标记字段之中，并且将标记字段的最后三位设置为 101
    - 在接下来的运行过程中，每当有线程请求这把锁，Java 虚拟机只需判断锁对象标记字段中：最后三位是否为 101，是否包含当前线程的地址，以及 epoch 值是否和锁对象的类的 epoch 值相同。如果都满足，那么当前线程持有该偏向锁，可以直接返回
  - epoch 值
    - 偏向锁的撤销
      - 当请求加锁的线程和锁对象标记字段保持的线程地址不匹配时，Java 虚拟机需要撤销该偏向锁。这个撤销过程非常麻烦，它要求持有偏向锁的线程到达安全点，再将偏向锁替换成轻量锁。
      - 总撤销数超过了一个阈值 20，Java 虚拟机会宣布这个类的偏向锁失效	
      - 如果总撤销数超过另一个阈值40， Java 虚拟机会认为这个类已经不再适合偏向锁，之后的加锁过程中直接为该类实例设置轻量级锁
    - 每个类中维护一个 epoch 值，你可以理解为第几代偏向锁，当设置偏向锁时，Java 虚拟机需要将该 epoch 值复制到锁对象的标记字段中。
    - 在宣布某个类的偏向锁失效时，Java 虚拟机实则将该类的 epoch 值加 1，表示之前那一代的偏向锁已经失效。而新设置的偏向锁则需要复制新的 epoch 值。

  

  

  

## Java语法糖与Java编译器（自动装箱与自动拆箱、泛型相关）

- Java 语法和 Java 字节码的差异之处。这些差异之处都是通过Java 编译器来协调的。

- 自动装箱与自动拆箱

  - 之所以需要包装类型，是因为许多 Java 核心类库的 API 都是面向对象的。举个例子，Java 核心类库中的容器类，就只支持引用类型
    - 调用 Integer.valueOf 方法，将 int 类型的值转换为 Integer 类型，再存储至容器类中
    - 调用 Integer.intValue 方法。返回 Integer 对象所存储的 int 值
  - 对于基本类型的数值来说，我们需要先将其转换为对应的包装类，再存入容器之中。这个转换可以是显式，也可以是隐式的，后者正是 Java 中的自动装箱
  - ArrayList 取出元素时，我们得到的实际上也是 Integer 对象。如果应用程序期待的是一个 int 值，那么就会发生自动拆箱

- 类型擦除

  - 在前面例子生成的字节码中，往 ArrayList 中添加元素的 add 方法，所接受的参数类型是 Object；而从 ArrayList 中获取元素的 get 方法，其返回类型同样也是 Object。

  - 之所以会出现这种情况，是因为 Java 泛型的类型擦除。Java 程序里的泛型信息，在 Java 虚拟机里全部都丢失了。

  - Java 编译器将选取该泛型所能指代的所有类中层次最高的那个，作为替换泛型的类。

  - ```java
    // foo 方法的方法描述符所接收参数的类型以及返回类型都为 Number。
    // 方法描述符是 Java 虚拟机识别方法调用目标方法的关键。
    class GenericTes<T extends Number> {
     T foo(T t) {
     return t;
     }
    }
    ```

- 桥接方法

  - 泛型的类型擦除带来了不少问题。其中一个便是方法重写

  - 为了保证编译而成的 Java 字节码能够保留重写的语义，Java 编译器额外添加了一个桥接方法。该桥接方法在字节码层面重写了父类的方法，并将调用子类的方法。

  - ```java
    // VIPOnlyMerchant 类将包含一个桥接方法 actionPrice(Customer)，它重写了父类的同名同方法描述符的方法。该桥接方法将传入的 Customer 参数强制转换为 VIP 类型，再调用原本的 actionPrice(VIP) 方法。
    
    class Merchant<T extends Cusomer> {
     public double actionPrice(T cusomer) {
     return 0.0d;
     }
    }
    class VIPOnlyMerchant extends Merchant<VIP> {
     @Override
     public double actionPrice(VIP cusomer) {
     return 0.0d;
     }
    }
    ```





## 即时编译

- 即时编译是提升应用程序运行效率的技术

  - 代码会先被 Java 虚拟机解释执行，之后反复执行的热点代码则会被即时编译成为机器码，直接运行在底层硬件之上。

- 分层编译模式

  - 分层编译将 Java 虚拟机的执行状态分为了五个层次

  - C1 代码”来指代由 C1 生成的机器码，“C2 代码”来指代由 C2 生成的机器码

    > 0 解释执行；
    >
    > 1 执行不带 profling 的 C1 代码；
    >
    > 2 执行仅带方法调用次数以及循环回边执行次数 profling 的 C1 代码；
    >
    > 3 执行带所有 profling 的 C1 代码；
    >
    > 4 执行 C2 代码。

  - profling 越多，其额外的性能开销越大。

    - profling 是指在程序执行过程中，收集能够反映程序执行状态的数据
    - 分支跳转指令的branch profle，和类型相关指令的type profle。

  - 在 5 个层次的执行状态中，1 层和 4 层为终止状态

  - 4 个不同的编译路径

    - 通常情况下，热点方法会被 3 层的 C1 编译，然后再被 4 层的 C2 编译。
    - 在 C1 忙碌的情况下，由 4 层的 C2编译
    - C2 忙碌的情况下，2 层的 C1 编译，然后再被 3 层的 C1 编译，以减少方法在 3层的执行时间。
    - 如果方法的字节码数目比较少（如getter/setter），而且 3 层的 profling 没有可收集的数据，在 3 层编译之后，直接选择用 1 层的 C1 编译。由于这是一个终止状态，因此 Java 虚拟机不会继续用 4 层的 C2 编译。

- 即时编译的触发

  - Java 虚拟机是根据方法的调用次数以及循环回边的执行次数来触发即时编译的,即时编译是以方法为单位的

  - 当启用分层编译时,Java 虚拟机会将这些编译线程按照 1:2 的比例分配给 C1 和 C2

  - > 当方法调用次数大于由参数 -XX:TierXInvocationThreshold 指定的阈值乘以系数
    > 或者当方法调用次数大于由参数 -XX:TierXMINInvocationThreshold 指定的阈值乘以系数，并且方法调用次数和循环回边次数之和大于由参数
    > -XX:TierXCompileThreshold 指定的阈值乘以系数时，便会触发 X 层即时编译。
    >
    > 触发条件为：
    > i > TierXInvocationThreshold * s || (i > TierXMinInvocationThreshold * s && i + b >
    > TierXCompileThreshold * s)
    > 其中 i 为调用次数，b 为循环回边次数。





## Java字节码

- Java 字节码是 Java 虚拟机所使用的指令集
- 操作数栈
  - 每当为 Java 方法分配栈桢时，Java 虚拟机往往需要开辟一块额外的空间作为操作数栈，来存放计算的操作数以及返回结果。
  - 具体来说便是：执行每一条指令之前，Java 虚拟机要求该指令的操作数已被压入操作数栈中。在执行指令时，Java 虚拟机会将该指令所需的操作数弹出，并且将指令的结果重新压入栈中。
  - 最为常见的便是 dup： 复制栈顶元素，以及pop：舍弃栈顶元素。
    - 当执行 new 指令时，Java 虚拟机将指向一块已分配的、未初始化的内存的引用压入操作数栈中。
    - 接下来，我们需要以这个引用为调用者，调用其构造器，也就是字节码中的 invokespecial指令。
    - 该指令将消耗操作数栈上的元素，作为它的调用者以及参数
  - 上述两条指令只能处理非 long 或者非 double 类型的值，这是因为 long 类型或者 double 类型的值，需要占据两个栈单元。当遇到这些值时，我们需要同时复制栈顶两个单元的 dup2 指令，以及弹出栈顶两个单元的 pop2 指令。
  - 正常情况下，操作数栈的压入弹出都是一条条指令完成的。唯一的例外情况是在抛异常时，Java虚拟机会清除操作数栈上的所有内容，而后将异常实例压入操作数栈上。
- 局部变量区、访问指令表
  - Java 方法栈桢的另外一个重要组成部分则是局部变量区，字节码程序可以将计算的结果缓存在局部变量区之中。
  - Java 虚拟机将局部变量区当成一个数组，依次存放 this 指针（仅非静态方法），所传入的参数，以及字节码中的局部变量。
  - Java 字节码中唯一能够直接作用于局部变量区的指令是 iinc M N（M 为非负整数，N 为整数）
    - 将局部变量数组的第 M 个单元中的 int 值增加 N，常用于 for循环中自增量的更新。





## 方法内联

- 在编译过程中遇到方法调用时，将目标方法的方法体纳入编译范围之中，并取代原方法调用的优化手段。
  - 不仅可以消除调用本身带来的性能开销，还可以进一步触发更多的优化。它可以算是编译优化里最为重要的一环。
  - 以 getter/setter 为例，如果没有方法内联，在调用 getter/setter 时，程序需要保存当前方法的执行位置，创建并压入用于 getter/setter 的栈帧、访问字段、弹出栈帧，最后再恢复当前方法的执行。而当内联了对 getter/setter 的方法调用后，上述操作仅剩字段访问。
- 在 C2 中，方法内联是在解析字节码的过程中完成的。
- 对于需要动态绑定的虚方法调用来说，即时编译器则需要先对虚方法调用进行去虚化（devirtualize），即转换为一个或多个直接调用，然后才能进行方法内联。
  - 基于类型推导的完全去虚化
    - 通过数据流分析推导出调用者的动态类型，从而确定具体的目标方法。
    - 关键在于证明虚方法调用的目标方法是唯一的
    - 类型推导属于全局优化，本身比较浪费时间
  - 基于类层次分析的完全去虚化
    - 通过分析 Java 虚拟机中所有已被加载的类，判断某个抽象方法或者接口方法是否仅有一个实现。如果是，那么对这些方法的调用将只能调用至该具体实现中。





## 逃逸分析

- 逃逸分析是“一种确定指针动态范围的静态分析，它可以分析在程序的哪些地方可以访问到指针
- 即时编译器判断对象是否逃逸的依据，一是对象是否被存入堆中（静态字段或者堆中对象的实例字段），二是对象是否被传入未知代码中。
  - 一旦对象被存入堆中，其他线程便能获得该对象的引用。即时编译器也因此无法追踪所有使用该对象的代码位置
  - 由于 Java 虚拟机的即时编译器是以方法为单位的，对于方法中未被内联的方法调用，即时编译器会将其当成未知代码
  - 通常来说，即时编译器里的逃逸分析是放在方法内联之后的，以便消除这些“未知代码”入口
- 基于逃逸分析的优化
  - 锁消除
    - synchronized (new Object()) {}会被完全优化掉。这正是因为基于逃逸分析的锁消除。由于其他线程不能获得该锁对象，因此也无法基于该锁对象构造两个线程之间的 happens-before 规则。
    - 不过，基于逃逸分析的锁消除实际上并不多见
  - 栈上分配
    - 如果逃逸分析能够证明某些新建的对象不逃逸，那么 Java 虚拟机完全可以将其分配至栈上，并且在 new 语句所在的方法退出时，通过弹出当前方法的栈桢来自动回收所分配的内存空间。这样一来，我们便无须借助垃圾回收器来处理不再被引用的对象。
    - 由于实现起来需要更改大量假设了“对象只能堆分配”的代码，因此 HotSpot 虚拟机并没有采用栈上分配，而是使用了标量替换这么一项技术。
  - 标量替换
    - 标量，就是仅能存储一个值的变量，比如 Java 代码中的局部变量。聚合量则可能同时存储多个值，其中一个典型的例子便是 Java 对象。
    - 标量替换这项优化技术，可以看成将原本对对象的字段的访问，替换为一个个局部变量的访问
- Java 中Iterable对象的 foreach 循环遍历是一个语法糖，Java 编译器会将该语法糖编译为调用Iterable对象的iterator方法，并用所返回的Iterator对象的hasNext以及next方法，来完成遍历。
  - ArrayList.iterator方法将创建一个ArrayList$Itr实例。
  - 理想情况下，即时编译器能够内联对ArrayList$Itr构造器的调用，对hasNext以及next方法的调用，以及当内联了Itr.next方法后，对checkForComodification方法的调用
  - 如果这些方法调用均能够被内联。新建的ArrayList$Itr实例既没有被存入任何字段之中，也没有作为任何方法调用的调用者或者参数。因此，逃逸分析将断定该实例不逃逸。

## JVM内存模型

- JVM 不仅承担了 Java 字节码的分析（JITcompiler）和执行（Runtime），同时也内置了自动内存分配管理机制。这个机制可以大大降低手动分配回收机制可能带来的内存泄露和内存溢出风险
- JVM 内存模型的具体设计
  - 堆
    - 堆是 JVM 内存中最大的一块内存空间，该内存被所有线程共享，几乎所有对象和数组都被分配到了堆内存中。堆被划分为新生代和老年代
  - 方法区
    - 方法区是一个规范，并不是一个物理空间，方法区不是堆的一部分，方法区和堆存在交集
    - 方法区主要是用来存放已被虚拟机加载的类相关信息，包括类信息、运行时常量池、字符串常量池
    - 在加载类的时候，JVM 会先加载 class 文件，class 文件中除了有类的版本、字段、方法和接口等描述信息外，还有一项信息是常量池，用于存放编译期间生成的各种字面量和符号引用。
      - 字面常量包括字符串常量（例如String str=“abc”，其中"abc"就是常量），声明为 final 的属性以及一些基本类型（例如，范围在 -127-128 之间的整型）的属性，符号引用则包括类和方法的全限定名（例如 String 这个类，它的全限定名就是Java/lang/String）、字段的名称和描述符以及方法的名称和描述符。
      - 通常方法区中有静态常量池和运行时常量池，静态常量池主要存储的是字面量以及符号引用等信息，而运行时常量池存储的是类加载时生成的直接引用等信息。静态常量池也包括了我们说的字符串常量池。
    - 而当类加载到内存中后，JVM 就会将 class 文件常量池中的内容存放到运行时的常量池中；在解析阶段，JVM 会把符号引用替换为直接引用（对象的索引值）。
      - 运行时常量池是全局共享的，多个类共用一个运行时常量池，class 文件中常量池多个相同的字符串在运行时常量池只会存在一份。
    - Java8 为什么使用元空间替代永久代，这样做有什么好处呢
      - 1.8以后取而代之的是"metaspace"，他其实是使用的本地内存，有时叫"非堆"，所以不受xms(堆空间)限制，可以用-XX:MetaspaceSize等指定。
      - 移除永久代是为了融合 HotSpot JVM 与 JRockit VM 而做出的努力，因为 JRockit 没有永久代，所以不需要配置永久代。
      - 永久代内存经常不够用或发生内存溢出，爆出异常 java.lang.OutOfMemoryError:PermGen。
        - 在 JDK1.7 版本中，指定的 PermGen 区大小为 8M，由于PermGen 中类的元数据信息在每次 FullGC 的时候都可能被收集，回收率都偏低，成绩 很难令人满意；还有，为 PermGen 分配多大的空间很难确定，PermSize 的大小依赖于 很多因素，比如，JVM 加载的 class 总数、常量池的大小和方法的大小等。
      - 方法区只是一个逻辑分区，而元空间是具体实现。所以类的元数据是存放在元空间，逻辑上属于方法区
    - 方法区不是堆的一部分，方法区和堆存在交集。方法区的静态变量和运行时常量池存放在堆中，但类的元信息等还是存放在了本地内存中。
  - 程序计数器
    - 程序计数器是一块很小的内存空间，主要用来记录各个线程执行的字节码的地址
  - 虚拟机栈
    - Java 虚拟机栈是线程私有的内存空间，它和 Java 线程一起创建
    - 保存方法的局部变量、操作数栈、动态链接方法和返回地址等信息，并参与方法的调用和返回。每一个方法的调用都伴随着栈帧的入栈操作，方法的返回则是栈帧的出栈操作。
    - 创建一个线程，会创建一个栈，然后方法调用一次，就会申请一个栈帧
  - 本地方法栈
    - 本地方法栈跟 Java 虚拟机栈的功能类似，Java 虚拟机栈用于管理 Java 方法的调用，而本地方法栈则用于管理本地方法的调用。但本地方法并不是用 Java 实现的，而是由 C 语言实现的。
  - 堆、栈、方法区等，这些是一种规范，是逻辑上的分区。在物理空间中，常量池是存储在堆内存空间的。
- **new一个对象JVM 处理过程**
  - JVM 向操作系统申请内存
  - 配置参数分配堆、栈以及方法区的内存大小
  - Class 文件加载、验证、准备以及解析，其中准备阶段会为类的静态变量分配内存，初始化为系统的初始值
  - 进行最后一个初始化阶段。在这个阶段中，JVM 首先会执行构造器 <clinit> 方法，编译器会在.java 文件被编译成.class 文件时，收集所有类的初始化代码，包括静态变量赋值语句、静态代码块、静态方法，收集在一起成为 <clinit>() 方法。
  - 执行方法。启动 main 线程，执行 main 方法
  - 此时再次创建一个 JVMCase 对象，调用 sayHello 非静态方法，此时 sayHello 方法入栈，并通过栈中的 student 引用调用堆中的 Student对象，之后，调用静态方法 print，print 静态方法属于 JVMCase 类，是从静态方法中获取，之后放入到栈中，也是通过 student 引用调用堆中的 student 对象。
- **除了程序计数器，其他区域都有可能会因为可能的空间不足发生 OutOfMemoryError**
  - 堆内存不足是最常见的 OOM 原因之一，抛出的错误信息是“java.lang.OutOfMemoryError:Java heap space”，原因可能千奇百怪，例如，可能存在内存泄漏问题；也很有可能就是堆的大小不合理，比如我们要处理比较可观的数据量，但是没有显式指定 JVM 堆大小或者指定数值偏小；或者出现 JVM 处理引用不及时，导致堆积起来，内存无法释放等。
  - 而对于 Java 虚拟机栈和本地方法栈，这里要稍微复杂一点。如果我们写一段程序不断的进行递归调用，而且没有退出条件，就会导致不断地进行压栈。类似这种情况，JVM 实际会抛出 StackOverFlowError；当然，如果 JVM 试图去扩展栈空间的的时候失败，则会抛出 OutOfMemoryError。
  - 随着元数据区的引入，方法区内存已经不再那么窘迫，所以相应的 OOM 有所改观，出现 OOM，异常信息则变成了：“java.lang.OutOfMemoryError: Metaspace”
- 试图分配一个**100M bytes 大数组**的时候发生了 OOME，但是 GC 日志显示，明明堆上还有远不止100M 的空间，可能问题的原因是什么
  - 如果仅从jvm的角度来看，要看下新生代和老年代的垃圾回收机制是什么。如果新生代是serial，会默认使用copying算法，利用两块eden和survivor来进行处理。
  - 但是默认当遇到超大对象时，会直接将超大对象放置到老年代中，而不用走正常对象的存活次数记录。
  - 因为要放置的是一个byte数组，那么必然需要申请连续的空间，当空间不足时，会进行gc操作。
  - 这里又需要看老年代的gc机制是哪一种。
    - 如果是serial old，那么会采用mark compat，会进行整理，从而整理出连续空间，如果还不够，说明是老年代的空间不够，所谓的堆内存大于100m是新+老共同的结果。
    - 对于 G1 这种按 region 来管理内存的垃圾收集器，可能的情况是没有多个连续的 region，它们的内存总和大于 100M。
    - 如果采用的是cms(concurrent mark sweep)，那么只会标记清理，并不会压缩，所以内存会碎片化，同时可能出现浮游垃圾。
    - 如果是cms的话，即使老年代的空间大于100m，也会出现没有连续的空间供该对象使用。



## **JVM内存结构**

当代主流虚拟机（Hotspot VM）的垃圾回收都采用“分代回收”的算法。“分代回收”是基于这样一个事实：对象的生命周期不同，所以针对不同生命周期的对象可以采取不同的回收方式，以便提高回收效率。

Hotspot VM将堆划分为不同的物理区，就是“分代”思想的体现。如图所示，JVM堆主要由新生代、老年代、永久代构成。

1. 新生代（Young Generation）：大多数对象在新生代中被创建，其中很多对象的生命周期很短。每次新生代的垃圾回收（又称Minor GC）后只有少量对象存活，所以选用复制算法，只需要少量的复制成本就可以完成回收。
   1. 新生代内又分三个区：一个Eden区，两个Survivor区（一般而言），大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到两个Survivor区（中的一个）。当这个Survivor区满时，此区的存活且不满足“晋升”条件的对象将被复制到另外一个Survivor区。
   2. 对象每经历一次Minor   GC，年龄加1，达到“晋升年龄阈值”后，被放到老年代，这个过程也称为“晋升”。显然，“晋升年龄阈值”的大小直接影响着对象在新生代中的停留时间，在Serial和ParNew  GC两种回收器中，“晋升年龄阈值”通过参数MaxTenuringThreshold设定，默认值为15。

2. 老年代（Old  Generation）：在新生代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代，该区域中对象存活率高。老年代的垃圾回收（又称Major  GC）通常使用“标记-清理”或“标记-整理”算法。整堆包括新生代和老年代的垃圾回收称为Full GC（HotSpot  VM里，除了CMS之外，其它能收集老年代的GC都会同时收集整个GC堆，包括新生代）。

3. 永久代（Perm Generation）：主要存放元数据，例如Class、Method的元信息，与垃圾回收要回收的Java对象关系不大。相对于新生代和年老代来说，该区域的划分对垃圾回收影响比较小。



## JVM即时编译器JIT

- .java 文件被编译成 .class 文件的过程，这个编译我们一般称为前端编译，JIT 或解释器会将字节码转换成机器码，这个过程就叫运行时编译。

- **java 从编译到运行的整个过程**

  - 编译后的字节码文件主要包括常量池和方法表集合这两部分
    - 常量池主要记录的是类文件中出现的字面量以及符号引用
    - 方法表集合中主要包含一些方法的字节码、方法访问权限（public、protect、prviate等）、方法名索引（与常量池中的方法引用对应）、描述符索引、JVM 执行指令以及属性集合等。
  - 当一个类被创建实例或者被其它对象引用时，虚拟机在没有加载过该类的情况下，会通过类加载器将字节码文件加载到内存中。
    - 不同的实现类由不同的类加载器加载，JDK 中的本地方法类一般由根加载器（Bootstrploader）加载进来，JDK 中内部实现的扩展类一般由扩展加载器（ExtClassLoader ）实现加载，而程序中的类文件则由系统加载器（AppClassLoader ）实现加载。
  - 类在加载进来之后，会进行连接、初始化，最后才会被使用
    - 在连接过程中，又包括验证、准备和解析三个部分
      - 准备：为类的静态变量分配内存，初始化为系统的初始值
        - private final static int value=123，会在准备阶段分配内存，并初始化值为 123，而如果是 private static int value=123，这个阶段 value 的值仍然为 0
      - 解析：将符号引用转为直接引用的过程
  - 初始化类的静态变量和静态代码块为用户自定义的值，初始化的顺序和 Java 源码从上到下的顺序一致。
    - VM 会保证 <clinit>() 方法的线程安全，保证同一时间只有一个线程执行。

- 即时编译

  - 在 HotSpot 虚拟机中，内置了两个 JIT，分别为 C1 编译器和 C2 编译器，这两个编译器的编译过程是不一样的。
    - C1 编译器是一个简单快速的编译器，主要的关注点在于局部性的优化，适用于执行时间较短或对启动性能有要求的程序。
    - C2 编译器是为长期运行的服务器端应用程序做性能调优的编译器，适用于执行时间较长或对峰值性能有要求的程序
  - Java7 引入了分层编译，这种方式综合了 C1 的启动性能优势和 C2 的峰值性能优势，分层编译将JVM 的执行状态分为了 5 个层次
  - 热点探测
    - 方法调用计数器
    - 回边计数器
      - 建立回边计数器的主要目的是为了触发 OSR（On StackReplacement）编译，即栈上编译

- 编译优化技术

  - 方法内联

    - 方法调用会产生一定的时间和空间方面的开销。
    - 对于那些方法体代码不是很大，又频繁调用的方法来说，这个时间和空间的消耗会很大。方法内联的优化行为就是把目标方法的代码复制到发起调用的方法之中，避免发生真实的方法调用。
    - 热点方法不一定会被 JVM做内联优化，如果这个方法体太大了，JVM 将不执行内联操作。而方法体的大小阈值，我们也可以通过参数设置来优化

  - 逃逸分析

    - 判断一个对象是否被外部方法引用或外部线程访问的分析技术，编译器会根据逃逸分析的结果对代码进行优化。

    - 逃逸分析如果发现一个对象只在方法中使用，就会将对象分配在栈上。

    - 锁消除

      - StringBuffer 和 StringBuilder 的性能基本没什么区别：这是因为在局部方法中创建的对象只能被当前线程访问，无法被其它线程访问，这个变量的读写肯定不会有竞争，这个时候 JIT 编译会对这个对象的方法锁进行锁消除。

      - ```java
        public static String getString(String s1, String s2) {
        	StringBuffer sb = new StringBuffer();
        	sb.append(s1);
        	sb.append(s2);
        	return sb.toString();
        }
        ```

    - 标量替换

      - 逃逸分析证明一个对象不会被外部访问，如果这个对象可以被拆分的话，当程序真正执行的时候可能不创建这个对象，而直接创建它的成员变量来代替。将对象拆分后，可以分配对象的成员变量在栈或寄存器上，原本的对象就无需分配内存空间了。这种编译优化就叫做标量替换

- Class.forName 和 ClassLoader.loadClass 都能加载类，两者在加载类时的区别

  - Class.forName()会初始化类，执行连接和初始化操作
    - Class.forName()除了将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块，还会执行给静态变量赋值的静态方法。
  - classLoader只会执行连接操作，而不会执行初始化操作
    - 不会执行static中的内容
    - spring做类加载的时候用的是ClassLoader





## 如何优化垃圾回收机制

- 回收发生在哪里

  - JVM 的内存区域中，程序计数器、虚拟机栈和本地方法栈这 3 个区域是线程私有的，随着线程的创建而创建，销毁而销毁
  - 垃圾回收的重点就是关注堆和方法区中的内存了，堆中的回收主要是对象的回收，方法区的回收主要是废弃常量和无用的类的回收。

- 对象在什么时候可以被回收

  - 一般一个对象不再被引用，就代表该对象可以被回收
    - 强引用
      - 永远不会被回收
    - 软引用
      - 发生内存溢出时被回收
    - 弱引用
      - 只要发生垃圾回收事件就被回收
    - 虚引用
      - 这个对象被回收时收到系统通知
  - 引用计数算法
    - 虽然引用计数算法的实现简单，判断效率也很高，但它存在着对象之间相互循环引用的问题。
  - 可达性分析算法
    - 当一个对象到 GC Roots 没有任何引用链相连时，就证明此对象是不可用的

- GC 算法

  - SN\SO
  - PNN/PNO
  - PS
  - CMS
  - G1

- GC 性能衡量指标

  - 吞吐量
  - 停顿时间
  - 垃圾回收频率

- 查看 & 分析 GC 日志

  - ```java
    -XX:+PrintGC 输出 GC 日志
    -XX:+PrintGCDetails 输出 GC 的详细日志
    -XX:+PrintGCTimeStamps 输出 GC 的时间戳（以基准时间的形式）
    -XX:+PrintGCDateStamps 输出 GC 的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800） 
    -XX:+PrintHeapAtGC 在进行 GC 的前后打印出堆的信息
    -Xloggc:../logs/gc.log 日志文件的输出路径
    ```

  - GCeasy是一款非常直观的 GC 日志分析工具

- GC 调优策略

  - 降低 Minor GC 频率
    - 由于新生代空间较小，Eden 区很快被填满，就会导致频繁 Minor GC，因此我们可以通过增大新生代空间来降低 Minor GC 的频率。
    - 单次 Minor GC 时间是由两部分组成：T1（扫描新生代）和 T2（复制存活对象）
  - 降低 Full GC 的频率
    - 通常情况下，由于堆内存空间不足或老年代对象太多，会触发 Full GC，频繁的 Full GC 会带来上下文切换，增加系统的性能开销
    - 减少创建大对象
      - 大对象如果超过年轻代最大对象阈值，会被直接创建在老年代；即使被创建在了年轻代，由于年轻代的内存空间有限，通过 Minor GC 之后也会进入到老年代。这种大对象很容易产生较多的 Full GC
    - 增大堆内存空间
  - 选择合适的 GC 回收器
    - 假设我们有这样一个需求，要求每次操作的响应时间必须在 500ms 以内。这个时候我们一般会选择响应速度较快的 GC 回收器，CMS（Concurrent Mark Sweep）回收器和 G1 回收器都是不错的选择。
    - 而当我们的需求对系统吞吐量有要求时，就可以选择 Parallel Scavenge 回收器来提高系统的吞吐量。

- G1 是如何实现更好的 GC 性能的

  - cms在1.9已经被标记为废弃，主要原因在于标记清除下的悬浮内存，导致内存空间碎片化，进而导致fullGC的发生
  - G1将整块内存分配成若干个同等大小的reg。新生代和老年代各自有不同数量的reg组成。垃圾回收的算法应该算是标记整理。所以其规避了cms内存碎片化的问题，大大降低了fullGC的频率，总体更稳定。
    - G1中各代的内存区域里reg间不一定是连续的，所以对于cpu缓存加载机制并不是特别友好，而且大对象占据超过一个reg时还代理内存浪费的问题。所以总的来说1.8可以用G1但值得考虑，首先这个内存空间要大，保证每个reg尽量大，以减少内存浪费。
  - CMS 垃圾收集器是基于标记清除算法实现的，目前主要用于老年代垃圾回收。CMS 收集器的 GC 周期主要由 7 个阶段组成，其中有两个阶段会发生 stop-the-world，其它阶段都是并发执行的
    - 初始化标记、并发标记、并发预请理、可中止的并发预请理、重新标记、并发请理、并发重置
    - 初始化标记、重新标记
  - G1 垃圾收集器是基于标记整理算法实现的，是一个分代垃圾收集器，既负责年轻代，也负责老年代的垃圾回收。
    - 初始标记->并发标记->最终标记->筛选回收
    - Mix GC 主要包括了四个阶段，其中只有并发标记阶段不会发生 STW，其它阶段均会发生 STW
  - 为了避免在回收年轻代时跨代扫描整个老年代，CMS和 G1 都用到了 Card Table 来记录这些引用关系
    - CMS 主要集中在老年代的回收，而 G1 集中在分代回收，包括了年轻代的 Young GC 以及老年代的 Mix GC；G1 使用了 Region 方式对堆内存进行了划分，且基于标记整理算法实现，整体减少了垃圾碎片的产生；
      在初始化标记阶段，搜索可达对象使用到的 Card Table，其实现方式不一样。
    - 只是 G1 在 Card Table 的基础上引入了 RSet，每个 Region 初始化时，都会初始化一个 RSet，RSet 记录了其它 Region 中的对象引用本 Region 对象的关系
  - 并发标记时漏标问题，也就是说，当一个白色标记对象，在垃圾回收被清理掉时，正好有一个对象引用了该白色标记对象，此时由于被回收掉了，就会出现对象丢失的问题。
    - 为了避免上述问题，CMS 采用了 Incremental Update 算法，只要在写屏障（write barrier）里发现一个白对象的引用被赋值到一个黑对象的字段里，那就把这个白对象变成灰色的。而在 G1 中，采用的是 SATB 算法，该算法认为开始时所有能遍历到的对象都是需要标记的，即认为都是活的。
  - G1 具备 Pause Prediction Model ，即停顿预测模型。用户可以设定整个 GC 过程中期望的停顿时间，用参数 -XX:MaxGCPauseMillis 可以指定一个 G1 收集过程的目标停顿时间，默认值 200ms。
  - G1与CMS的优势在于以下几点
    - 并行与并发
    - 分代收集
    - 空间管理

- 不管什么GC，都会发送stop the world，区别是发生的时间长短

  - 而这个时间跟垃圾收集器又有关系，Serial、PartNew、Parallel Scavenge收集器无论是串行还是并行，都会挂起用户线程，而CMS和G1在并发标记时，是不会挂起用户线程，但其他时候一样会挂起用户线程，stop the world的时间相对来说小很多了。
  - 一般情况下，一次full gc将会对年轻代、老年代以及元空间、堆外内存进行垃圾回收
  - 触发FullGC的原因有很多：
    a、当年轻代晋升到老年代的对象大小比目前老年代剩余的空间大小还要大时，此时会触发FullGC；
    b、当老年代的空间使用率超过某阈值时，此时会触发Full GC;
    c、当元空间不足时（JDK1.7永久代不足），也会触发Full GC;
    d、当调用System.gc()也会安排一次Full GC;



## 如何优化JVM内存分配

- 对象在堆中的生存周期
  - 当我们新建一个对象时，对象会被优先分配到新生代的 Eden 区中，这时虚拟机会给对象定义一个对象年龄计数器（通过参数 -XX:MaxTenuringThreshold 设置）
  - 同时，也有另外一种情况，当 Eden 空间不足时，虚拟机将会执行一个新生代的垃圾回收（Minor GC）。这时 JVM 会把存活的对象转移到 Survivor 中，并给对象的年龄 +1。对象在 Survivor 中同样也会经历 MinorGC，每经过一次 MinorGC，对象的年龄将会 +1。
- 查看 JVM 堆内存分配
  - 年轻代和老年代按照默认比例 1:2 进行分配，年轻代中的Eden 和 Survivor 则按照默认比例 8:2 进行分配
- 具体调优方法
  - 调整堆内存空间减少 FullGC
    - -Xms：堆初始大小；
    - -Xmx：堆最大值
  - 调整年轻代减少 MinorGC
- 堆外内存是如何创建和回收的
  - 可以通过directBuffer创建堆外内存，full gc可以对堆外内存进行回收





## 内存持续上升该如何排查问题

- 常用的监控和诊断内存工具

  - 监控整个服务器内存的使用情况
    - top 命令实时显示正在执行进程的 CPU 使用率、内存使用率以及系统负载等信息
      - 通过 top -Hp pid 查看具体线程使用系统资源情况
    - vmstat 命令经常被用来观察进程的上下文切换
    - pidstat 命令深入到线程级别
      - -u：默认的参数，显示各个进程的 cpu 使用情况；
        -r：显示各个进程的内存使用情况；
        -d：显示各个进程的 I/O 使用情况；
        -w：显示每个进程的上下文切换情况；
        -p：指定进程号；
        -t：显示进程中线程的统计信息
      - 我们可以通过相关命令（例如 ps 或 jps）查询到相关进程 ID，再运行以下命令来监测该进程的内存使用情况
  - JVM 的内存分配以及使用情况
    - jstat 可以监测 Java 应用程序的实时运行情况，包括堆内存信息以及垃圾回收信息。
    
      - 如何使用 jstat 查看堆内存的使用情况。我们可以用 jstat -gc pid
    
      - ```
        
        ```
    
        
    
    - 线程堆栈分析工具，最常用的功能就是使用 jstack pid 命令查看线程的堆栈信息，通常会结合 top -Hp pid 或 pidstat -p pid -t 一起查看具体线程的状态，也经常用来排查一些死锁的异常
    
      - 每个线程堆栈的信息中，都可以查看到线程 ID、线程的状态（wait、sleep、running 等状态）以及是否持有锁等。
    
    - 我们可以通过 jmap 命令把堆内存的使用情况 dump 到文件中,我们可以将文件下载下来，使用 MAT 工具打开文件进行分析
    
      - 我们可以使用 jmap -histo[:live] pid 查看堆内存中的对象数目、大小统计直方图，如果带上 live 则只统计活对象
      - 我们可以通过 jmap 命令把堆内存的使用情况 dump 到文件中
      - 们可以将文件下载下来，使用 MAT 工具打开文件进行分析

- **内存泄露和内存溢出**

  - 内存泄漏与内存溢出的关系：内存泄漏很容易导致内存溢出，但内存溢出不一定是内存泄漏导致的
    - 内存泄漏是指不再使用的对象无法得到及时的回收，持续占用内存空间，从而造成内存空间的浪费。
    - 内存溢出则是发生了OutOfMemoryException，内存溢出的情况有很多，例如堆内存空间不足，栈空间不足，以及方法区空间不足都会发生内存溢出异常。
  - 我们平时遇到的内存溢出问题一般分为两种，一种是由于大峰值下没有限流，瞬间创建大量对象而导致的内存溢出；另一种则是由于内存泄漏而导致的内存溢出。
    - 使用限流，我们一般就可以解决第一种内存溢出问题，但其实很多时候，内存溢出往往是内存泄漏导致的，这种问题就是程序的 BUG，我们需要及时找到问题代码。
  - 在使用时，如果 ThreadLocal 使用不恰当，就可能导致内存泄漏。
    - 在启动应用程序之前，我们可以通过 HeapDumpOnOutOfMemoryError 和
      HeapDumpPath 这两个参数开启堆内存异常日志
    - top->jstack->jmap->MAT
      - 从 top 命令查看进程的内存使用情况，可以发现在机器只有 8G 内存且只分配了 4G 内存给 Java 进程的情况下，Java 进程内存使用率已经达到了 55%，再通过 top -Hp pid 查看具体线程占用系统资源情况。
      - 再通过 jstack pid 查看具体线程的堆栈信息，可以发现该线程一直处于 TIMED_WAITING 状态，此时 CPU 使用率和负载并没有出现异常，我们可以排除死锁或 I/O 阻塞的异常问题了。
      - 我们再通过 jmap 查看堆内存的使用情况，可以发现，老年代的使用率几乎快占满了，而且内存一直得不到释放：
      - 通过以上堆内存的情况，我们基本可以判断系统发生了内存泄漏。
      - 我们需要查看具体的堆内存对象，看看是哪个对象占用了堆内存，可以通过 jmap 查看存活对象的数量
    - 如何避免threadLocal内存泄漏
      - ThreadLocal是基于ThreadLocalMap实现的，这个Map的Entry继承了WeakReference，而Entry对象中的key使用了WeakReference封装，也就是说Entry中的key是一个弱引用类型，而弱引用类型只能存活在下次GC之前
      - 如果一个线程调用ThreadLocal的set设置变量，当前ThreadLocalMap则新增一条记录，但发生
        一次垃圾回收，此时key值被回收，而value值依然存在内存中，由于当前线程一直存在，所以
        value值将一直被引用。
      - 我们只需要在使用完该key值之后，通过remove方法remove掉，就可以防止内存泄漏了。
  
  

## JVM调优案例分析与实践

- 常用命令

  - 两种方式都可以查看tomcat进程号
    - ps -ef | grep java
    - jps -lmvV |grep java
  - 查看进程内线程情况	
    - 找到占用cpu时间最长的进程号:2565	
    - top -Hp 2556（2556为上一步查询出来的进程号）	
  - 得到线程号的十六进制数
    - printf "%x\n" 2565（输出为a05）
  - 使用jstack定位问题
    - jstack 21711 | grep a05
  - 查看内存和swap使用情况
    - free -h   		
    - 可以把free的输出看成一个二维数组FO(Free Output)。
    - free的输出一共有四行，第四行为交换区的信息，分别是交换的总量（total），使用量（used）和有多少空闲的交换区（free）

- 内存和SWAP问题

  - swap全称为swap place，即交换区，当内存不够的时候，被踢出的进程被暂时存储到交换区。当需要这条被踢出的进程的时候，就从交换区重新加载到内存，否则它不会主动交换到真实内存中。
  - 系统稳定运行，偶尔发生响应超时的情况。查看下游依赖服务和数据库状态都良好。超时完全是由于服务本身问题造成的。重启不能解决问题，一直会间隔性的发生超时
  - 原因分析
    - 系统内存够用(JVM内存未使用到SWAP内存)，但JVM内存不够，最终导致JVM的频繁垃圾回收（FGC），严重影响性能 (stop the word)
      - 增大JVM内存，但有可能导致第二种情况的问题出现
      - 如果机器资源充足，建议把影响的业务独立拆分，分开部署
      - 如果机器资源不是很充足，只能进行代码的优化了
    - 系统内存不够，把JVM堆部分用到了SWAP，那么此时的垃圾回收需要把SWAP的内存换回到系统物理内存再进行JVM的垃圾回收。最大影响，导致每次GC的时间变得很久
      - 增大系统内存，但是有最大物理内存的限制。一般每个虚拟机的系统内存是固定分配的
      - 分析导致占用内存过大的原因，进行程序优化
    - 物理内存不够用， 大量JVM的堆内存被交换到SWAP后，垃圾回收时，把SWAP内存换回物理内存，但SWAP的内存又不会立即回， 此时可以观察到垃圾回收同时swap使用的内存会变大(其它部分内存要交换到SWAP里)
      - 增大物理内存。
      - 分析导致占用内存过大的原因，进行程序优化。或进行服务的拆分
    - 进程因为内存问题而被系统杀掉。开启SWAP分区，可以有效防止进程因为内存问题而被系统杀掉






























































































