

## Bucket & Metric 聚合分析及嵌套聚合


Bucket & Metric Aggregation
	SELECT COUNT(brand) ->  Metric - ⼀些系列的统计⽅法
	FROM cars 
	GROUP by brand   	->  Bucket - ⼀组满⾜条件的⽂档


Aggregation 的语法
	Aggregation 属于 Search 的 一部分。一般情况下，建议将其 Size 指定为 0

/*

"agg(和Query同级的关键词)":{
	"自定义聚合名字":{
		"type":{
			"agg_body(聚合的定义：不同的Type+Body)"
		}
		[,"meta":{[meta_data_body]}]
		[,"aggs(子聚合查询)":{sub_agg}]
	}
	"自定义聚合名字2":{

	}
}
*/


DELETE /employees
PUT /employees/
{
  "mappings" : {
      "properties" : {
        "age" : {
          "type" : "integer"
        },
        "gender" : {
          "type" : "keyword"
        },
        "job" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 50
            }
          }
        },
        "name" : {
          "type" : "keyword"
        },
        "salary" : {
          "type" : "integer"
        }
      }
    }
}

PUT /employees/_bulk
{ "index" : {  "_id" : "1" } }
{ "name" : "Emma","age":32,"job":"Product Manager","gender":"female","salary":35000 }
{ "index" : {  "_id" : "2" } }
{ "name" : "Underwood","age":41,"job":"Dev Manager","gender":"male","salary": 50000}
{ "index" : {  "_id" : "3" } }
{ "name" : "Tran","age":25,"job":"Web Designer","gender":"male","salary":18000 }
{ "index" : {  "_id" : "4" } }
{ "name" : "Rivera","age":26,"job":"Web Designer","gender":"female","salary": 22000}
{ "index" : {  "_id" : "5" } }
{ "name" : "Rose","age":25,"job":"QA","gender":"female","salary":18000 }
{ "index" : {  "_id" : "6" } }
{ "name" : "Lucy","age":31,"job":"QA","gender":"female","salary": 25000}
{ "index" : {  "_id" : "7" } }
{ "name" : "Byrd","age":27,"job":"QA","gender":"male","salary":20000 }
{ "index" : {  "_id" : "8" } }
{ "name" : "Foster","age":27,"job":"Java Programmer","gender":"male","salary": 20000}
{ "index" : {  "_id" : "9" } }
{ "name" : "Gregory","age":32,"job":"Java Programmer","gender":"male","salary":22000 }
{ "index" : {  "_id" : "10" } }
{ "name" : "Bryant","age":20,"job":"Java Programmer","gender":"male","salary": 9000}
{ "index" : {  "_id" : "11" } }
{ "name" : "Jenny","age":36,"job":"Java Programmer","gender":"female","salary":38000 }
{ "index" : {  "_id" : "12" } }
{ "name" : "Mcdonald","age":31,"job":"Java Programmer","gender":"male","salary": 32000}
{ "index" : {  "_id" : "13" } }
{ "name" : "Jonthna","age":30,"job":"Java Programmer","gender":"female","salary":30000 }
{ "index" : {  "_id" : "14" } }
{ "name" : "Marshall","age":32,"job":"Javascript Programmer","gender":"male","salary": 25000}
{ "index" : {  "_id" : "15" } }
{ "name" : "King","age":33,"job":"Java Programmer","gender":"male","salary":28000 }
{ "index" : {  "_id" : "16" } }
{ "name" : "Mccarthy","age":21,"job":"Javascript Programmer","gender":"male","salary": 16000}
{ "index" : {  "_id" : "17" } }
{ "name" : "Goodwin","age":25,"job":"Javascript Programmer","gender":"male","salary": 16000}
{ "index" : {  "_id" : "18" } }
{ "name" : "Catherine","age":29,"job":"Javascript Programmer","gender":"female","salary": 20000}
{ "index" : {  "_id" : "19" } }
{ "name" : "Boone","age":30,"job":"DBA","gender":"male","salary": 30000}
{ "index" : {  "_id" : "20" } }
{ "name" : "Kathy","age":29,"job":"DBA","gender":"female","salary": 20000}


Metric Aggregation
	单值分析：只输出⼀个分析结果
		min, max, avg, sum
		Cardinality （类似 distinct Count） 
	多值分析：输出多个分析结果
		stats, extended stats
		percentile, percentile rank
		top hits （排在前⾯的示例）

Bucket
	按照⼀定的规则，将⽂档分配到不同的桶中，从⽽达到分类的⽬的。ES 提供的⼀些常⻅的 Bucket Aggregation
		Terms
		数字类型
			Range / Data Range
			Histogram / Date Histogram
		⽀持嵌套：也就在桶⾥再做分桶


# Metric 聚合，找到最低的工资
POST employees/_search
{
  "size": 0,
  "aggs": {
    "min_salary": {
      "min": {
        "field":"salary"
      }
    }
  }
}


# 多个 Metric 聚合，找到最低最高和平均工资
POST employees/_search
{
  "size": 0,
  "aggs": {
    "max_salary": {
      "max": {
        "field": "salary"
      }
    },
    "min_salary": {
      "min": {
        "field": "salary"
      }
    },
    "avg_salary": {
      "avg": {
        "field": "salary"
      }
    }
  }
}

# 一个聚合，输出多值
POST employees/_search
{
  "size": 0,
  "aggs": {
    "stats_salary": {
      "stats": {
        "field":"salary"
      }
    }
  }
}
Result：
  "aggregations" : {
    "stats_salary" : {
      "count" : 20,
      "min" : 9000.0,
      "max" : 50000.0,
      "avg" : 24700.0,
      "sum" : 494000.0
    }
  }

Terms Aggregation
	字段需要打开 fielddata，才能进⾏ Terms Aggregation
		Keyword 默认⽀持 doc_values
		Text 需要在 Mapping 中 enable。会按照分词后的结果进⾏分

# 对keword 进行聚合
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field":"job.keyword"
      }
    }
  }
}


# 对 Text 字段进行 terms 聚合查询，失败
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field":"job"
      }
    }
  }
}

# 对 Text 字段打开 fielddata，支持terms aggregation
PUT employees/_mapping
{
  "properties" : {
    "job":{
       "type": "text",
       "fielddata": true
    }
  }
}


# 对 Text 字段进行 terms 分词。分词后的terms
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field":"job"
      }
    }
  }
}

POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field":"job.keyword"
      }
    }
  }
}


# 对job.keyword 和 job 进行 terms 聚合，分桶的总数并不一样
	Cardinality:类似 SQL 中的 Distinct

POST employees/_search
{
  "size": 0,
  "aggs": {
    "cardinate": {
      "cardinality": {
        "field": "job"
      }
    }
  }
}


# 对 性别的 keyword 进行聚合
POST employees/_search
{
  "size": 0,
  "aggs": {
    "gender": {
      "terms": {
        "field":"gender"
      }
    }
  }
}


#指定 bucket 的 size
POST employees/_search
{
  "size": 0,
  "aggs": {
    "ages": {
      "terms": {
        "field":"age",
        "size":3
      }
    }
  }
}

Bucket Size & Top Hits Demo
	应⽤场景：当获取分桶后，桶内最匹配的顶部⽂档列表
	Size：按年龄分桶，找出指定数据量的分桶信息
	Top Hits：查看各个⼯种中，年纪最⼤的 3 名员⼯


# 指定size，不同工种中，年纪最大的3个员工的具体信息
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field":"job.keyword"
      },
      "aggs":{
        "old_employee":{
          "top_hits":{
            "size":3,
            "sort":[
              {
                "age":{
                  "order":"desc"
                }
              }
            ]
          }
        }
      }
    }
  }
}

Range & Histogram 聚合
	按照数字的范围，进⾏分桶
	在 Range Aggregation 中，可以⾃定义 Key




#Salary Ranges 分桶，可以自己定义 key
POST employees/_search
{
  "size": 0,
  "aggs": {
    "salary_range": {
      "range": {
        "field":"salary",
        "ranges":[
          {
            "to":10000
          },
          {
            "from":10000,
            "to":20000
          },
          {
            "key":">20000",
            "from":20000
          }
        ]
      }
    }
  }
}


#Salary Histogram,工资0到10万，以 5000一个区间进行分桶
POST employees/_search
{
  "size": 0,
  "aggs": {
    "salary_histrogram": {
      "histogram": {
        "field": "salary",
        "interval": 5000,
        "extended_bounds": {
          "min": 0,
          "max": 100000
        }
      }
    }
  }
}



# 嵌套聚合，按照工作类型分桶，并统计工资信息
	⽀持嵌套：也就在桶⾥再做分桶
POST employees/_search
{
  "size": 0,
  "aggs": {
    "Job_salary_stats": {
      "terms": {
        "field": "job.keyword"
      },
      "aggs": {
        "salary": {
          "stats": {
            "field": "salary"
          }
        }
      }
    }
  }
}

# 多次嵌套。根据工作类型分桶，然后按照性别分桶，计算工资的统计信息
POST employees/_search
{
  "size": 0,
  "aggs": {
    "Job_gender_stats": {
      "terms": {
        "field": "job.keyword"
      },
      "aggs": {
        "gender_stats": {
          "terms": {
            "field": "gender"
          },
          "aggs": {
            "salary_stats": {
              "stats": {
                "field": "salary"
              }
            }
          }
        }
      }
    }
  }
}






------------


## Pipeline 聚合分析

Pipeline
	管道的概念: ⽀持对聚合分析的结果，再次进⾏聚合分析
Pipeline 的分析结果会输出到原结果中，根据位置的不同，分为两类
	Sibling - 结果和现有分析结果同级
		Max，min，Avg & Sum Bucket
		Stats，Extended Status Bucket
		Percentiles Bucket
	Parent - 结果内嵌到现有的聚合分析结果之中
		Derivative （求导）
		Cumultive Sum （累计求和）
		Moving Function (滑动窗⼝)

Sibling Pipeline 的例⼦
	对不同类型⼯作的，平均⼯资
		求最⼤
		平均
		统计信息
		百分位数





DELETE employees
PUT /employees/_bulk
{ "index" : {  "_id" : "1" } }
{ "name" : "Emma","age":32,"job":"Product Manager","gender":"female","salary":35000 }
{ "index" : {  "_id" : "2" } }
{ "name" : "Underwood","age":41,"job":"Dev Manager","gender":"male","salary": 50000}
{ "index" : {  "_id" : "3" } }
{ "name" : "Tran","age":25,"job":"Web Designer","gender":"male","salary":18000 }
{ "index" : {  "_id" : "4" } }
{ "name" : "Rivera","age":26,"job":"Web Designer","gender":"female","salary": 22000}
{ "index" : {  "_id" : "5" } }
{ "name" : "Rose","age":25,"job":"QA","gender":"female","salary":18000 }
{ "index" : {  "_id" : "6" } }
{ "name" : "Lucy","age":31,"job":"QA","gender":"female","salary": 25000}
{ "index" : {  "_id" : "7" } }
{ "name" : "Byrd","age":27,"job":"QA","gender":"male","salary":20000 }
{ "index" : {  "_id" : "8" } }
{ "name" : "Foster","age":27,"job":"Java Programmer","gender":"male","salary": 20000}
{ "index" : {  "_id" : "9" } }
{ "name" : "Gregory","age":32,"job":"Java Programmer","gender":"male","salary":22000 }
{ "index" : {  "_id" : "10" } }
{ "name" : "Bryant","age":20,"job":"Java Programmer","gender":"male","salary": 9000}
{ "index" : {  "_id" : "11" } }
{ "name" : "Jenny","age":36,"job":"Java Programmer","gender":"female","salary":38000 }
{ "index" : {  "_id" : "12" } }
{ "name" : "Mcdonald","age":31,"job":"Java Programmer","gender":"male","salary": 32000}
{ "index" : {  "_id" : "13" } }
{ "name" : "Jonthna","age":30,"job":"Java Programmer","gender":"female","salary":30000 }
{ "index" : {  "_id" : "14" } }
{ "name" : "Marshall","age":32,"job":"Javascript Programmer","gender":"male","salary": 25000}
{ "index" : {  "_id" : "15" } }
{ "name" : "King","age":33,"job":"Java Programmer","gender":"male","salary":28000 }
{ "index" : {  "_id" : "16" } }
{ "name" : "Mccarthy","age":21,"job":"Javascript Programmer","gender":"male","salary": 16000}
{ "index" : {  "_id" : "17" } }
{ "name" : "Goodwin","age":25,"job":"Javascript Programmer","gender":"male","salary": 16000}
{ "index" : {  "_id" : "18" } }
{ "name" : "Catherine","age":29,"job":"Javascript Programmer","gender":"female","salary": 20000}
{ "index" : {  "_id" : "19" } }
{ "name" : "Boone","age":30,"job":"DBA","gender":"male","salary": 30000}
{ "index" : {  "_id" : "20" } }
{ "name" : "Kathy","age":29,"job":"DBA","gender":"female","salary": 20000}



# 平均工资最低的工作类型
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "size": 10
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        }
      }
    },
    "min_salary_by_job":{
      "min_bucket": {
        "buckets_path": "jobs>avg_salary"
      }
    }
  }
}


# 平均工资最高的工作类型
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "size": 10
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        }
      }
    },
    "max_salary_by_job":{
      "max_bucket": {
        "buckets_path": "jobs>avg_salary"
      }
    }
  }
}
Result：
    "max_salary_by_job" : {
      "value" : 50000.0,
      "keys" : [
        "Dev Manager"
      ]
    }




# 平均工资的平均工资
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "size": 10
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        }
      }
    },
    "avg_salary_by_job":{
      "avg_bucket": {
        "buckets_path": "jobs>avg_salary"
      }
    }
  }
}
Result：
    "avg_salary_by_job" : {
      "value" : 27974.48979591837
    }


# 平均工资的统计分析
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "size": 10
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        }
      }
    },
    "stats_salary_by_job":{
      "stats_bucket": {
        "buckets_path": "jobs>avg_salary"
      }
    }
  }
}
Result：
    "stats_salary_by_job" : {
      "count" : 7,
      "min" : 19250.0,
      "max" : 50000.0,
      "avg" : 27974.48979591837,
      "sum" : 195821.42857142858
    }


# 平均工资的百分位数
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "size": 10
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        }
      }
    },
    "percentiles_salary_by_job":{
      "percentiles_bucket": {
        "buckets_path": "jobs>avg_salary"
      }
    }
  }
}



#按照年龄对平均工资求导
POST employees/_search
{
  "size": 0,
  "aggs": {
    "age": {
      "histogram": {
        "field": "age",
        "min_doc_count": 1,
        "interval": 1
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        },
        "derivative_avg_salary":{
          "derivative": {
            "buckets_path": "avg_salary"
          }
        }
      }
    }
  }
}


#Cumulative_sum
POST employees/_search
{
  "size": 0,
  "aggs": {
    "age": {
      "histogram": {
        "field": "age",
        "min_doc_count": 1,
        "interval": 1
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        },
        "cumulative_salary":{
          "cumulative_sum": {
            "buckets_path": "avg_salary"
          }
        }
      }
    }
  }
}
Result：
	每个key一次的累加avg_salary总和（累计求和，取的是一个key的，不是一个key的全部）


#Moving Function
	window：按key个数分
POST employees/_search
{
  "size": 0,
  "aggs": {
    "age": {
      "histogram": {
        "field": "age",
        "min_doc_count": 1,
        "interval": 1
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        },
        "moving_avg_salary":{
          "moving_fn": {
            "buckets_path": "avg_salary",
            "window":10,
            "script": "MovingFunctions.min(values)"
          }
        }
      }
    }
  }
}




----------


## 聚合的作⽤范围及排序


聚合的作⽤范围

	ES 聚合分析的默认作⽤范围是 query 的查询结果集
	同时 ES 还⽀持以下⽅式改变聚合的作⽤范围
		Filter
		Post_Filter
		Global



DELETE /employees
PUT /employees/
{
  "mappings" : {
      "properties" : {
        "age" : {
          "type" : "integer"
        },
        "gender" : {
          "type" : "keyword"
        },
        "job" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 50
            }
          }
        },
        "name" : {
          "type" : "keyword"
        },
        "salary" : {
          "type" : "integer"
        }
      }
    }
}

PUT /employees/_bulk
{ "index" : {  "_id" : "1" } }
{ "name" : "Emma","age":32,"job":"Product Manager","gender":"female","salary":35000 }
{ "index" : {  "_id" : "2" } }
{ "name" : "Underwood","age":41,"job":"Dev Manager","gender":"male","salary": 50000}
{ "index" : {  "_id" : "3" } }
{ "name" : "Tran","age":25,"job":"Web Designer","gender":"male","salary":18000 }
{ "index" : {  "_id" : "4" } }
{ "name" : "Rivera","age":26,"job":"Web Designer","gender":"female","salary": 22000}
{ "index" : {  "_id" : "5" } }
{ "name" : "Rose","age":25,"job":"QA","gender":"female","salary":18000 }
{ "index" : {  "_id" : "6" } }
{ "name" : "Lucy","age":31,"job":"QA","gender":"female","salary": 25000}
{ "index" : {  "_id" : "7" } }
{ "name" : "Byrd","age":27,"job":"QA","gender":"male","salary":20000 }
{ "index" : {  "_id" : "8" } }
{ "name" : "Foster","age":27,"job":"Java Programmer","gender":"male","salary": 20000}
{ "index" : {  "_id" : "9" } }
{ "name" : "Gregory","age":32,"job":"Java Programmer","gender":"male","salary":22000 }
{ "index" : {  "_id" : "10" } }
{ "name" : "Bryant","age":20,"job":"Java Programmer","gender":"male","salary": 9000}
{ "index" : {  "_id" : "11" } }
{ "name" : "Jenny","age":36,"job":"Java Programmer","gender":"female","salary":38000 }
{ "index" : {  "_id" : "12" } }
{ "name" : "Mcdonald","age":31,"job":"Java Programmer","gender":"male","salary": 32000}
{ "index" : {  "_id" : "13" } }
{ "name" : "Jonthna","age":30,"job":"Java Programmer","gender":"female","salary":30000 }
{ "index" : {  "_id" : "14" } }
{ "name" : "Marshall","age":32,"job":"Javascript Programmer","gender":"male","salary": 25000}
{ "index" : {  "_id" : "15" } }
{ "name" : "King","age":33,"job":"Java Programmer","gender":"male","salary":28000 }
{ "index" : {  "_id" : "16" } }
{ "name" : "Mccarthy","age":21,"job":"Javascript Programmer","gender":"male","salary": 16000}
{ "index" : {  "_id" : "17" } }
{ "name" : "Goodwin","age":25,"job":"Javascript Programmer","gender":"male","salary": 16000}
{ "index" : {  "_id" : "18" } }
{ "name" : "Catherine","age":29,"job":"Javascript Programmer","gender":"female","salary": 20000}
{ "index" : {  "_id" : "19" } }
{ "name" : "Boone","age":30,"job":"DBA","gender":"male","salary": 30000}
{ "index" : {  "_id" : "20" } }
{ "name" : "Kathy","age":29,"job":"DBA","gender":"female","salary": 20000}



# Query
POST employees/_search
{
  "size": 0,
  "query": {
    "range": {
      "age": {
        "gte": 20
      }
    }
  },
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword"
      }
    }
  }
}


#Filter
	只对当前的子聚合语句生效
	all_jobs还是基于query的作用范围

POST employees/_search
{
  "size": 0,
  "aggs": {
    "older_person": {
      "filter": {
        "range": {
          "age": {
            "from": 35
          }
        }
      },
      "aggs": {
        "jobs": {
          "terms": {
            "field": "job.keyword"
          }
        }
      }
    },
    "all_jobs": {
      "terms": {
        "field": "job.keyword"
      }
    }
  }
}



#Post field ： 一条语句，找出所有的job类型。还能找到聚合后符合条件的结果
	是对聚合分析后的⽂档进⾏再次过滤
	Size ⽆需设置为 0 
	使⽤场景
		⼀条语句，获取聚合信息 + 获取符合条件的⽂档



POST employees/_search
{
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword"
      }
    }
  },
  "post_filter": {
    "match": {
      "job.keyword": "Dev Manager"
    }
  }
}


#global ： ⽆视 query，对全部⽂档进⾏统计

POST employees/_search
{
  "size": 0,
  "query": {
    "range": {
      "age": {
        "gte": 40
      }
    }
  },
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword"
      }
    },
    "all": {
      "global": {},
      "aggs": {
        "salary_avg": {
          "avg": {
            "field": "salary"
          }
        }
      }
    }
  }
}



#排序 order
	指定 order， 按照 count 和 key 进⾏排序
		默认情况，按照 count 降序排序
		指定 size，就能返回相应的桶

#count and key
POST employees/_search
{
  "size": 0,
  "query": {
    "range": {
      "age": {
        "gte": 20
      }
    }
  },
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "order": [
          {
            "_count": "asc"
          },
          {
            "_key": "desc"
          }
        ]
      }
    }
  }
}



# 基于⼦聚合的值排序
	与terms一级

POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "order": [
          {
            "avg_salary": "desc"
          }
        ]
      },
      "aggs": {
        "avg_salary": {
          "avg": {
            "field": "salary"
          }
        }
      }
    }
  }
}


#排序 order
#count and key
POST employees/_search
{
  "size": 0,
  "aggs": {
    "jobs": {
      "terms": {
        "field": "job.keyword",
        "order": [
          {
            "stats_salary.min": "desc"
          }
        ]
      },
      "aggs": {
        "stats_salary": {
          "stats": {
            "field": "salary"
          }
        }
      }
    }
  }
}




------------

## 聚合的精准度问题

分布式系统的近似统计算法
				数据量

	Hadoop离线计算   	 近似计算
	
精确度							实时性
				有限数据计算

只能满足两条


DELETE my_flights
PUT my_flights
{
  "settings": {
    "number_of_shards": 20
  },
  "mappings" : {
      "properties" : {
        "AvgTicketPrice" : {
          "type" : "float"
        },
        "Cancelled" : {
          "type" : "boolean"
        },
        "Carrier" : {
          "type" : "keyword"
        },
        "Dest" : {
          "type" : "keyword"
        },
        "DestAirportID" : {
          "type" : "keyword"
        },
        "DestCityName" : {
          "type" : "keyword"
        },
        "DestCountry" : {
          "type" : "keyword"
        },
        "DestLocation" : {
          "type" : "geo_point"
        },
        "DestRegion" : {
          "type" : "keyword"
        },
        "DestWeather" : {
          "type" : "keyword"
        },
        "DistanceKilometers" : {
          "type" : "float"
        },
        "DistanceMiles" : {
          "type" : "float"
        },
        "FlightDelay" : {
          "type" : "boolean"
        },
        "FlightDelayMin" : {
          "type" : "integer"
        },
        "FlightDelayType" : {
          "type" : "keyword"
        },
        "FlightNum" : {
          "type" : "keyword"
        },
        "FlightTimeHour" : {
          "type" : "keyword"
        },
        "FlightTimeMin" : {
          "type" : "float"
        },
        "Origin" : {
          "type" : "keyword"
        },
        "OriginAirportID" : {
          "type" : "keyword"
        },
        "OriginCityName" : {
          "type" : "keyword"
        },
        "OriginCountry" : {
          "type" : "keyword"
        },
        "OriginLocation" : {
          "type" : "geo_point"
        },
        "OriginRegion" : {
          "type" : "keyword"
        },
        "OriginWeather" : {
          "type" : "keyword"
        },
        "dayOfWeek" : {
          "type" : "integer"
        },
        "timestamp" : {
          "type" : "date"
        }
      }
    }
}


POST _reindex
{
  "source": {
    "index": "kibana_sample_data_flights"
  },
  "dest": {
    "index": "my_flights"
  }
}

GET kibana_sample_data_flights/_count
GET my_flights/_count


get kibana_sample_data_flights/_search


Min 聚合分析的执⾏流程
	到CN上，CN分发请求到DN，DN计算当前节点的min value返回给CN，CN再min（P0,P1,P2）

Terms Aggregation 的返回值
	在 Terms Aggregation 的返回中有两个特殊的数值
		doc_count_error_upper_bound ： 被遗漏的term 分桶，包含的⽂档，有可能的最⼤值
		sum_other_doc_count: 除了返回结果 bucket 的 terms 以外，其他 terms 的⽂档总数（总数-返回的总数）


Terms 聚合分析的执⾏流程
	到CN上，CN分发请求到DN，DN计算当前节点的top3返回给CN，CN返回的top3不一定准确

Terms 不正确的案例

TOP3 A12/B6/C4
					
	Node1 A6/B4/C4/D3	TOP3 A (6) / B (4) / C (4)
	Node2 A6/B2/C1/D3	TOP3 A (6) / B (2) / D (3)

doc_count_error_upper_bound=4+3=7
sum_other_doc_count=29-22=7



GET kibana_sample_data_flights/_search
{
  "size": 0,
  "aggs": {
    "weather": {
      "terms": {
        "field":"OriginWeather",
        "size":5,
        "show_term_doc_count_error":true
      }
    }
  }
}

如何解决 Terms 不准的问题：提升 shard_size 的参数
	Terms 聚合分析不准的原因，数据分散在多个分⽚上， Coordinating Node ⽆法获取数据全貌
	解决⽅案 1：当数据量不⼤时，设置 Primary Shard 为 1；实现准确性
	⽅案 2：在分布式数据上，设置 shard_size 参 数，提⾼精确度
		原理：每次从 Shard 上额外多获取数据，提升准确率

	shard_size 设定
		调整 shard size ⼤⼩，降低 doc_count_error_upper_bound 来提升准确度
			增加整体计算量，提⾼了准确度，但会降低相应时间
		Shard Size 默认⼤⼩设定
			shard size = size *1.5 +10


GET my_flights/_search
{
  "size": 0,
  "aggs": {
    "weather": {
      "terms": {
        "field":"OriginWeather",
        "size":1,
        "shard_size":1,
        "show_term_doc_count_error":true
      }
    }
  }
}




------

## 对象及 Nested 对象

数据的关联关系
	真实世界中有很多重要的关联关系
		博客 / 作者 / 评论
		银⾏账户有多次交易记录
		客户有多个银⾏账户
		⽬录⽂件有多个⽂件和⼦⽬录

关系型数据库的范式化设计
	范式化设计(Normalization)的主要⽬标是“减少不必要的更新”
	副作⽤：⼀个完全范式化设计的数据库会经常⾯临“查询缓慢”的问题
		数据库越范式化，就需要 Join 越多的表
	范式化节省了存储空间，但是存储空间却越来越便宜
	范式化简化了更新，但是数据“读”取操作可能更多

	1NF – 消除⾮主属性对键的部分函数依赖
	2NF – 消除⾮主要属性对键的传递函数依赖
	3NF – 消除主属性对键的传递函数依赖
	BCNF –主属性不依赖于主属性


Denormalization
	反范式化设计
		数据 “Flattening”，不使⽤关联关系，⽽是在⽂档中保存冗余的数据拷⻉
	优点：⽆需处理 Joins 操作，数据读取性能好
		Elasticsearch 通过压缩 _source 字段，减少磁盘空间的开销
	缺点：不适合在数据频繁修改的场景
		⼀条数据（⽤户名）的改动，可能会引起很多数据的更新

在 Elasticsearch 中处理关联关系
	关系型数据库，⼀般会考虑 Normalize 数据；在 Elasticsearch，往往考虑 Denormalize 数据
		Denormalize 的好处：读的速度变快 / ⽆需表连接 / ⽆需⾏锁
	Elasticsearch 并不擅⻓处理关联关系。我们⼀般采⽤以下四种⽅法处理关联
		对象类型
		嵌套对象(Nested Object)
		⽗⼦关联关系(Parent / Child )
		应⽤端关联



案例 1：博客和其作者信息
	对象类型
		在每⼀博客的⽂档中都保留作者的信息
		如果作者信息发⽣变化，需要修改相关的博客⽂档


DELETE blog
# 设置blog的 Mapping
PUT /blog
{
  "mappings": {
    "properties": {
      "content": {
        "type": "text"
      },
      "time": {
        "type": "date"
      },
      "user": {
        "properties": {
          "city": {
            "type": "text"
          },
          "userid": {
            "type": "long"
          },
          "username": {
            "type": "keyword"
          }
        }
      }
    }
  }
}


# 插入一条 Blog 信息
PUT blog/_doc/1
{
  "content":"I like Elasticsearch",
  "time":"2019-01-01T00:00:00",
  "user":{
    "userid":1,
    "username":"Jack",
    "city":"Shanghai"
  }
}


# 通过⼀条查询即可获取到博客和作者信息
POST blog/_search
{
  "query": {
    "bool": {
      "must": [
        {"match": {"content": "Elasticsearch"}},
        {"match": {"user.username": "Jack"}}
      ]
    }
  }
}

案例 2：包含对象数组的⽂档


DELETE my_movies

# 电影的Mapping信息
PUT my_movies
{
      "mappings" : {
      "properties" : {
        "actors" : {
          "properties" : {
            "first_name" : {
              "type" : "keyword"
            },
            "last_name" : {
              "type" : "keyword"
            }
          }
        },
        "title" : {
          "type" : "text",
          "fields" : {
            "keyword" : {
              "type" : "keyword",
              "ignore_above" : 256
            }
          }
        }
      }
    }
}


# 写入一条电影信息
POST my_movies/_doc/1
{
  "title":"Speed",
  "actors":[
    {
      "first_name":"Keanu",
      "last_name":"Reeves"
    },
    {
      "first_name":"Dennis",
      "last_name":"Hopper"
    }

  ]
}

# 查询电影信息
POST my_movies/_search
{
  "query": {
    "bool": {
      "must": [
        {"match": {"actors.first_name": "Keanu"}},
        {"match": {"actors.last_name": "Hopper"}}
      ]
    }
  }
}

为什么会搜到不需要的结果
		"title":"Speed"
		"actors.first_name":["Keanu","Dennis"]
		"actors.last_name":["Reeves","Hopper"]
	存储时，内部对象的边界并没有考虑在内，JSON 格式被处理成扁平式键值对的结构
	当对多个字段进⾏查询时，导致了意外的搜索结果
	可以⽤ Nested Data Type 解决这个问题
		

什么是 Nested Data Type
	当对象包含了多值对象时，可以使⽤嵌套对象(Nested Object)解决查询正确性的问题
	Nested 数据类型：允许对象数组中的对象被独⽴索引
	使⽤ nested 和 properties 关键字，将所有 actors 索引到多个分隔的⽂档
	在内部， Nested ⽂档会被保存在两个Lucene ⽂档中，在查询时做 Join 处理
		"title":"Speed"
		"actors.first_name":["Keanu","Dennis"]
		"actors.last_name":["Reeves","Hopper"]
			Doc: Keanu Reeves 
			Doc: Denis Hooper


DELETE my_movies

PUT my_movies
{
  "mappings": {
    "properties": {
      "actors": {
        "type": "nested",
        "properties": {
          "first_name": {
            "type": "keyword"
          },
          "last_name": {
            "type": "keyword"
          }
        }
      },
      "title": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 256
          }
        }
      }
    }
  }
}




POST my_movies/_doc/1
{
  "title":"Speed",
  "actors":[
    {
      "first_name":"Keanu",
      "last_name":"Reeves"
    },

    {
      "first_name":"Dennis",
      "last_name":"Hopper"
    }

  ]
}

# Nested 查询(嵌套查询)
POST my_movies/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "title": "Speed"
          }
        },
        {
          "nested": {
            "path": "actors",
            "query": {
              "bool": {
                "must": [
                  {
                    "match": {
                      "actors.first_name": "Keanu"
                    }
                  },
                  {
                    "match": {
                      "actors.last_name": "Hopper"
                    }
                  }
                ]
              }
            }
          }
        }
      ]
    }
  }
}





# Nested Aggregation(嵌套聚合)
POST my_movies/_search
{
  "size": 0,
  "aggs": {
    "actors": {
      "nested": {
        "path": "actors"
      },
      "aggs": {
        "actor_name": {
          "terms": {
            "field": "actors.first_name",
            "size": 10
          }
        }
      }
    }
  }
}


# 普通 aggregation不工作
POST my_movies/_search
{
  "size": 0,
  "aggs": {
    "actors": {
      "terms": {
        "field": "actors.first_name",
        "size": 10
      }
    }
  }
}


---------


## ⽂档的⽗⼦关系

Parent / Child
	对象和 Nested 对象的局限性
		每次更新，需要重新索引整个对象（包括根对象和嵌套对象）
	ES 提供了类似关系型数据库中 Join 的实现。使⽤ Join 数据类型实现，可以通过维护 Parent/ Child 的关系，从⽽分离两个对象
		⽗⽂档和⼦⽂档是两个独⽴的⽂档
		更新⽗⽂档⽆需重新索引⼦⽂档。⼦⽂档被添加，更新或者删除也不会影响到⽗⽂档和其他的⼦⽂档

⽗⼦关系
	定义⽗⼦关系的⼏个步骤
		1. 设置索引的 Mapping
		2. 索引⽗⽂档
		3. 索引⼦⽂档
		4. 按需查询⽂档


DELETE my_blogs

	"type": "join"：指明join类型
	relations：声明PC关系
	blog：Parent名称
	comment：child名称

# 设定 Parent/Child Mapping
PUT my_blogs
{
  "settings": {
    "number_of_shards": 2
  },
  "mappings": {
    "properties": {
      "blog_comments_relation": {
        "type": "join",	
        "relations": {	
          "blog": "comment"
        }
      },
      "content": {
        "type": "text"
      },
      "title": {
        "type": "keyword"
      }
    }
  }
}


#索引父文档
PUT my_blogs/_doc/blog1 //父文档id
{
  "title":"Learning Elasticsearch",
  "content":"learning ELK @ geektime",
  "blog_comments_relation":{ //声明文档类型
    "name":"blog"
  }
}

#索引父文档
PUT my_blogs/_doc/blog2
{
  "title":"Learning Hadoop",
  "content":"learning Hadoop",
    "blog_comments_relation":{
    "name":"blog"
  }
}


#索引子文档
PUT my_blogs/_doc/comment1?routing=blog1 //子文档id 指定routing，确保和父文档索引到相同的分片
{
  "comment":"I am learning ELK",
  "username":"Jack",
  "blog_comments_relation":{
    "name":"comment",
    "parent":"blog1"//父文档的id
  }
}

#索引子文档
PUT my_blogs/_doc/comment2?routing=blog2
{
  "comment":"I like Hadoop!!!!!",
  "username":"Jack",
  "blog_comments_relation":{
    "name":"comment",
    "parent":"blog2"
  }
}

#索引子文档
PUT my_blogs/_doc/comment3?routing=blog2
{
  "comment":"Hello Hadoop",
  "username":"Bob",
  "blog_comments_relation":{
    "name":"comment",
    "parent":"blog2"
  }
}

Parent / Child 所⽀持的查询
	查询所有⽂档
	Parent Id 查询
	Has Child 查询
	Has Parent 查询

# 查询所有文档
POST my_blogs/_search


#根据父文档ID查看
GET my_blogs/_doc/blog2

# Parent Id 查询
POST my_blogs/_search
{
  "query": {
    "parent_id": {
      "type": "comment",
      "id": "blog2"
    }
  }
}
# Has Child 查询
	返回⽗⽂档
	通过对⼦⽂档进⾏查询
		返回具有相关⼦⽂档的⽗⽂档
		⽗⼦⽂档在相同的分⽚上，因此 Join效率⾼

POST my_blogs/_search
{
  "query": {
    "has_child": {
      "type": "comment",
      "query" : {
        "match": {
          "username" : "Jack"
        }
      }
    }
  }
}


# Has Parent 查询，返回相关的子文档

POST my_blogs/_search
{
  "query": {
    "has_parent": {
      "parent_type": "blog",
      "query" : {
         "match": {
           "title" : "Learning Hadoop"
        }
      }
    }
  }
}



#通过ID和routing ，访问子文档
GET my_blogs/_doc/comment3?routing=blog2

#更新子文档
PUT my_blogs/_doc/comment3?routing=blog2
{
    "comment": "Hello Hadoop",
    "blog_comments_relation": {
      "name": "comment",
      "parent": "blog2"
    }
}



嵌套对象 v.s ⽗⼦⽂档

	 	Nested Object 						Parent / Child
优点 	⽂档存储在⼀起，读取性能⾼ 			⽗⼦⽂档可以独⽴更新
缺点 	更新嵌套的⼦⽂档时，需要更新整个⽂档 	需要额外的内存维护关系。读取性能相对差
适⽤场景 ⼦⽂档偶尔更新，以查询为主 			⼦⽂档更新频繁


-------


## Update By Query & Reindex API

使⽤场景
	⼀般在以下⼏种情况时，我们需要重建索引
		索引的 Mappings 发⽣变更：字段类型更改，分词器及字典更新
		索引的 Settings 发⽣变更：索引的主分⽚数发⽣改变
		集群内，集群间需要做数据迁移
	Elasticsearch 的内置提供的 API
		Update By Query：在现有索引上重建
		Reindex：在其他索引上重建索引



DELETE blogs/

# 写入文档
PUT blogs/_doc/1
{
  "content":"Hadoop is cool",
  "keyword":"hadoop"
}

# 查看 Mapping
GET blogs/_mapping




# 案例 1：为索引增加⼦字段
	改变 Mapping，增加⼦字段，使⽤英⽂分词器
PUT blogs/_mapping
{
      "properties" : {
        "content" : {
          "type" : "text",
          "fields" : {
            "english" : {
              "type" : "text",
              "analyzer":"english"
            }
          }
        }
      }
    }



# 查询 Mapping 变更前写入的文档
	此时尝试对⼦字段进⾏查询
	虽然有数据已经存在，但是没有返回结果

POST blogs/_search
{
  "query": {
    "match": {
      "content.english": "Hadoop"
    }
  }
}



# 写入文档
PUT blogs/_doc/2
{
  "content":"Elasticsearch rocks",
    "keyword":"elasticsearch"
}

# 查询新写入文档
POST blogs/_search
{
  "query": {
    "match": {
      "content.english": "Elasticsearch"
    }
  }

}



# Update所有文档
POST blogs/_update_by_query
{

}

# 查询之前写入的文档
POST blogs/_search
{
  "query": {
    "match": {
      "content.english": "Hadoop"
    }
  }
}


# 查询
GET blogs/_mapping

案例 2：更改已有字段类型的 Mappings
	ES 不允许在原有 Mapping 上对字段类型进⾏修改
	只能创建新的索引，并且设定正确的字段类型，再重新导⼊数据

PUT blogs/_mapping
{
        "properties" : {
        "content" : {
          "type" : "text",
          "fields" : {
            "english" : {
              "type" : "text",
              "analyzer" : "english"
            }
          }
        },
        "keyword" : {
          "type" : "keyword"
        }
      }
}



DELETE blogs_fix

# 创建新的索引并且设定新的Mapping
PUT blogs_fix/
{
  "mappings": {
        "properties" : {
        "content" : {
          "type" : "text",
          "fields" : {
            "english" : {
              "type" : "text",
              "analyzer" : "english"
            }
          }
        },
        "keyword" : {
          "type" : "keyword"
        }
      }    
  }
}

# Reindx API
	Reindex API ⽀持把⽂档从⼀个索引拷⻉到另外⼀个索引
	使⽤ Reindex API 的⼀些场景
		修改索引的主分⽚数
		改变字段的 Mapping 中的字段类型
		集群内数据迁移 / 跨集群的数据迁移


POST  _reindex
{
  "source": {
    "index": "blogs"
  },
  "dest": {
    "index": "blogs_fix"
  }
}


# Reindx API，version Type Internal
	_reindex 只会创建不存在的⽂档
	⽂档如果已经存在，会导致版本冲突

POST  _reindex
{
  "source": {
    "index": "blogs"
  },
  "dest": {
    "index": "blogs_fix",
    "op_type": "create"
  }
}



# Reindx API，version Type Internal


POST  _reindex
{
  "source": {
    "index": "blogs"
  },
  "dest": {
    "index": "blogs_fix",
    "version_type": "internal"
  }
}

# 文档版本号增加
GET  blogs_fix/_doc/1

# Reindx API，version Type Internal
POST  _reindex
{
  "source": {
    "index": "blogs"
  },
  "dest": {
    "index": "blogs_fix",
    "version_type": "external"
  }
}


# Reindx API，version Type Internal
POST  _reindex
{
  "source": {
    "index": "blogs"
  },
  "dest": {
    "index": "blogs_fix",
    "version_type": "external"
  },
  "conflicts": "proceed"
}



# 通过查看 Task API，了解 Reindex 的状况
GET _tasks?detailed=true&actions=*reindex





------------


## Ingest Pipeline 与 Painless Script


Ingest Node
	Elasticsearch 5.0 后，引⼊的⼀种新的节点类型。默认配置下，每个节点都是 Ingest Node
		具有预处理数据的能⼒，可拦截 Index 或 Bulk API 的请求
		对数据进⾏转换，并重新返回给 Index 或 Bulk API
	⽆需 Logstash，就可以进⾏数据的预处理，例如
		为某个字段设置默认值；重命名某个字段的字段名；对字段值进⾏ Split 操作
		⽀持设置 Painless 脚本，对数据进⾏更加复杂的加⼯


Pipeline & Processor
	Pipeline - 管道会对通过的数据（⽂档），按照顺序进⾏加⼯
	Processor - Elasticsearch 对⼀些加⼯的⾏为进⾏了抽象包装
		Elasticsearch 有很多内置的 Processors。也⽀持通过插件的⽅式，实现⾃⼰的 Processor
	Pipeline就是一组Processors




#########Demo for Pipeline###############

DELETE tech_blogs

# 需求：修复与增强写⼊的数据
	Blog数据，包含3个字段，tags用逗号间隔
	Tags 字段中，逗号分隔的⽂本应该是数组，⽽不是⼀个字符串
		需求：后期需要对 Tags 进⾏ Aggregation 统计

PUT tech_blogs/_doc/1
{
  "title":"Introducing big data......",
  "tags":"hadoop,elasticsearch,spark",
  "content":"You konw, for big data"
}


# 使⽤ Pipeline 切分字符串
	Simulate API，模拟Pipeline
	在数组中定义Processors
	使用不同的测试文档

POST _ingest/pipeline/_simulate
{
  "pipeline": { 
    "description": "to split blog tags",
    "processors": [
      {
        "split": {
          "field": "tags",
          "separator": ","
        }
      }
    ]
  },
  "docs": [
    {
      "_index": "index",
      "_id": "id",
      "_source": {
        "title": "Introducing big data......",
        "tags": "hadoop,elasticsearch,spark",
        "content": "You konw, for big data"
      }
    },
    {
      "_index": "index",
      "_id": "idxx",
      "_source": {
        "title": "Introducing cloud computering",
        "tags": "openstack,k8s",
        "content": "You konw, for cloud"
      }
    }
  ]
}


# 为⽂档增加字段
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "description": "to split blog tags",
    "processors": [
      {
        "split": {
          "field": "tags",
          "separator": ","
        }
      },

      {
        "set":{
          "field": "views",
          "value": 0
        }
      }
    ]
  },

  "docs": [
    {
      "_index":"index",
      "_id":"id",
      "_source":{
        "title":"Introducing big data......",
  "tags":"hadoop,elasticsearch,spark",
  "content":"You konw, for big data"
      }
    },


    {
      "_index":"index",
      "_id":"idxx",
      "_source":{
        "title":"Introducing cloud computering",
  "tags":"openstack,k8s",
  "content":"You konw, for cloud"
      }
    }

    ]
}



# 为ES添加一个 Pipeline
	blog_pipeline：Pipeline UID

PUT _ingest/pipeline/blog_pipeline
{
  "description": "a blog pipeline",
  "processors": [
      {
        "split": {
          "field": "tags",
          "separator": ","
        }
      },

      {
        "set":{
          "field": "views",
          "value": 0
        }
      }
    ]
}

#查看Pipleline
GET _ingest/pipeline/blog_pipeline


#测试pipeline
POST _ingest/pipeline/blog_pipeline/_simulate
{
  "docs": [
    {
      "_source": {
        "title": "Introducing cloud computering",
        "tags": "openstack,k8s",
        "content": "You konw, for cloud"
      }
    }
  ]
}

#不使用pipeline更新数据
PUT tech_blogs/_doc/1
{
  "title":"Introducing big data......",
  "tags":"hadoop,elasticsearch,spark",
  "content":"You konw, for big data"
}

#使用pipeline更新数据(写⼊数据时) 
PUT tech_blogs/_doc/2?pipeline=blog_pipeline
{
  "title": "Introducing cloud computering",
  "tags": "openstack,k8s",
  "content": "You konw, for cloud"
}


#查看两条数据，一条被处理，一条未被处理
POST tech_blogs/_search
{}

#update_by_query 会导致错误
POST tech_blogs/_update_by_query?pipeline=blog_pipeline
{
}

#增加update_by_query的条件(对已有数据进⾏处理)
POST tech_blogs/_update_by_query?pipeline=blog_pipeline
{
    "query": {
        "bool": {
            "must_not": {
                "exists": {
                    "field": "views"
                }
            }
        }
    }
}


Ingest Node v.s Logstash

				Logstash 								Ingest Node
数据输⼊与输出 	⽀持从不同的数据源读取，并写⼊不同的数据源  ⽀持从 ES REST API 获取数据，并且写⼊ Elasticsearch
数据缓冲 		实现了简单的数据队列，⽀持重写 			不⽀持缓冲
数据处理 		⽀持⼤量的插件，也⽀持定制开发				内置的插件，可以开发 Plugin 进⾏扩展（Plugin 更新需要重启）
配置和使⽤ 		增加了⼀定的架构复杂度 					⽆需额外部署




Painless 简介
	⾃ Elasticsearch 5.x 后引⼊，专⻔为 Elasticsearch 设计，扩展了 Java 的语法。 
	6.0 开始，ES 只⽀持 Painless
	Painless ⽀持所有 Java 的数据类型及 Java API ⼦集
	Painless Script 具备以下特性
		⾼性能 / 安全
		⽀持显示类型或者动态定义类型


Painless 的⽤途
	可以对⽂档字段进⾏加⼯处理
		更新或删除字段，处理数据聚合操作
		Script Field：对返回的字段提前进⾏计算
		Function Score：对⽂档的算分进⾏处理
	在 Ingest Pipeline 中执⾏脚本
	在 Reindex API，Update By Query 时，对数据进⾏处理


通过 Painless 脚本访问字段
	上下⽂ 					语法
	Ingestion 				ctx.field_name
	Update 					ctx._source.field_name
	Search & Aggregation 	doc["field_name"]






#########Demo for Painless###############

# 增加一个 Script Prcessor
POST _ingest/pipeline/_simulate
{
  "pipeline": {
    "description": "to split blog tags",
    "processors": [
      {
        "split": {
          "field": "tags",
          "separator": ","
        }
      },
      {
        "script": {
          "source": """
          if(ctx.containsKey("content")){
            ctx.content_length = ctx.content.length();
          }else{
            ctx.content_length=0;
          }"""
        }
      },
      {
        "set": {
          "field": "views",
          "value": 0
        }
      }
    ]
  },
  "docs": [
    {
      "_index": "index",
      "_id": "id",
      "_source": {
        "title": "Introducing big data......",
        "tags": "hadoop,elasticsearch,spark",
        "content": "You konw, for big data"
      }
    },
    {
      "_index": "index",
      "_id": "idxx",
      "_source": {
        "title": "Introducing cloud computering",
        "tags": "openstack,k8s",
        "content": "You konw, for cloud"
      }
    }
  ]
}


# 案例 2：⽂档更新计数

DELETE tech_blogs
PUT tech_blogs/_doc/1
{
  "title":"Introducing big data......",
  "tags":"hadoop,elasticsearch,spark",
  "content":"You konw, for big data",
  "views":0
}


# Inline 脚本
POST tech_blogs/_update/1
{
  "script": {
    "source": "ctx._source.views += params.new_views",
    "params": {
      "new_views":100
    }
  }
}

# 查看views计数
POST tech_blogs/_search
{

}


# Stored Scripts 保存脚本在 Cluster State
POST _scripts/update_views
{
  "script":{
    "lang": "painless",
    "source": "ctx._source.views += params.new_views"
  }
}

# 通过 Id 使⽤ , 使⽤ Params，减少编译的条数
POST tech_blogs/_update/1
{
  "script": {
    "id": "update_views",
    "params": {
      "new_views":1000
    }
  }
}




# 案例 3：搜索时的 Script 字段

GET tech_blogs/_search
{
  "script_fields": {
    "rnd_views": {
      "script": {
        "lang": "painless",
        "source": """
          java.util.Random rnd = new Random();
          doc['views'].value+rnd.nextInt(1000);
        """
      }
    }
  },
  "query": {
    "match_all": {}
  }
}




脚本缓存

参数 							说明
script.cache.max_size 			设置最⼤缓存数
script.cache.expire 			设置缓存超时
script.max_compilations_rate 	默认5分钟最多75次编译 （75/5m）


	编译的开销相较⼤
	Elasticsearch 会将脚本编译后缓存在Cache 中
		Inline scripts 和 Stored Scripts 都会被缓存 
		默认缓存 100 个脚本




-------------




## Elasticsearch 数据建模实例


什么是数据建模？
	数据建模（Data modeling）， 是创建数据模型的过程数据模型是对真实世界进⾏抽象描述的⼀种⼯具和⽅法，实现对现实世界的映射
		博客 / 作者 / ⽤户评论
	三个过程：概念模型 => 逻辑模型 => 数据模型（第三范式）
		数据模型：结合具体的数据库，在满⾜业务读写性能等需求的前提下，确定最终的定义


数据建模：功能需求 + 性能需求
	
	逻辑模型 数据需求
		实体属性
		实体之间的关系
		搜索相关的配置

	物理模型 性能需求
		索引模版
		分⽚数量
		索引 Mapping
		字段配置
		关系处理


如何对字段进⾏建模
	字段类型 >> 是否要搜索及分词 >> 是否要聚合及排序 >> 是否要额外的存储



字段类型：Text v.s Keyword
	Text
		⽤于全⽂本字段，⽂本会被 Analyzer 分词
		默认不⽀持聚合分析及排序。需要设置 fielddata 为 true
	Keyword
		⽤于 id，枚举及不需要分词的⽂本。例如电话号码，email地址，⼿机号码，邮政编码，性别等
		适⽤于 Filter（精确匹配），Sorting 和 Aggregations
	设置多字段类型
		默认会为⽂本类型设置成 text，并且设置⼀个 keyword 的⼦字段
		在处理⼈类语⾔时，通过增加“英⽂”，“拼⾳”和“标准”分词器，提⾼搜索结构


字段类型 ：结构化数据
	数值类型
		尽量选择贴近的类型。例如可以⽤ byte，就不要⽤ long
	枚举类型
		设置为 keyword。即便是数字，也应该设置成 keyword，获取更加好的性能
	其他
		 / 布尔 / 地理信息


检索
	如不需要检索，排序和聚合分析
		Enable 设置成 false
	如不需要检索
		Index 设置成 false
	对需要检索的字段，可以通过如下配置，设定存储粒度
		Index_options / Norms ：不需要归⼀化数据时，可以关闭


聚合及排序
	如不需要检索，排序和聚合分析
		Enable 设置成 false
	如不需要排序或者聚合分析功能
		Doc_values / fielddata 设置成 false
	更新频繁，聚合查询频繁的 keyword 类型的字段
		推荐将 eager_global_ordinals 设置为 true


额外的存储
	是否需要专⻔存储当前字段数据
		Store 设置成 true，可以存储该字段的原始内容
		⼀般结合 _source 的 enabled 为 false 时候使⽤
	Disable _source：节约磁盘；适⽤于指标型数据
		⼀般建议先考虑增加压缩⽐
		⽆法看到 _source字段，⽆法做 ReIndex，⽆法做Update
		Kibana 中⽆法做 discovery



⼀个数据建模的实例








# Index 一本书的信息
PUT books/_doc/1
{
  "title":"Mastering ElasticSearch 5.0",
  "description":"Master the searching, indexing, and aggregation features in ElasticSearch Improve users’ search experience with Elasticsearch’s functionalities and develop your own Elasticsearch plugins",
  "author":"Bharvi Dixit",
  "public_date":"2017",
  "cover_url":"https://images-na.ssl-images-amazon.com/images/I/51OeaMFxcML.jpg"
}



#查询自动创建的Mapping

	Index 设置成 false，不⽀持搜索，⽀持 Terms 聚合
	如将 “enabled” 设置为 false，则⽆法进⾏搜索和聚合分析


GET books/_mapping

DELETE books

#优化字段类型
	书名：⽀持全⽂和精确匹配
	简介：⽀持全⽂
	作者：精确值
	发⾏⽇期：⽇期类型
	图书封⾯：精确值

PUT books
{
  "mappings": {
    "properties": {
      "author": {
        "type": "keyword"
      },
      "cover_url": {
        "type": "keyword",
        "index": false
      },
      "description": {
        "type": "text"
      },
      "public_date": {
        "type": "date"
      },
      "title": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 100
          }
        }
      }
    }
  }
}

Cover URL index 设置成false，无法对该字段进行搜索
POST books/_search
{
  "query": {
    "term": {
      "cover_url": {
        "value": "https://images-na.ssl-images-amazon.com/images/I/51OeaMFxcML.jpg"
      }
    }
  }
}

#Cover URL index 设置成false，依然支持聚合分析
POST books/_search
{
  "aggs": {
    "cover": {
      "terms": {
        "field": "cover_url",
        "size": 10
      }
    }
  }
}





# 需求变更 
	新需求：增加图书内容的字段。并要求能被搜索同时⽀持⾼亮显示
	新需求会导致 _source 的内容过⼤
		Source Filtering 只是传输给客户端时进⾏过滤，Fetch 数据时，ES 节点还是会传输 _source 中的数据
	解决⽅法
		关闭 _source
		然后将每个字段的 “store” 设置成 true

DELETE books
PUT books
{
  "mappings": {
    "_source": {
      "enabled": false
    },
    "properties": {
      "author": {
        "type": "keyword",
        "store": true
      },
      "cover_url": {
        "type": "keyword",
        "index": false,
        "store": true
      },
      "description": {
        "type": "text",
        "store": true
      },
      "content": {
        "type": "text",
        "store": true
      },
      "public_date": {
        "type": "date",
        "store": true
      },
      "title": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 100
          }
        },
        "store": true
      }
    }
  }
}


查询图书：解决字段过⼤引发的性能问题
	返回结果不包含 _source 字段
	对于需要显示的信息，可以在在查询中指定"stored_fields"
	禁⽌ _source 字段后，还是⽀持使⽤ highlights API，⾼亮显示 content 中匹配的相关信息


# Index 一本书的信息,包含Content

PUT books/_doc/1
{
  "title":"Mastering ElasticSearch 5.0",
  "description":"Master the searching, indexing, and aggregation features in ElasticSearch Improve users’ search experience with Elasticsearch’s functionalities and develop your own Elasticsearch plugins",
  "content":"The content of the book......Indexing data, aggregation, searching.    something else. something in the way............",
  "author":"Bharvi Dixit",
  "public_date":"2017",
  "cover_url":"https://images-na.ssl-images-amazon.com/images/I/51OeaMFxcML.jpg"
}

#查询结果中，Source不包含数据
POST books/_search
{}

#搜索，通过store 字段显示数据，同时高亮显示 conent的内容
POST books/_search
{
  "stored_fields": [
    "title",
    "author",
    "public_date"
  ],
  "query": {
    "match": {
      "content": "searching"
    }
  },
  "highlight": {
    "fields": {
      "content": {}
    }
  }
}




Mapping 字段的相关设置
	Enabled – 设置成 false，仅做存储，不⽀持搜索和聚合分析 （数据保存在 _source 中）
	Index – 是否倒排索引。设置成 false，⽆法被搜索，但还是⽀持 aggregation，并出现在 _source 中 
	Norms – 如果字段⽤来过滤和聚合分析，可以关闭，节约存储
	Doc_values – 是否启⽤ doc_values，⽤于排序和聚合分析
	Field_data – 如果要对 text 类型启⽤排序和聚合分析， fielddata 需要设置成true
	Store – 默认不存储，数据默认存储在 _source。 
	Coerce – 默认开启，是否开启数据类型的⾃动转换（例如，字符串转数字）
	Multifields 多字段特性
	Dynamic – true / false / strict 控制 Mapping 的⾃动更新


# Coerce

PUT my_index
{
  "mappings": {
    "properties": {
      "number_one": {
        "type": "integer"
      },
      "number_two": {
        "type": "integer",
        "coerce": false
      }
    }
  }
}


PUT my_index
{
  "settings": {
    "index.mapping.coerce": false
  },
  "mappings": {
    "properties": {
      "number_one": {
        "type": "integer",
        "coerce": true
      },
      "number_two": {
        "type": "integer"
      }
    }
  }
}

PUT my_index/_doc/1
{ "number_one": "10" } 

PUT my_index/_doc/2
{ "number_two": "10" } 




# analyzer


UT my_index
{
   "settings":{
      "analysis":{
         "analyzer":{
            "my_analyzer":{ 
               "type":"custom",
               "tokenizer":"standard",
               "filter":[
                  "lowercase"
               ]
            },
            "my_stop_analyzer":{ 
               "type":"custom",
               "tokenizer":"standard",
               "filter":[
                  "lowercase",
                  "english_stop"
               ]
            }
         },
         "filter":{
            "english_stop":{
               "type":"stop",
               "stopwords":"_english_"
            }
         }
      }
   },
   "mappings":{
       "properties":{
          "title": {
             "type":"text",
             "analyzer":"my_analyzer", 
             "search_analyzer":"my_stop_analyzer", 
             "search_quote_analyzer":"my_analyzer" 
         }
      }
   }
}

PUT my_index/_doc/1
{
   "title":"The Quick Brown Fox"
}

PUT my_index/_doc/2
{
   "title":"A Quick Brown Fox"
}

GET my_index/_search
{
   "query":{
      "query_string":{
         "query":"\"the quick brown fox\"" 
      }
   }
}




-----------




## Elasticsearch 数据建模最佳实践

建模建议（⼀）：如何处理关联关系

	Object 			优先考虑 Denormalization
	Nested 			当数据包含多数值对象（多个演员），同时有查询需求
	Child/Parent 	关联⽂档更新⾮常频繁时

Kibana
	Kibana ⽬前暂不⽀持 nested 类型和 parent/child 类型 ，在未来有可能会⽀持
	如果需要使⽤ Kibana 进⾏数据分析，在数据建模时仍需对嵌套和⽗⼦关联类型作出取舍


建模建议（⼆）: 避免过多字段
	⼀个⽂档中，最好避免⼤量的字段
		过多的字段数不容易维护
		Mapping 信息保存在 Cluster State 中，数据量过⼤，对集群性能会有影响 （ClusterState 信息需要和所有的节点同步）
		删除或者修改数据需要 reindex
	默认最⼤字段数是 1000，可以设置 index.mapping.total_fields.limt 限定最⼤字段数。
	什么原因会导致⽂档中有成百上千的字段？


Dynamic v.s Strict
	Dynamic（⽣产环境中，尽量不要打开 Dynamic） 
		true - 未知字段会被⾃动加⼊
		false - 新字段不会被索引。但是会保存在 _source
		strict - 新增字段不会被索引，⽂档写⼊失败
	Strict 
		制到字段级别












#Cookie Service
	来⾃ Cookie Service 的数据
	Cookie 的键值对很多
	当 Dynamic 设置为 True
	同时采⽤扁平化的设计，必然导致字段数量的膨胀

##索引数据，dynamic mapping 会不断加入新增字段
PUT cookie_service/_doc/1
{
 "url":"www.google.com",
 "cookies":{
   "username":"tom",
   "age":32
 }
}

PUT cookie_service/_doc/2
{
 "url":"www.amazon.com",
 "cookies":{
   "login":"2019-01-01",
   "email":"xyz@abc.com"
 }
}


DELETE cookie_service

# 解决⽅案：Nested Object & Key Value

PUT cookie_service
{
  "mappings": {
    "properties": {
      "cookies": {
        "type": "nested",
        "properties": {
          "name": {
            "type": "keyword"
          },
          "dateValue": {
            "type": "date"
          },
          "keywordValue": {
            "type": "keyword"
          },
          "IntValue": {
            "type": "integer"
          }
        }
      },
      "url": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 256
          }
        }
      }
    }
  }
}


##写入数据，使用key和合适类型的value字段
PUT cookie_service/_doc/1
{
 "url":"www.google.com",
 "cookies":[
    {
      "name":"username",
      "keywordValue":"tom"
    },
    {
      "name":"age",
      "intValue":32
    }
   ]
 }


PUT cookie_service/_doc/2
{
 "url":"www.amazon.com",
 "cookies":[
    {
      "name":"login",
      "dateValue":"2019-01-01"
    },
    {
      "name":"email",
      "IntValue":32
    }
   ]
 }


# Nested 查询，通过bool查询进行过滤
POST cookie_service/_search
{
  "query": {
    "nested": {
      "path": "cookies",
      "query": {
        "bool": {
          "filter": [
            {
              "term": {
                "cookies.name": "age"
              }
            },
            {
              "range": {
                "cookies.intValue": {
                  "gte": 30
                }
              }
            }
          ]
        }
      }
    }
  }
}

通过 Nested 对象保存 Key/Value 的⼀些不⾜
可以减少字段数量，解决 Cluster State 中保存过多 Meta 信息的问题，但是
	导致查询语句复杂度增加
	Nested 对象，不利于在 Kibana 中实现可视化分析



案例
	⽂档中某个字段包含了 Elasticsearch 的版本信息，例如 version: “7.1.0” 
	搜索所有是 bug fix 的版本？每个主要版本号所关联的⽂档?


建模建议（三）：避免正则查询

# 在Mapping中加入元信息，便于管理
PUT softwares/
{
  "mappings": {
    "_meta": {
      "software_version_mapping": "1.0"
    }
  }
}

GET softwares/_mapping
PUT softwares/_doc/1
{
  "software_version":"7.1.0"
}

DELETE softwares



# 解决⽅案：将字符串转换为对象:使用inner object
PUT softwares/
{
  "mappings": {
    "_meta": {
      "software_version_mapping": "1.1"
    },
    "properties": {
      "version": {
        "properties": {
          "display_name": {
            "type": "keyword"
          },
          "hot_fix": {
            "type": "byte"
          },
          "marjor": {
            "type": "byte"
          },
          "minor": {
            "type": "byte"
          }
        }
      }
    }
  }
}


#通过 Inner Object 写入多个文档
PUT softwares/_doc/1
{
  "version":{
  "display_name":"7.1.0",
  "marjor":7,
  "minor":1,
  "hot_fix":0  
  }

}


# 搜索过滤 : 实现Filter 过滤，避免正则查询。⼤⼤提升性能

POST softwares/_search
{
  "query": {
    "bool": {
      "filter": [
        {
          "match": {
            "version.marjor": 7
          }
        },
        {
          "match": {
            "version.minor": 2
          }
        }
      ]
    }
  }
}



建模建议（四）：避免空值引起的聚合不准

# Not Null 解决聚合的问题
DELETE ratings
PUT ratings
{
  "mappings": {
      "properties": {
        "rating": {
          "type": "float",
          "null_value": 1.0
        }
      }
    }
}


PUT ratings/_doc/1
{
 "rating":5
}
PUT ratings/_doc/2
{
 "rating":null
}


POST ratings/_search
POST ratings/_search
{
  "size": 0,
  "aggs": {
    "avg": {
      "avg": {
        "field": "rating"
      }
    }
  }
}

POST ratings/_search
{
  "query": {
    "term": {
      "rating": {
        "value": 1
      }
    }
  }
}



建模建议（五）:为索引的 Mapping 加⼊ Meta 信息


Mappings 设置⾮常重要，需要从两个维度进⾏考虑
	功能：搜索，聚合，排序
	性能：存储的开销；内存的开销；搜索的性能

Mappings 设置是⼀个迭代的过程
	加⼊新的字段很容易（必要时需要 update_by_query)
	更新删除字段不允许（需要 Reindex 重建数据） 
	最好能对 Mappings 加⼊ Meta 信息，更好的进⾏版本管理
	可以考虑将 Mapping ⽂件上传 git 进⾏管理






# 在Mapping中加入元信息，便于管理
PUT softwares/
{
  "mappings": {
    "_meta": {
      "software_version_mapping": "1.0"
    }
  }
}

GET softwares/_mapping
PUT softwares/_doc/1
{
  "software_version":"7.1.0"
}

DELETE softwares
























































