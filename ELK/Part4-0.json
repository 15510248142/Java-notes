


## Logstash 入门及架构介绍


Logstash
	ELT 工具 / 数据搜集处理引擎。支持 200 多个插件


Logstash Concepts
	Pipeline
		包含了 input-filter-output 三个阶段的处理流程
		插件生命周期管理
		队列管理
	Logstash Event
		数据在内部流转时的具体表现形式。数据在 input 阶段被转换为 Event，在 output 被转化成目标格式 数据
		Event 其实是一个 Java Object，在配置文件中，对 Event 的属性进行增删改查



Logstash 架构简介
	Codec（Code / Decode）：将原始数据 decode 成 Event；将 Event encode 成目标数据
		Filter Plugins 处理 Event


input -> codec -> queue -> batcher -> Filter -> output


多 Pipelines 实例
	Pipeline.works: Pipeline 线程数，默认是 CPU 核数	
	Pipeline.batch.size：Batcher 一次批量获取等待处理的文档数，默认 125。需结合 jvm.options 调节
	Pipeline.batch.delay：Batcher 等待时间


Codec Plugin - Multiline
	Pattern： 设置行匹配的正则表达式
	What ：如果匹配成功，那么匹配行属于上一个事件还是下一个事件
		Previous / Nex
	Negate true / false：是否对 pattern 结果取反


Filter Plugin
	Filter Plugin 可以对 Logstash Event 进行各种处理，例如解析，删除字段，类型转换
		Date：日期解析 
		Dissect：分割符解析 
		Grok：正则匹配解析 
		Mutate：处理字段。重命名，删除，替换 
		Ruby：利用 Ruby 代码来动态修改 Event


Filter Plugin - Mutate
	对字段做各种操作
		Convert 类型转换
		Gsub 字符串替换
		Split / Join / Merge 字符串切割，数组合并字符串，数组合并数组
		Rename 字段重命名
		Update / Replace 字段内容更新替换
		Remove_field 字段删除



--------


## 利用 JDBC 插件导入数据到 Elasticsearch


需求 – 将数据库中的数据同步到 ES，借助 ES 的全文搜索，提高搜索速度


JDBC Input Plugin & 设计实现思路
	支持通过 JDBC Input Plugin 将数 据从数据库从读到 Logstash
		需要自己提供所需的 JDBC Driver
	Scheduling
		扩展了 Cron，支持时区

Demo
	支持 新增 / 更新 / 删除 三种 API
	User 表包含了一个 last update 的字段
	User 表包含了一个 is deleted 字段

/*

input {
  jdbc {
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_connection_string => "jdbc:mysql://localhost:3306/db_example"
    jdbc_user => root
    jdbc_password => ymruan123
    #启用追踪，如果为true，则需要指定tracking_column
    use_column_value => true
    #指定追踪的字段，
    tracking_column => "last_updated"
    #追踪字段的类型，目前只有数字(numeric)和时间类型(timestamp)，默认是数字类型
    tracking_column_type => "numeric"
    #记录最后一次运行的结果
    record_last_run => true
    #上面运行结果的保存位置
    last_run_metadata_path => "jdbc-position.txt"
    statement => "SELECT * FROM user where last_updated >:sql_last_value;"
    schedule => " * * * * * *"
  }
}
output {
  elasticsearch {
    document_id => "%{id}"
    document_type => "_doc"
    index => "users"
    hosts => ["http://localhost:9200"]
  }
  stdout{
    codec => rubydebug
  }
}
*/




---------


## Beats

全品类采集器，搞定所有数据类型
	以搜集数据为主 
	支持与 Logstash 或 ES 集成
	全品类 / 轻量级 / 开箱即用 / 可插拔 / 可扩展 / 可视化


Metricbeat 简介
	用来定期搜集操作系统，软件的指标数据
		Metric v.s Logs
			Metric – 可聚合的数据，定期搜集
			Logs 文本数据，随机搜集
	指标存储在 Elasticsearch 中，可以通过 Kibana 进行实时的数据分析


Metricbeat 组成
	Module
		搜集的指标对象，例如不同的操作系统，不同的数据库，不同的应用系统
	Metricset	
		一个 Module可以有多个 metricset
		具体的指标集合。以减少调用次数为原则进行划分
			不同的 metricset 可以设置不同的抓取时长



Packetbeat
	Packetbeat - 实时网络数据分析，监控应用服务器之间的网络流量
		常见抓包工具 - Tcpdump /wireshark
		常见抓包配置 - Pcap 基于 libpcap，跨平台 / Af_packet 仅支持 Linux，基于内存映射嗅探，高性 能
	Network flows：抓取记录网络流量数据，不涉及协议解析	




--------



## 使用 Index Pattern 配置数据 






---------



## 使用 Kibana Discovery 探索数据





------------


## 基本可视化组件介绍





-------------


## 构建 Dashboard




------------



## 用 Monitoring 和 Alerting 监控 Elasticsearch 集群


X-Pack Monitoring
	X-Pack 提供了免费集群监控的功能
	使用 Elasticsearch 监控 Elasticsearch	
		Xpack.monitoring.collection.interval 默认设置 10 秒
	在生产环境中，建议搭建 dedicated 集群用于 ES 集群的监控。有以下几个好处	
		减少负载和数据	
		当被监控集群出现问题，还能看到监控相关的数据


xpack.monitoring.collection.indices 	默认监控所有索引。支持配置索引列表（逗号间 隔）
xpack.monitoring.collection.interval 	搜集数据的时间间隔，默认 10 秒
xpack.monitoring.history.duration 		数据保留的时间，默认 7 天



Watcher for Alerting

	需要 Gold 账户
	一个 Watcher 由 5个部分组成
		Trigger – 多久被触发一次（例如：5 分钟触发一次）
		Input – 查询条件（在所有日志索引中查看 “ERROR” 相关）
		Condition –查询是否满足条件（例如：大于 1000 条返回）
		Actions – 执行相关操作（例如：发送邮件)




--------






























































































































































